{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "# 07. 딥 러닝(Deep Learning) 개요\n",
    "***\n",
    "\n",
    "딥 러닝(Deep Learning)은 머신 러닝(Machine Learning)의 특정한 한 분야로서 인공 신경망(Artificial Neural Network)의 층을 연속적으로 깊게 쌓아올려 데이터를 학습하는 방식을 말합니다.\n",
    "딥 러닝이 화두가 되기 시작한 것은 2010년대의 비교적 최근의 일이지만, 딥 러닝의 기본 구조인 인공 신경망의 역사는 생각보다 오래되었습니다.\n",
    "이번 챕터에서는 딥 러닝을 보다 쉽게 이해하기 위해 1957년의 초기 인공 신경망인 퍼셉트론에서부터 설명을 시작하여 층을 깊게 쌓아 학습하는 딥 러닝까지 개념을 점차적으로 확장해보겠습니다.\n",
    "추가적으로 이번 챕터에서는 피드 포워드 신경망과 같은 기본적인 인공 신경망 용어들과 케라스의 사용 방법에 대해서 학습합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85113155a2f2c087"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 07-01 퍼셉트론(Perceptron)\n",
    "***\n",
    "\n",
    "인공 신경망은 수많은 머신 러닝 방법 중 하나입니다.\n",
    "하지만 최근 인공 신경망을 복잡하게 쌓아 올린 딥 러닝이 다른 머신 러닝 방법들을 뛰어넘는 성능을 보여주는 사례가 늘면서,\n",
    "전통적인 머신 러닝과 딥 러닝을 구분해서 이해해야 한다는 목소리가 커지고 있습니다.\n",
    "딥 러닝을 이해하기 위해서는 우선 인공 신경망에 대한 이해가 필요한데, 여기서는 초기의 인공 신경망인 퍼셉트론(Perceptron)에 대해서 이해합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55adbc6607655689"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. 퍼셉트론(Perceptron)\n",
    "***\n",
    "퍼셉트론(Perceptron)은 프랑크 로젠블라트(Frank Rosenblatt)가 1957년에 제안한 초기 형태의 인공 신경망으로 다수의 입력으로부터 하나의 결과를 내보내는 알고리즘입니다. \n",
    "퍼셉트론은 실제 뇌를 구성하는 신경 세포 뉴런의 동작과 유사한데, 신경 세포 뉴런의 그림을 먼저 보도록 하겠습니다.\n",
    "뉴런은 가지돌기에서 신호를 받아들이고, 이 신호가 일정치 이상의 크기를 가지면 축삭돌기를 통해서 신호를 전달합니다.\n",
    "\n",
    "![그림](img.png)\n",
    "\n",
    "다수의 입력을 받는 퍼셉트론의 그림을 보겠습니다. 신경 세포 뉴런의 입력 신호와 출력 신호가 퍼셉트론에서 각각 입력값과 출력값에 해당됩니다.\n",
    "\n",
    "![그림](img_1.png)\n",
    "\n",
    "$x$는 입력값을 의미하며, $w$는 가중치(Weight), $y$는 출력값입니다.\n",
    "그림 안의 원은 인공 뉴런에 해당됩니다. 실제 신경 세포 뉴런에서의 신호를 전달하는 축삭돌기의 역할을 퍼셉트론에서는 가중치가 대신합니다.\n",
    "각각의 인공 뉴런에서 보내진 입력값 $x$는 각각의 가중치 $w$와 함께 종착지인 인공 뉴런에 전달되고 있습니다.\n",
    "\n",
    "**각각의 입력값에는 각각의 가중치가 존재하는데, 이때 가중치의 값이 크면 클수록 해당 입력 값이 중요하다는 것을 의미합니다.**\n",
    "\n",
    "각 입력값이 가중치와 곱해져서 인공 뉴런에 보내지고,\n",
    "각 입력값과 그에 해당되는 가중치의 곱의 전체 합이 임계치(threshold)를 넘으면 종착지에 있는 인공 뉴런은 출력 신호로서 1을 출력하고,\n",
    "그렇지 않을 경우에는 0을 출력합니다.\n",
    "이러한 함수를 계단 함수(Step function)라고 하며, 아래는 그래프는 계단 함수의 하나의 예를 보여줍니다.\n",
    "\n",
    "![그림](img_2.png)\n",
    "\n",
    "이때 계단 함수에 사용된 이 임계치값을 수식으로 표현할 때는 보통 세타(Θ)로 표현합니다. 식으로 표현하면 다음과 같습니다.\n",
    "\n",
    "![그림](img_3.png)\n",
    "\n",
    "위의 식에서 임계치를 좌변으로 넘기고 편향 $b$(bias)로 표현할 수도 있습니다.\n",
    "편향 $b$ 또한 퍼셉트론의 입력으로 사용됩니다.\n",
    "보통 그림으로 표현할 때는 입력값이 1로 고정되고 편향 $b$가 곱해지는 변수로 표현됩니다.\n",
    "\n",
    "![그림](img_4.png)\n",
    "![그림](img_5.png)\n",
    "\n",
    "이 책을 포함한 많은 인공 신경망 자료에서 편의상 편향 $b$가 그림이나 수식에서 생략되서 표현되기도 하지만\n",
    "실제로는 편향 $b$ 또한 딥 러닝이 최적의 값을 찾아야 할 변수 중 하나입니다.\n",
    "\n",
    "뒤에서 배우겠지만 이렇게 뉴런에서 출력값을 변경시키는 함수를 활성화 함수(Activation Function)라고 합니다.\n",
    "초기 인공 신경망 모델인 퍼셉트론은 활성화 함수로 계단 함수를 사용하였지만,\n",
    "그 뒤에 등장한 여러가지 발전된 신경망들은 계단 함수 외에도 여러 다양한 활성화 함수를 사용하기 시작했습니다.\n",
    "사실 앞서 배운 시그모이드 함수나 소프트맥스 함수 또한 활성화 함수 중 하나입니다.\n",
    "\n",
    "퍼셉트론을 배우기 전에 로지스틱 회귀를 먼저 배운 이유도 여기에 있습니다.\n",
    "퍼셉트론의 활성화 함수는 계단 함수이지만 여기서 활성화 함수를 시그모이드 함수로 변경하면 방금 배운 퍼셉트론은 곧 이진 분류를 수행하는 로지스틱 회귀와 동일함을 알 수 있습니다.\n",
    "\n",
    "다시 말하면 로지스틱 회귀 모델이 인공 신경망에서는 하나의 인공 뉴런으로 볼 수 있습니다.\n",
    "로지스틱 회귀를 수행하는 인공 뉴런과 위에서 배운 퍼셉트론의 차이는 오직 활성화 함수의 차이입니다.\n",
    "\n",
    "![그림](img_6.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d48c38251662a8f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. 단층 퍼셉트론(Single-Layer Perceptron)\n",
    "***\n",
    "위에서 배운 퍼셉트론을 단층 퍼셉트론이라고 합니다.\n",
    "퍼셉트론은 단층 퍼셉트론과 다층 퍼셉트론으로 나누어진다.\n",
    "\n",
    "단층 퍼셉트론의 단계 \n",
    "- 값을 보내는 단계\n",
    "- 값을 받아서 출력하는 단계\n",
    "\n",
    "이때 이 각 단계를 보통 층(layer)이라고 부르며, 이 두 개의 층을 입력층(input layer)과 출력층(output layer)이라고 합니다.\n",
    "\n",
    "![그림](img_7.png)\n",
    "\n",
    "단층 퍼셉트론이 어떤 일을 할 수 있으며 한계는 무엇인지 학습해보겠습니다.\n",
    "컴퓨터는 두 개의 값 0과 1을 입력해 하나의 값을 출력하는 회로가 모여 만들어지는데, 이 회로를 게이트(gate)라고 부릅니다.\n",
    "초기 형태의 인공 신경망인 단층 퍼셉트론은 간단한 XOR 게이트조차도 구현할 수 없는 부족한 인공 신경망이라는 지적을 받았습니다.\n",
    "단층 퍼셉트론을 이용하면 AND, NAND, OR 게이트는 구현가능합니다. 게이트 연산에 쓰이는 것은 두 개의 입력값과 하나의 출력값입니다.\n",
    "AND 게이트란 두 개의 입력값 $x1, x2$이 각각 0 또는 1의 값을 가질 수 있으면서 모두 1인 경우에만 출력값 $y$가 1이 나오는 구조를 말합니다.\n",
    "\n",
    "![그림](img_8.png)\n",
    "\n",
    "단층 퍼셉트론의 식을 통해 AND 게이트를 만족하는 두 개의 가중치와 편향 값에는 뭐가 있을까요?\n",
    "각각 $w1$, $w2$, $b$라고 한다면 [0.5, 0.5, -0.7], [0.5, 0.5, -0.8] 또는 [1.0, 1.0, -1.0] 등 이 외에도 다양한 가중치와 편향의 조합이 나올 수 있습니다.\n",
    "이해를 돕기 위해서 AND 게이트를 위한 매개변수 값을 가진 단층 퍼셉트론의 식을 파이썬 코드로 간단하게 구현해봅시다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca328653576cef16"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def AND_gate(x1, x2):\n",
    "    w1 = 0.5\n",
    "    w2 = 0.5\n",
    "    b = -0.7\n",
    "    result = x1*w1 + x2*w2 + b\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T08:11:26.863523200Z",
     "start_time": "2024-01-30T08:11:26.856984300Z"
    }
   },
   "id": "d8299c43053c8b11",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "위의 함수에 AND 게이트의 입력값을 모두 넣어보면 오직 두 개의 입력값이 1인 경우에만 1을 출력합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c75622e74ffcb815"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(0, 0, 0, 1)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AND_gate(0, 0), AND_gate(0, 1), AND_gate(1, 0), AND_gate(1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T08:12:39.544267600Z",
     "start_time": "2024-01-30T08:12:39.519217700Z"
    }
   },
   "id": "4e8a56d550654626",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "그렇다면 두 개의 입력값이 1인 경우에만 출력값이 0, 나머지 입력값의 쌍(pair)에 대해서는 모두 출력값이 1이 나오는 NAND 게이트는 어떨까요?\n",
    "\n",
    "![그림](img_9.png)\n",
    "\n",
    "앞서 언급했던 AND 게이트를 충족하는 가중치와 편향값인 [0.5, 0.5, -0.7]에 -를 붙여서 [-0.5, -0.5, +0.7]을 단층 퍼셉트론의 식에 넣어보면 NAND 게이트를 충족합니다.\n",
    "파이썬 코드를 통해서 이를 확인해봅시다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edf9484d6d9c9451"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def NAND_gate(x1, x2):\n",
    "    w1 = -0.5\n",
    "    w2 = -0.5\n",
    "    b = 0.7\n",
    "    result = x1*w1 + x2*w2 + b\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T05:54:48.356383300Z",
     "start_time": "2024-01-25T05:54:48.348449900Z"
    }
   },
   "id": "96a7629e0c5029fd",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "단지 같은 코드에 함수 이름과 가중치와 편향만 바꿨을 뿐입니다. 퍼셉트론의 구조는 같기때문입니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96366837d336ec37"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 1, 1, 0)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAND_gate(0, 0), NAND_gate(0, 1), NAND_gate(1, 0), NAND_gate(1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T05:55:01.322664500Z",
     "start_time": "2024-01-25T05:55:01.315984400Z"
    }
   },
   "id": "17f1ed4c3c460ba",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "NAND 게이트를 구현한 파이썬 코드에 입력값을 넣자, 두 개의 입력값이 1인 경우에만 0이 나오는 것을 확인할 수 있습니다.\n",
    "퍼셉트론으로 NAND 게이트를 구현한 것입니다.\n",
    "[-0.5, -0.5, -0.7] 외에도 퍼셉트론이 NAND 게이트의 동작을 하도록 하는 다양한 가중치와 편향의 값들이 있을 것입니다.\n",
    "\n",
    "두 개의 입력이 모두 0인 경우에 출력값이 0이고 나머지 경우에는 모두 출력값이 1인 OR 게이트 또한 적절한 가중치 값과 편향 값만 찾으면 단층 퍼셉트론의 식으로 구현할 수 있습니다.\n",
    "\n",
    "![그림](img_10.png)\n",
    "\n",
    "예를 들어 각각 가중치와 편향에 대해서 [0.6, 0.6, -0.5]를 선택하면 OR 게이트를 충족합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "313910317a6b3932"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def OR_gate(x1, x2):\n",
    "    w1 = 0.6\n",
    "    w2 = 0.6\n",
    "    b = -0.5\n",
    "    result = x1*w1 + x2*w2 + b\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T06:05:56.959149Z",
     "start_time": "2024-01-25T06:05:56.954965500Z"
    }
   },
   "id": "133b2ef5122cfcc8",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(0, 1, 1, 1)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OR_gate(0, 0), OR_gate(0, 1), OR_gate(1, 0), OR_gate(1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T06:05:58.939348800Z",
     "start_time": "2024-01-25T06:05:58.935849400Z"
    }
   },
   "id": "c0931539323e6100",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "이처럼 단층 퍼셉트론은 AND 게이트, NAND 게이트, OR 게이트를 구현할 수 있으나 지금부터 설명할 XOR 게이트는 구현할 수 없습니다.\n",
    "XOR 게이트는 입력값 두 개가 서로 다른 값을 갖고 있을때에만 출력값이 1이 되고, 입력값 두 개가 서로 같은 값을 가지면 출력값이 0이 되는 게이트입니다.\n",
    "위의 파이썬 코드에 아무리 수많은 가중치와 편향을 넣어봐도 XOR 게이트를 구현하는 것은 불가능합니다.\n",
    "그 이유는 단층 퍼셉트론은 직선 하나로 두 영역을 나눌 수 있는 문제에 대해서만 구현이 가능하기 때문입니다.\n",
    "\n",
    "예를 들어 AND 게이트에 대한 단층 퍼셉트론을 시각화해보면 다음과 같습니다.\n",
    "\n",
    "![그림](img_11.png)\n",
    "\n",
    "그림에서는 출력값 0을 하얀색 원, 1을 검은색 원으로 표현했습니다. AND 게이트를 충족하려면 하얀색 원과 검은색 원을 직선으로 나누게 됩니다.\n",
    "마찬가지로 NAND 게이트나 OR 게이트에 대해서도 시각화를 했을 때 직선으로 나누는 것이 가능합니다.\n",
    "\n",
    "![그림](img_12.png)\n",
    "\n",
    "그렇다면 XOR 게이트는 어떨까요? XOR 게이트는 입력값 두 개가 서로 다른 값을 갖고 있을때에만 출력값이 1이 되고, 입력값 두 개가 서로 같은 값을 가지면 출력값이 0이 되는 게이트입니다.\n",
    "XOR 게이트를 시각화해보면 다음과 같습니다.\n",
    "\n",
    "![그림](img_13.png)\n",
    "\n",
    "하얀색 원과 검은색 원을 직선 하나로 나누는 것은 불가능하므로 단층 퍼셉트론으로는 XOR 게이트를 구현할 수 없습니다.\n",
    "위의 좌측 그림과 같이 적어도 두 개의 선이 필요합니다. 이를 어떻게 해결할 수 있을까요? 이에 대한 해답은 다층 퍼셉트론입니다.\n",
    "다층 퍼셉트론을 사용하면 여러 개의 선으로 분류하는 효과를 얻을 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae8046ed843569d7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. 다층 퍼셉트론(MultiLayer Perceptron, MLP)\n",
    "***\n",
    "\n",
    "XOR 게이트는 기존의 AND, NAND, OR 게이트를 조합하면 만들 수 있습니다. 퍼셉트론 관점에서 말하면 층을 더 쌓으면 만들 수 있습니다.\n",
    "다층 퍼셉트론과 단층 퍼셉트론의 차이는 단층 퍼셉트론은 입력층과 출력층만 존재하지만, 다층 퍼셉트론은 중간에 층을 더 추가하였다는 점입니다.\n",
    "이렇게 입력층과 출력층 사이에 존재하는 층을 은닉층(hidden layer)이라고 합니다.\n",
    "즉, 다층 퍼셉트론은 중간에 은닉층이 존재한다는 점이 단층 퍼셉트론과 다릅니다. 다층 퍼셉트론은 줄여서 MLP라고도 부릅니다.\n",
    "\n",
    "![그림](img_14.png)\n",
    "\n",
    "위의 그림은 AND, NAND, OR 게이트를 조합하여 XOR 게이트를 구현한 다층 퍼셉트론의 예입니다.\n",
    "XOR 예제에서는 은닉층 1개만으로 문제를 해결할 수 있었지만, 다층 퍼셉트론은 본래 은닉층이 1개 이상인 퍼셉트론을 말합니다.\n",
    "즉, XOR 문제나 기타 복잡한 문제를 해결하기 위해서 다층 퍼셉트론은 중간에 수많은 은닉층을 더 추가할 수 있습니다.\n",
    "은닉층의 개수는 2개일 수도 있고, 수십 개일수도 있고 사용자가 설정하기 나름입니다.\n",
    "아래는 더 어려운 문제를 풀기 위해서 은닉층이 하나 더 추가되고(이 경우에는 은닉층이 2개), 뉴런의 개수를 늘린 다층 퍼셉트론의 모습을 보여줍니다.\n",
    "\n",
    "![그림](img_15.png)\n",
    "\n",
    "위와 같이 은닉층이 2개 이상인 신경망을 심층 신경망(Deep Neural Network, DNN) 이라고 합니다.\n",
    "심층 신경망은 다층 퍼셉트론만 이야기 하는 것이 아니라, 여러 변형된 다양한 신경망들도 은닉층이 2개 이상이 되면 심층 신경망이라고 합니다.\n",
    "\n",
    "지금까지는 OR, AND, XOR 게이트 등. 퍼셉트론이 제대로 된 정답을 출력할 때까지 저자가 직접 가중치를 바꿔보면서 적절한 가중치를 수동으로 찾았습니다.\n",
    "하지만 이제는 기계가 가중치를 스스로 찾아내도록 자동화시켜야하는데, 이것이 머신 러닝에서 말하는 훈련(training) 또는 학습(learning) 단계에 해당됩니다.\n",
    "앞서 선형 회귀와 로지스틱 회귀에서 보았듯이 손실 함수(Loss function)와 옵티마이저(Optimizer)를 사용합니다.\n",
    "그리고 만약 학습을 시키는 인공 신경망이 심층 신경망일 경우에는 이를 심층 신경망을 학습시킨다고 하여, 딥 러닝(Deep Learning)이라고 합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da25fcd2fb6735c2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def AND_gate(x1, x2):\n",
    "    w1 = 0.5\n",
    "    w2 = 0.5\n",
    "    b = -0.7\n",
    "    result = x1*w1 + x2*w2 + b\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def NAND_gate(x1, x2):\n",
    "    w1 = -0.5\n",
    "    w2 = -0.5\n",
    "    b = 0.7\n",
    "    result = x1*w1 + x2*w2 + b\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1    \n",
    "    \n",
    "def OR_gate(x1, x2):\n",
    "    w1 = 0.6\n",
    "    w2 = 0.6\n",
    "    b = -0.5\n",
    "    result = x1*w1 + x2*w2 + b\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "# def XOR_gate_1(x1, x2):\n",
    "#     s1 = OR_gate(x1, x2)\n",
    "#     s2 = NAND_gate(x1, x2)\n",
    "#     if x1 == 1 and x2 == 1:\n",
    "#         return s2\n",
    "#     else:\n",
    "#         return s1\n",
    "#     \n",
    "# def XOR_gate_2(x1, x2):\n",
    "#     s1 = OR_gate(x1, x2)\n",
    "#     s2 = NAND_gate(x1, x2)\n",
    "#     if x1 & x2 == 1:\n",
    "#         return s2\n",
    "#     else:\n",
    "#         return s1\n",
    "    \n",
    "def XOR_gate(x1, x2):\n",
    "    s1 = NAND_gate(x1, x2)\n",
    "    s2 = OR_gate(x1, x2)\n",
    "    y = AND_gate(s1, s2)\n",
    "    return y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T08:37:46.978743100Z",
     "start_time": "2024-01-30T08:37:46.965406Z"
    }
   },
   "id": "2195c32d082cfd7c",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(0, 1, 1, 0)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XOR_gate_1(0, 0), XOR_gate_1(0, 1), XOR_gate_1(1, 0), XOR_gate_1(1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T08:06:18.020091600Z",
     "start_time": "2024-01-25T08:06:18.014059700Z"
    }
   },
   "id": "d8308f05bca6319a",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(0, 1, 1, 0)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XOR_gate_2(0, 0), XOR_gate_2(0, 1), XOR_gate_2(1, 0), XOR_gate_2(1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T08:06:19.235160100Z",
     "start_time": "2024-01-25T08:06:19.228914400Z"
    }
   },
   "id": "c0b561f811716c84",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(0, 1, 1, 0)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XOR_gate(0, 0), XOR_gate(0, 1), XOR_gate(1, 0), XOR_gate(1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T08:37:49.123368600Z",
     "start_time": "2024-01-30T08:37:49.117426Z"
    }
   },
   "id": "7635e15a779c10ac",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 07-02 인공 신경망(Artificial Neural Network) 훑어보기\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1add636e2dc75e58"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. 피드 포워드 신경망(Feed-Forward Neural Network, FFNN)\n",
    "***\n",
    "\n",
    "![그림](img_16.png)\n",
    "\n",
    "위 그림의 다층 퍼셉트론(MLP)과 같이 오직 입력층에서 출력층 방향으로 연산이 전개되는 신경망을 피드 포워드 신경망(Feed-Forward Neural Network, FFNN)이라고 합니다.\n",
    "\n",
    "![그림](img_17.png)\n",
    "\n",
    "위의 그림은 FFNN에 속하지 않는 RNN이라는 신경망을 보여줍니다.\n",
    "이 신경망은 은닉층의 출력값을 출력층으로도 값을 보내지만, 동시에 은닉층의 출력값이 다시 은닉층의 입력으로 사용됩니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9c09f9fd1f848a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. 전결합층(Fully-connected layer, FC, Dense layer)\n",
    "***\n",
    "\n",
    "다층 퍼셉트론은 은닉층과 출력층에 있는 모든 뉴런은 바로 이전 층의 모든 뉴런과 연결돼 있었습니다.\n",
    "그와 같이 어떤 층의 모든 뉴런이 이전 층의 모든 뉴런과 연결돼 있는 층을 전결합층(Fully-connected layer) 또는 완전연결층이라고 합니다.\n",
    "줄여서 FC라고 부르기도 합니다. 앞서 본 다층 퍼셉트론의 모든 은닉층과 출력층은 전결합층입니다.\n",
    "동일한 의미로 밀집층(Dense layer) 이라고 부르기도 하는데, 케라스에서는 밀집층을 구현할 때 Dense()를 사용합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e644ec60a4dace0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. 활성화 함수(Activation Function)\n",
    "***\n",
    "\n",
    "![그림](img_18.png)\n",
    "\n",
    "앞서 배운 퍼셉트론에서는 계단 함수(Step function)를 통해 출력값이 0이 될지, 1이 될지를 결정했습니다.\n",
    "이러한 매커니즘은 실제 뇌를 구성하는 신경 세포 뉴런이 전위가 일정치 이상이 되면 시냅스가 서로 화학적으로 연결되는 모습을 모방한 것입니다.\n",
    "이렇게 은닉층과 출력층의 뉴런에서 출력값을 결정하는 함수를 활성화 함수(Activation function)라고 하는데 계단 함수는 이러한 활성화 함수의 하나의 예제에 불과합니다.\n",
    "\n",
    "다양한 활성화 함수에 대해서 정리해봅시다. 일부는 머신 러닝 챕터에서 이미 봤던 함수들입니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45baa401377e414c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (1) 활성화 함수의 특징 - 비선형 함수(Nonlinear function)\n",
    "\n",
    "활성화 함수의 특징은 선형 함수가 아닌 비선형 함수여야 한다는 점입니다. 선형 함수란 출력이 입력의 상수배만큼 변하는 함수를 선형함수라고 합니다.\n",
    "예를 들어 $f(x) = wx + b$라는 함수가 있을 때, $w$와 $b$는 상수입니다.\n",
    "이 식을 그래프로 시각화하면 직선입니다. 반대로 비선형 함수는 직선 1개로는 그릴 수 없는 함수를 말합니다.\n",
    "\n",
    "인공 신경망에서 활성화 함수는 비선형 함수여야 합니다.\n",
    "앞서 퍼셉트론에서도 계단 함수라는 활성화 함수를 사용했는데 계단 함수 또한 비선형 함수에 속합니다.\n",
    "인공 신경망의 능력을 높이기 위해서는 은닉층을 계속해서 추가해야 합니다.\n",
    "그런데 만약 활성화 함수로 선형 함수를 사용하게 되면 은닉층을 쌓을 수가 없습니다.\n",
    "예를 들어 활성화 함수로 선형 함수를 선택하고, 층을 계속 쌓는다고 가정해보겠습니다.\n",
    "활성화 함수는 $f(x) = wx$라고 가정합니다.\n",
    "여기다가 은닉층을 두 개 추가한다고하면 출력층을 포함해서 $y(x) = f(f(f(x)))$가 됩니다.\n",
    "이를 식으로 표현하면 $w \\times w \\times w \\times w$입니다.\n",
    "그런데 이는 잘 생각해보면 $w$의 세 제곱값을 $k$라고 정의해버리면 $y(x) = kx$와 같이 다시 표현이 가능합니다.\n",
    "이 경우, 선형 함수로 은닉층을 여러번 추가하더라도 1회 추가한 것과 차이가 없음을 알 수 있습니다.\n",
    "\n",
    "활성화 함수가 존재하지 않는 선형 함수 층을 사용하지 않는다는 의미는 아닙니다.\n",
    "종종 활성화 함수를 사용하지 않는 층을 비선형 층들과 함께 인공 신경망의 일부로서 추가하는 경우도 있는데, 학습 가능한 가중치가 새로 생긴다는 점에서 의미가 있습니다.\n",
    "이와 같이 선형 함수를 사용한 층을 활성화 함수를 사용하는 은닉층과 구분하기 위해서 이 책에서는 선형층(linear layer)이나 투사층(projection layer) 등의 다른 표현을 사용하여 표현합니다.\n",
    "뒤의 챕터에서 언급할 임베딩 층(embedding layer)도 일종의 선형층입니다. 임베딩 층에는 활성화 함수가 존재하지 않습니다.\n",
    "활성화 함수를 사용하는 일반적인 은닉층을 선형층과 대비되는 표현을 사용하면 비선형층(nonlinear layer)입니다.\n",
    "\n",
    "파이썬을 통해 주로 사용되는 활성화 함수를 직접 그려봅시다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e62013949b9dd5f5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T07:03:20.126538Z",
     "start_time": "2024-01-26T07:03:20.117954Z"
    }
   },
   "id": "753b5d062b7bdbbb",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (2) 계단 함수(Step function)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cfdf51370ac3c14"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGxCAYAAACwbLZkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAq7ElEQVR4nO3df3SU5Z338c8kgUmUJD4kMoCEEBAKGhVJKgWJgD/CIrLFoxBrD4iFHrOLIkRdDOyKcnw2u7Qi648gLCBrpZqDVJdtUyXrKmKhfYAG2wrq+ouAJMRkuxmkmjgz9/MHzMCQBDLhx31lrvfrnDmnubhn5ps5vScfv/d1XbfHcRxHAAAALklwuwAAAGA3wggAAHAVYQQAALiKMAIAAFxFGAEAAK4ijAAAAFcRRgAAgKsIIwAAwFWEEQAA4CrCCNBF/O53v9Ott96q/v37y+v1yufzadSoUXrggQeijisvL9e6devcKfIYj8fT5iMzM9PVuvbs2aNHH31Un3/+eat/mzlzpgYMGHDeawIgedgOHjDfr371K/31X/+1xo0bpx//+Mfq06ePamtrtXPnTr388ss6cOBA5Njc3FxlZmbq7bffdq1ej8ej22+/vVVQ6tatm/Ly8lyqSnrllVc0depUvfXWWxo3blzUv33yySfy+/26+uqr3SkOsFiS2wUAOL2lS5cqJydHb7zxhpKSjp+2d9xxh5YuXepiZe3z+Xz63ve+53YZHTZo0CC3SwCsxWUaoAtobGxUZmZmVBAJS0g4fhoPGDBA77//vrZs2RK5NHLipQe/368HH3xQOTk56t69uy655BLNmzdPR44ciXpNj8eje++9VytXrtSQIUPk9Xp12WWX6eWXXz4rv097l0QeffRReTyeNmv52c9+pmHDhumCCy7QVVddpV/+8petnv/BBx/oBz/4gXw+n7xer/r3768ZM2aoublZ69at09SpUyVJ48ePj3w+4UtabdX0zTffqLS0NOrzmjNnjv73f/836rgBAwbolltu0euvv64RI0YoJSVFQ4cO1dq1azv9GQE2oTMCdAGjRo3S6tWrNXfuXP3whz/UiBEj1K1bt1bHvfrqq7r99tuVnp6u8vJySZLX65Uk/eUvf9HYsWN14MABLVy4UFdeeaXef/99PfLII/rjH/+o//zP/4wKAps2bdJbb72lJUuW6MILL1R5ebl+8IMfKCkpSbfffvtpa3YcR4FAIGosMTGxVdjoiF/96lfasWOHlixZoh49emjp0qW69dZb9eGHH2rgwIGSpPfee09jxoxRZmamlixZosGDB6u2tlabNm1SS0uLJk2apH/8x3/UwoUL9eyzz2rEiBGS2u+IOI6jKVOm6M0331RpaakKCgr0hz/8QYsXL9b27du1ffv2yGcbfv8HHnhADz/8sHw+n1avXq1Zs2bp0ksv1XXXXRfz7wxYxQFgvIaGBmfMmDGOJEeS061bN2f06NFOWVmZc/jw4ahjL7/8cmfs2LGtXqOsrMxJSEhwduzYETX+yiuvOJKcysrKyJgkJyUlxamrq4uMBQIBZ+jQoc6ll1562nrDdZ78+Nd//VfHcRznrrvucrKzs1s9b/Hixc7JX0uSHJ/P5/j9/shYXV2dk5CQ4JSVlUXGrr/+eueiiy5y6uvr261rw4YNjiTnrbfeavVvJ9f0+uuvO5KcpUuXRh1XUVHhSHJWrVoVGcvOznaSk5Odffv2Rca+/vprp2fPns4999zTbj0AjuIyDdAFZGRkaOvWrdqxY4f+6Z/+Sd///vf10UcfqbS0VFdccYUaGhpO+xq//OUvlZubq+HDhysQCEQeEyZMkMfjaTXh9YYbbpDP54v8nJiYqKKiIn388cdRE2bbM23aNO3YsSPqMWXKlFh/dUlHL6ukpqZGfvb5fOrVq5f27dsn6WjXZ8uWLZo2bZouvvjiTr3Hyf7rv/5L0tHLNyeaOnWqLrzwQr355ptR48OHD1f//v0jPycnJ2vIkCGRGgG0j8s0QBeSn5+v/Px8SdK3336rBQsW6Mknn9TSpUtPO5H10KFD+vjjj9u8vCOpVaDp3bt3q2PCY42NjerXr98p3+/iiy+O1HqmMjIyWo15vV59/fXXkqQ///nPCgaDp60pFo2NjUpKSmoVbjwej3r37q3GxsaYagTQPsII0EV169ZNixcv1pNPPqk//elPpz0+MzNTKSkp7U6qPHkPkLq6ulbHhMfa+sMbi+TkZDU3N7ca70iHpy09e/ZUYmJihzo2HZWRkaFAIKAvv/wyKpA4jqO6ujp997vfPWvvBdiOyzRAF1BbW9vm+N69eyVJffv2jYy191/jt9xyiz755BNlZGREOiwnPk5eSfLmm2/q0KFDkZ+DwaAqKio0aNCgM+5ADBgwQPX19VGv39LSojfeeKNTr5eSkqKxY8dqw4YNpww04QmnHelW3HDDDZKkF198MWp848aNOnLkSOTfAZw5OiNAFzBhwgT169dPkydP1tChQxUKhbR792498cQT6tGjh+6///7IsVdccYVefvllVVRUaODAgUpOTtYVV1yhefPmaePGjbruuus0f/58XXnllQqFQqqpqdHmzZv1wAMPaOTIkZHXyczM1PXXX69/+Id/iKym+eCDD87K8t6ioiI98sgjuuOOO/TQQw/pm2++0VNPPaVgMNjp11y2bJnGjBmjkSNH6uGHH9all16qQ4cOadOmTVq5cqVSU1OVm5srSVq1apVSU1OVnJysnJycNjs9N910kyZMmKAFCxbI7/fr2muvjaymufrqqzV9+vRO1wrgJG7PoAVwehUVFc6dd97pDB482OnRo4fTrVs3p3///s706dOdPXv2RB37+eefO4WFhU5qaqojKWqFyFdffeX8/d//vfOd73zH6d69u5Oenu5cccUVzvz586NWzkhy5syZ45SXlzuDBg1yunXr5gwdOtRZv359h+oNP/9UKisrneHDhzspKSnOwIEDnWeeeabd1TRtvVZ2drZz1113RY3t2bPHmTp1qpORkeF0797d6d+/vzNz5kznm2++iRyzfPlyJycnx0lMTHQkOc8//7zjOG2v8Pn666+dBQsWONnZ2U63bt2cPn36OH/zN3/j/PnPf25Vy6RJk1rVOHbs2DZXNgGIxnbwAFrxeDyaM2eOnnnmGbdLAWAB5owAAABXEUYAAICrmMAKoBWu3gI4n+iMAAAAVxFGAACAqwgjAADAVV1izkgoFNLBgweVmpraqduPAwCA889xHB0+fFh9+/ZVQkL7/Y8uEUYOHjyorKwst8sAAACdsH///lPeRqJLhJHwrcP379+vtLQ0l6sBAAAd4ff7lZWVFfk73p4uEUbCl2bS0tIIIwAAdDGnm2LBBFYAAOAqwggAAHAVYQQAALiKMAIAAFxFGAEAAK4ijAAAAFcRRgAAgKsIIwAAwFWEEQAA4CrCCAAAcFXMYeSdd97R5MmT1bdvX3k8Hr322munfc6WLVuUl5en5ORkDRw4UM8991xnagUAAHEo5jBy5MgRXXXVVXrmmWc6dPxnn32mm2++WQUFBaqurtbChQs1d+5cbdy4MeZiAQBA/In5RnkTJ07UxIkTO3z8c889p/79+2v58uWSpGHDhmnnzp366U9/qttuu63N5zQ3N6u5uTnys9/vj7VMAF3cN98Gtebdz9TwVfPpDwZwxm4b0U+5l6S78t7n/K6927dvV2FhYdTYhAkTtGbNGn377bfq1q1bq+eUlZXpscceO9elATDY2x/W6ydvfOh2GYA1ru7/f+I3jNTV1cnn80WN+Xw+BQIBNTQ0qE+fPq2eU1paqpKSksjPfr9fWVlZ57pUAAbxfxOQJGVnXKBbrmz9PQHg7Brcq4dr733Ow4gkeTyeqJ8dx2lzPMzr9crr9Z7zugCYKxg6+j0xuFeqHpow1OVqAJxL53xpb+/evVVXVxc1Vl9fr6SkJGVkZJzrtwfQRYXDSCIbEABx75yf5qNGjVJVVVXU2ObNm5Wfn9/mfBEAkI6HkaQE0ggQ72I+y7/66ivt3r1bu3fvlnR06e7u3btVU1Mj6eh8jxkzZkSOLy4u1r59+1RSUqK9e/dq7dq1WrNmjR588MGz8xsAiEvhMJKQ0PblXADxI+Y5Izt37tT48eMjP4cnmt51111at26damtrI8FEknJyclRZWan58+fr2WefVd++ffXUU0+1u6wXAKQTOyOEESDexRxGxo0bF5mA2pZ169a1Ghs7dqx+//vfx/pWACwWPPY9k9DORHcA8YOLsQCMxARWwB6c5gCMdDyM8DUFxDvOcgBGCtAZAazBaQ7ASCGW9gLW4CwHYKRwZ4QJrED8I4wAMFLo2GqapETCCBDvCCMAjBSkMwJYgzACwEhsegbYgzACwEhsBw/YgzACwEgBOiOANQgjAIwUiuwzQhgB4h1hBICRAoQRwBqEEQBGCi/tTWQ1DRD3CCMAjERnBLAHYQSAkZgzAtiDMALASIFQSBJLewEbEEYAGCl4NIuwtBewAGEEgJGCxzojTGAF4h9hBICRgkenjDBnBLAAYQSAkSKdEcIIEPcIIwCMFGQ1DWANwggAIx1rjBBGAAsQRgAYKcBlGsAahBEARopMYGU1DRD3CCMAjBSZwJpIGAHiHWEEgJHCm57RGQHiH2EEgJHCnRF2YAXiH2EEgJHCS3u5Nw0Q/wgjAIwUDiN0RoD4RxgBYKSgQ2cEsAVhBICRgkE6I4AtCCMAjBTpjLCaBoh7hBEARuLeNIA9CCMAjMQEVsAehBEARgqwtBewBmEEgJFCdEYAaxBGABgp0hlhAisQ9wgjAIwUOraaJokb5QFxjzACwEiR1TR0RoC4RxgBYBzHcXQsi7C0F7AAYQSAccJdEYkwAtiAMALAOAHCCGAVwggA44Qnr0qEEcAGhBEAxqEzAtiFMALAOKETwwiraYC4RxgBYBw6I4BdCCMAjBOK7L4qeeiMAHGPMALAOOHOCF0RwA6EEQDGCRJGAKsQRgAYh63gAbsQRgAYJ+jQGQFsQhgBYBwu0wB2IYwAMM7xMMJXFGADznQAxjkeRlwuBMB5wakOwDjhMJJEZwSwAmc6AOOEJ7CSRQA7dOpULy8vV05OjpKTk5WXl6etW7ee8vj169frqquu0gUXXKA+ffro7rvvVmNjY6cKBhD/6IwAdon5TK+oqNC8efO0aNEiVVdXq6CgQBMnTlRNTU2bx7/77ruaMWOGZs2apffff18bNmzQjh07NHv27DMuHkB8Cp6wHTyA+BdzGFm2bJlmzZql2bNna9iwYVq+fLmysrK0YsWKNo//7W9/qwEDBmju3LnKycnRmDFjdM8992jnzp1nXDyA+ERnBLBLTGd6S0uLdu3apcLCwqjxwsJCbdu2rc3njB49WgcOHFBlZaUcx9GhQ4f0yiuvaNKkSe2+T3Nzs/x+f9QDgD0inRFaI4AVYgojDQ0NCgaD8vl8UeM+n091dXVtPmf06NFav369ioqK1L17d/Xu3VsXXXSRnn766Xbfp6ysTOnp6ZFHVlZWLGUC6OKOd0YII4ANOtUDPfmW3o7jtHub7z179mju3Ll65JFHtGvXLr3++uv67LPPVFxc3O7rl5aWqqmpKfLYv39/Z8oE0EXRGQHskhTLwZmZmUpMTGzVBamvr2/VLQkrKyvTtddeq4ceekiSdOWVV+rCCy9UQUGBHn/8cfXp06fVc7xer7xebyylAYgjATojgFVi6ox0795deXl5qqqqihqvqqrS6NGj23zOX/7yFyWcNAktMTFR0tGOCgCcLORw117AJjFfpikpKdHq1au1du1a7d27V/Pnz1dNTU3ksktpaalmzJgROX7y5Mn6xS9+oRUrVujTTz/Vb37zG82dO1fXXHON+vbte/Z+EwBxIxBi0zPAJjFdppGkoqIiNTY2asmSJaqtrVVubq4qKyuVnZ0tSaqtrY3ac2TmzJk6fPiwnnnmGT3wwAO66KKLdP311+uf//mfz95vASCuhFjaC1jF43SBayV+v1/p6elqampSWlqa2+UAOMde2XVAD254T9cNuVgv/Ogat8sB0Ekd/fvNf3YAME6ICayAVQgjAIwTmTPCBFbACoQRAMYJ37WXzghgB8IIAOOEL9MkEkYAKxBGABgnQBgBrEIYAWAcOiOAXQgjAIxDZwSwC2EEgHHYDh6wC2EEgHECwWNhJJEwAtiAMALAOEE6I4BVCCMAjBMMhSQxZwSwBWEEgHGCR7MIYQSwBGEEgHHojAB2IYwAMA6dEcAuhBEAxol0RpjACliBMALAOJHVNHRGACsQRgAYJ8gOrIBVCCMAjEMYAexCGAFgHCawAnYhjAAwTngCaxJhBLACYQSAcY7dmkYJrKYBrEAYAWCcSGeEG+UBViCMADBOeAIrnRHADoQRAMYJhxHmjAB2IIwAME6kM0IYAaxAGAFgnACdEcAqhBEAxgmxHTxgFcIIAOMEgoQRwCaEEQDGiXRGWE0DWIEwAsA4ASawAlYhjAAwTogJrIBVCCMAjENnBLALYQSAcdj0DLALYQSAccJhhAmsgB0IIwCME2SfEcAqhBEAxglPYCWMAHYgjAAwToAwAliFMALAOHRGALsQRgAYh84IYBfCCADjcKM8wC6EEQDGCbDPCGAVwggA44T3GUlgnxHACoQRAMY5vgMrX1GADTjTARgn0hnhGwqwAqc6AOPQGQHswpkOwDjh7eDJIoAdONUBGCUUcnQsi3CjPMAShBEARgl3RSQu0wC24EwHYJTwfBGJyzSALTjVARjlxDBCZwSwA2c6AKME6IwA1uFUB2CUEJ0RwDqc6QCMcuIEVm5NA9iBMALAKOE5I4kJHnlY2gtYgTACwCiRMEIQAaxBGAFglBM7IwDs0KkwUl5erpycHCUnJysvL09bt2495fHNzc1atGiRsrOz5fV6NWjQIK1du7ZTBQOIb4QRwD5JsT6hoqJC8+bNU3l5ua699lqtXLlSEydO1J49e9S/f/82nzNt2jQdOnRIa9as0aWXXqr6+noFAoEzLh5A/AkQRgDrxBxGli1bplmzZmn27NmSpOXLl+uNN97QihUrVFZW1ur4119/XVu2bNGnn36qnj17SpIGDBhwZlUDiFshhzAC2CamyzQtLS3atWuXCgsLo8YLCwu1bdu2Np+zadMm5efna+nSpbrkkks0ZMgQPfjgg/r666/bfZ/m5mb5/f6oBwA7BIKEEcA2MXVGGhoaFAwG5fP5osZ9Pp/q6urafM6nn36qd999V8nJyXr11VfV0NCgv/3bv9X//M//tDtvpKysTI899lgspQGIE5HOCKtpAGt0agLryWv/Hcdpdz+AUCgkj8ej9evX65prrtHNN9+sZcuWad26de12R0pLS9XU1BR57N+/vzNlAuiCmDMC2CemzkhmZqYSExNbdUHq6+tbdUvC+vTpo0suuUTp6emRsWHDhslxHB04cECDBw9u9Ryv1yuv1xtLaQDiBKtpAPvE1Bnp3r278vLyVFVVFTVeVVWl0aNHt/mca6+9VgcPHtRXX30VGfvoo4+UkJCgfv36daJkAPGMMALYJ+bLNCUlJVq9erXWrl2rvXv3av78+aqpqVFxcbGko5dYZsyYETn+zjvvVEZGhu6++27t2bNH77zzjh566CH96Ec/UkpKytn7TQDEBcIIYJ+Yl/YWFRWpsbFRS5YsUW1trXJzc1VZWans7GxJUm1trWpqaiLH9+jRQ1VVVbrvvvuUn5+vjIwMTZs2TY8//vjZ+y0AxA22gwfs43GcE26RaSi/36/09HQ1NTUpLS3N7XIAnENbPvpSd639f7qsT5oq7y9wuxwAZ6Cjf7+5Nw0Ao4S4TANYhzACwCgs7QXsQxgBYBQmsAL2IYwAMAphBLAPYQSAUYJsBw9YhzACwCjBUEiSlJRIGAFsQRgBYJTg0SyiBDojgDUIIwCMEumMMGcEsAZhBIBRIp0RwghgDcIIAKPQGQHsQxgBYJTw0l46I4A9CCMAjBLgRnmAdQgjAIwSOrbPCJdpAHsQRgAYJcBlGsA6hBEARgnftZfOCGAPwggAo9AZAexDGAFgFDojgH0IIwCMEr5RHtvBA/YgjAAwSoDOCGAdwggAo4Qv0yQSRgBrEEYAGCVAGAGsQxgBYBQ6I4B9CCMAjEJnBLAPYQSAUcLbwXNvGsAehBEARgkEj4WRRMIIYAvCCACjBOmMANYhjAAwSpA5I4B1CCMAjEIYAexDGAFgFMIIYB/CCACjEEYA+xBGABglEkaYwApYgzACwCiR1TR0RgBrEEYAGIXLNIB9CCMAjEIYAexDGAFgFMIIYB/CCACjhMNIEmEEsAZhBIBRwhNYE1hNA1iDMALAKJHOCDfKA6xBGAFglHAYoTMC2IMwAsAox+eM8PUE2IKzHYBRIp0Rvp0Aa3C6AzAKnRHAPpztAIxyfDt4lwsBcN5wugMwSiDIBFbANoQRAEYJOVymAWzD2Q7AKAEmsALW4XQHYJQQE1gB63C2AzBKIMQEVsA2nO4AjBKKhBG+ngBbcLYDMEpkaS+raQBrEEYAGCVymYYb5QHWIIwAMErkMg2dEcAahBEARjk+gZUwAtiCMALAGOGuiEQYAWxCGAFgjABhBLASYQSAMcJbwUuEEcAmnQoj5eXlysnJUXJysvLy8rR169YOPe83v/mNkpKSNHz48M68LYA4d2JnJIkwAlgj5jBSUVGhefPmadGiRaqurlZBQYEmTpyompqaUz6vqalJM2bM0A033NDpYgHEt+AJYYS79gL2iDmMLFu2TLNmzdLs2bM1bNgwLV++XFlZWVqxYsUpn3fPPffozjvv1KhRozpdLID4FmTOCGClmMJIS0uLdu3apcLCwqjxwsJCbdu2rd3nPf/88/rkk0+0ePHiDr1Pc3Oz/H5/1ANA/IvujLhYCIDzKqYw0tDQoGAwKJ/PFzXu8/lUV1fX5nP++7//Ww8//LDWr1+vpKSkDr1PWVmZ0tPTI4+srKxYygTQRQVP2GPEw2UawBqdmsB68peE4zhtfnEEg0HdeeedeuyxxzRkyJAOv35paamampoij/3793emTABdTOS+NLRFAKt0rFVxTGZmphITE1t1Qerr61t1SyTp8OHD2rlzp6qrq3XvvfdKkkKhkBzHUVJSkjZv3qzrr7++1fO8Xq+8Xm8spQGIA8EgW8EDNoqpM9K9e3fl5eWpqqoqaryqqkqjR49udXxaWpr++Mc/avfu3ZFHcXGxvvOd72j37t0aOXLkmVUPIK6EOyMs6wXsElNnRJJKSko0ffp05efna9SoUVq1apVqampUXFws6eglli+++EIvvPCCEhISlJubG/X8Xr16KTk5udU4AITnjCQQRgCrxBxGioqK1NjYqCVLlqi2tla5ubmqrKxUdna2JKm2tva0e44AQFvCYYTOCGAXj+OcsP+yofx+v9LT09XU1KS0tDS3ywFwjuw56NfNT23Vxale7Vh0o9vlADhDHf37zb1pABiDzghgJ8IIAGOEJ7CyFTxgF8IIAGMEQyFJUlIiYQSwCWEEgDGCR7MI+4wAliGMADBG4FhnhB1YAbsQRgAYIxTujBBGAKsQRgAYg84IYCfCCABjhLhRHmAlwggAYwSCLO0FbEQYAWCMEDfKA6xEGAFgjAA3ygOsRBgBYAy2gwfsRBgBYIxwGGECK2AXwggAYxBGADsRRgAYI7K0l9U0gFUIIwCMEaAzAliJMALAGCHCCGAlwggAY9AZAexEGAFgDCawAnYijAAwBmEEsBNhBIAxgqymAaxEGAFgjOCxG+UlJRJGAJsQRgAYI9wZ4a69gF0IIwCMwZwRwE6EEQDGIIwAdiKMADBGJIxwmQawCmEEgDEiYYQJrIBVCCMAjBGgMwJYiTACwBjhu/YmMWcEsAphBIAxwpdpEggjgFUIIwCMEQ4jdEYAuxBGABiDzghgJ8IIAGPQGQHsRBgBYAy2gwfsRBgBYIwAnRHASoQRAMYIsR08YCXCCABjRDY9S+CrCbAJZzwAYxzvjLhcCIDzilMegDHojAB24owHYIzwdvB0RgC7cMoDMEYgyNJewEaEEQDGCEZulMdXE2ATzngAxggygRWwEqc8AGMEmcAKWIkzHoAx6IwAduKUB2AMOiOAnTjjARgjsrSX1TSAVQgjAIwR4N40gJUIIwCMwY3yADsRRgAYg84IYCfCCABjBAkjgJUIIwCMEQ4jSYQRwCqEEQDGCG8Hz71pALsQRgAYI9IZSSSMADYhjAAwRjiM0BkB7EIYAWAMJrACdupUGCkvL1dOTo6Sk5OVl5enrVu3tnvsL37xC9100026+OKLlZaWplGjRumNN97odMEA4hcTWAE7xRxGKioqNG/ePC1atEjV1dUqKCjQxIkTVVNT0+bx77zzjm666SZVVlZq165dGj9+vCZPnqzq6uozLh5AfIlcpiGMAFbxOM6x6esdNHLkSI0YMUIrVqyIjA0bNkxTpkxRWVlZh17j8ssvV1FRkR555JEOHe/3+5Wenq6mpialpaXFUi6ALmTQwkoFQ45+t/AG+dKS3S4HwBnq6N/vmDojLS0t2rVrlwoLC6PGCwsLtW3btg69RigU0uHDh9WzZ892j2lubpbf7496AIhvjuMwgRWwVExhpKGhQcFgUD6fL2rc5/Oprq6uQ6/xxBNP6MiRI5o2bVq7x5SVlSk9PT3yyMrKiqVMAF1Q6IQeLXNGALt0agKr56T/anEcp9VYW1566SU9+uijqqioUK9evdo9rrS0VE1NTZHH/v37O1MmgC4kEApF/jdzRgC7JMVycGZmphITE1t1Qerr61t1S05WUVGhWbNmacOGDbrxxhtPeazX65XX642lNABd3AlZhM4IYJmYOiPdu3dXXl6eqqqqosarqqo0evTodp/30ksvaebMmfr5z3+uSZMmda5SAHEteMJcevYZAewSU2dEkkpKSjR9+nTl5+dr1KhRWrVqlWpqalRcXCzp6CWWL774Qi+88IKko0FkxowZ+pd/+Rd973vfi3RVUlJSlJ6efhZ/FQBdWTBIGAFsFXMYKSoqUmNjo5YsWaLa2lrl5uaqsrJS2dnZkqTa2tqoPUdWrlypQCCgOXPmaM6cOZHxu+66S+vWrTvz3wBAXIjqjLCaBrBKzPuMuIF9RoD4V3/4G13zf9+UxyN9VsblXCAenJN9RgDgXAlPYKUrAtiHMALACOGlvcwXAexDGAFghEhnhDACWIcwAsAIdEYAexFGABghdGwuPWEEsA9hBIARAsduTsMEVsA+hBEARgjfsZfOCGAfwggAIxBGAHsRRgAYgTAC2IswAsAIhBHAXoQRAEYgjAD2IowAMEL4RnmspgHsQxgBYAQ6I4C9CCMAjEAYAexFGAFghHAYSSKMANYhjAAwQjiMJBBGAOsQRgAYgc4IYC/CCAAjhFfTJLCaBrAOYQSAESKdkUTCCGAbwggAI0TmjNAZAaxDGAFghABzRgBrEUYAGCHEPiOAtQgjAIwQ4DINYC3CCAAjhBwmsAK2IowAMEIgSGcEsBVhBIARIp0R5owA1iGMADBCgO3gAWsRRgAYge3gAXsRRgAYgaW9gL0IIwCMECCMANYijAAwQngCayKraQDrEEYAGOF4Z4SvJcA2nPUAjHB8zojLhQA47zjtARiBzghgL856AEYI0hkBrMVpD8AIQTojgLU46wEYIchqGsBahBEARggGuUwD2IrTHoARIp0RLtMA1uGsB2AEJrAC9uK0B2AEJrAC9uKsB2CESBhh/ipgHcIIACNEwgjXaQDrcNYDMAJLewF7EUYAGCHcGUlKIIwAtiGMADBCOIwkEEYA6xBGABiBzghgL8IIACPQGQHsRRgBYAQ6I4C9CCMAjBBeTZPAahrAOoQRAEYI0BkBrEUYAWCEUGQ7eMIIYBvCCAAjBAgjgLUIIwCMQGcEsBdhBIARAqGQJCawAjYijAAwwrHGiJK4bS9gHcIIACPQGQHs1akwUl5erpycHCUnJysvL09bt2495fFbtmxRXl6ekpOTNXDgQD333HOdKhZA/DqWRVjaC1go5jBSUVGhefPmadGiRaqurlZBQYEmTpyompqaNo//7LPPdPPNN6ugoEDV1dVauHCh5s6dq40bN55x8QDiR7gzwgRWwD4exzm27WEHjRw5UiNGjNCKFSsiY8OGDdOUKVNUVlbW6vgFCxZo06ZN2rt3b2SsuLhY7733nrZv397mezQ3N6u5uTnys9/vV1ZWlpqampSWlhZLuae0cdcB/elg01l7PQCd9/L/26+vvw3q1/cXaFifs3eeA3CP3+9Xenr6af9+J8Xyoi0tLdq1a5cefvjhqPHCwkJt27atzeds375dhYWFUWMTJkzQmjVr9O2336pbt26tnlNWVqbHHnssltI6ZctHX2rTewfP+fsA6Li0lNbfCQDiW0xhpKGhQcFgUD6fL2rc5/Oprq6uzefU1dW1eXwgEFBDQ4P69OnT6jmlpaUqKSmJ/BzujJxtN13mU1bPlLP+ugA6Z4gvVZdcxDkJ2CamMBLmOWm2u+M4rcZOd3xb42Fer1der7czpcVk8lV9Nfmqvuf8fQAAQPtimsCamZmpxMTEVl2Q+vr6Vt2PsN69e7d5fFJSkjIyMmIsFwAAxJuYwkj37t2Vl5enqqqqqPGqqiqNHj26zeeMGjWq1fGbN29Wfn5+m/NFAACAXWJe2ltSUqLVq1dr7dq12rt3r+bPn6+amhoVFxdLOjrfY8aMGZHji4uLtW/fPpWUlGjv3r1au3at1qxZowcffPDs/RYAAKDLinnOSFFRkRobG7VkyRLV1tYqNzdXlZWVys7OliTV1tZG7TmSk5OjyspKzZ8/X88++6z69u2rp556SrfddtvZ+y0AAECXFfM+I27o6DplAABgjo7+/ebeNAAAwFWEEQAA4CrCCAAAcBVhBAAAuIowAgAAXEUYAQAAriKMAAAAVxFGAACAqzp1197zLbwvm9/vd7kSAADQUeG/26fbX7VLhJHDhw9LkrKyslyuBAAAxOrw4cNKT09v99+7xHbwoVBIBw8eVGpqqjwej9vluM7v9ysrK0v79+9ne/xzjM/6/OGzPn/4rM8f2z9rx3F0+PBh9e3bVwkJ7c8M6RKdkYSEBPXr18/tMoyTlpZm5f+53cBnff7wWZ8/fNbnj82f9ak6ImFMYAUAAK4ijAAAAFcRRrogr9erxYsXy+v1ul1K3OOzPn/4rM8fPuvzh8+6Y7rEBFYAABC/6IwAAABXEUYAAICrCCMAAMBVhBEAAOAqwggAAHAVYSRONDc3a/jw4fJ4PNq9e7fb5cSdzz//XLNmzVJOTo5SUlI0aNAgLV68WC0tLW6XFjfKy8uVk5Oj5ORk5eXlaevWrW6XFHfKysr03e9+V6mpqerVq5emTJmiDz/80O2yrFBWViaPx6N58+a5XYqRCCNx4u/+7u/Ut29ft8uIWx988IFCoZBWrlyp999/X08++aSee+45LVy40O3S4kJFRYXmzZunRYsWqbq6WgUFBZo4caJqamrcLi2ubNmyRXPmzNFvf/tbVVVVKRAIqLCwUEeOHHG7tLi2Y8cOrVq1SldeeaXbpRiLfUbiwK9//WuVlJRo48aNuvzyy1VdXa3hw4e7XVbc+8lPfqIVK1bo008/dbuULm/kyJEaMWKEVqxYERkbNmyYpkyZorKyMhcri29ffvmlevXqpS1btui6665zu5y49NVXX2nEiBEqLy/X448/ruHDh2v58uVul2UcOiNd3KFDh/TjH/9YP/vZz3TBBRe4XY5Vmpqa1LNnT7fL6PJaWlq0a9cuFRYWRo0XFhZq27ZtLlVlh6amJkni/8fn0Jw5czRp0iTdeOONbpditC5x1160zXEczZw5U8XFxcrPz9fnn3/udknW+OSTT/T000/riSeecLuULq+hoUHBYFA+ny9q3Ofzqa6uzqWq4p/jOCopKdGYMWOUm5vrdjlx6eWXX9bvf/977dixw+1SjEdnxECPPvqoPB7PKR87d+7U008/Lb/fr9LSUrdL7rI6+lmf6ODBg/qrv/orTZ06VbNnz3ap8vjj8XiifnYcp9UYzp57771Xf/jDH/TSSy+5XUpc2r9/v+6//369+OKLSk5Odrsc4zFnxEANDQ1qaGg45TEDBgzQHXfcof/4j/+I+sIOBoNKTEzUD3/4Q/3bv/3buS61y+voZx3+Mjl48KDGjx+vkSNHat26dUpIIM+fqZaWFl1wwQXasGGDbr311sj4/fffr927d2vLli0uVhef7rvvPr322mt65513lJOT43Y5cem1117TrbfeqsTExMhYMBiUx+NRQkKCmpubo/7NdoSRLqympkZ+vz/y88GDBzVhwgS98sorGjlypPr16+didfHniy++0Pjx45WXl6cXX3yRL5KzaOTIkcrLy1N5eXlk7LLLLtP3v/99JrCeRY7j6L777tOrr76qt99+W4MHD3a7pLh1+PBh7du3L2rs7rvv1tChQ7VgwQIujZ2EOSNdWP/+/aN+7tGjhyRp0KBBBJGz7ODBgxo3bpz69++vn/70p/ryyy8j/9a7d28XK4sPJSUlmj59uvLz8zVq1CitWrVKNTU1Ki4udru0uDJnzhz9/Oc/17//+78rNTU1MicnPT1dKSkpLlcXX1JTU1sFjgsvvFAZGRkEkTYQRoAO2Lx5sz7++GN9/PHHrYIezcUzV1RUpMbGRi1ZskS1tbXKzc1VZWWlsrOz3S4troSXTo8bNy5q/Pnnn9fMmTPPf0HAMVymAQAArmL2HQAAcBVhBAAAuIowAgAAXEUYAQAAriKMAAAAVxFGAACAqwgjAADAVYQRAADgKsIIAABwFWEEAAC4ijACAABc9f8BOPXuSnmHD38AAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def step(x):\n",
    "    return np.array(x > 0, dtype=int) # 0보다 크면 1 return \n",
    "x = np.arange(-5.0, 5.0, 0.1) # -5.0부터 5.0까지 0.1 간격 생성\n",
    "y = step(x)\n",
    "plt.title('Step Function')\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T07:03:56.344707400Z",
     "start_time": "2024-01-26T07:03:56.148176Z"
    }
   },
   "id": "36965ce04a22803d",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "계단 함수는 거의 사용되지 않지만 퍼셉트론을 통해 인공 신경망을 처음 배울 때 접하게 되는 활성화 함수입니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f56e78368ecfa974"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (3) 시그모이드 함수(Sigmoid function)와 기울기 소실\n",
    "\n",
    "시그모이드 함수를 사용한 인공 신경망이 있다고 가정해보겠습니다.\n",
    "\n",
    "![그림](img_19.png)\n",
    "\n",
    "위 인공 신경망의 학습 과정은 다음과 같습니다.\n",
    "우선 인공 신경망은 입력에 대해서 순전파(forward propagation) 연산을 하고,\n",
    "그리고 순전파 연산을 통해 나온 예측값과 실제값의 오차를 손실 함수(loss function)을 통해 계산하고,\n",
    "그리고 이 손실(오차라고도 부릅니다. loss)을 미분을 통해서 기울기(gradient)를 구하고,\n",
    "이를 통해 출력층에서 입력층 방향으로 가중치와 편향을 업데이트 하는 과정인 역전파(back propagation)를 수행합니다.\n",
    "역전파에 대해서는 뒤에서 더 자세히 설명하겠지만 일단 여기에서는 인공 신경망에서 출력층에서 입력층 방향으로 가중치와 편향을 업데이트 하는 과정이라고만 언급해두겠습니다.\n",
    "역전파 과정에서 인공 신경망은 경사 하강법을 사용합니다.\n",
    "\n",
    "이 시그모이드 함수의 문제점은 미분을 해서 기울기(gradient)를 구할 때 발생합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96f0356932b9e160"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시그모이드 함수 그래프를 그리는 코드\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = sigmoid(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가\n",
    "plt.title('Sigmoid Function')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T07:19:53.637659500Z",
     "start_time": "2024-01-26T07:19:53.522540700Z"
    }
   },
   "id": "efdcd9f6f4df6a17",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "위 그래프는 시그모이드 함수의 그래프를 보여줍니다.\n",
    "시그모이드 함수의 출력값이 0 또는 1에 가까워지면, 그래프의 기울기가 완만해지는 모습을 볼 수 있습니다.\n",
    "기울기가 완만해지는 구간을 주황색, 그렇지 않은 구간을 초록색으로 칠해보겠습니다.\n",
    "\n",
    "![그래프](img_21.png)\n",
    "\n",
    "주황색 구간에서는 미분값이 0에 가까운 아주 작은 값입니다. 초록색 구간에서의 미분값은 최대값이 0.25입니다.\n",
    "다시 말해 시그모이드 함수를 미분한 값은 적어도 0.25 이하의 값입니다.\n",
    "시그모이드 함수를 활성화 함수로하는 인공 신경망의 층을 쌓는다면, 가중치와 편향을 업데이트 하는 과정인 역전파 과정에서 0에 가까운 값이 누적해서 곱해지게 되면서,\n",
    "앞단에는 기울기(미분값)가 잘 전달되지 않게 됩니다. 이러한 현상을 기울기 소실(Vanishing Gradient) 문제라고 합니다.\n",
    "\n",
    "시그모이드 함수를 사용하는 은닉층의 개수가 다수가 될 경우에는 0에 가까운 기울기가 계속 곱해지면 앞단에서는 거의 기울기를 전파받을 수 없게 됩니다.\n",
    "다시 말해 매개변수 $w$가 업데이트 되지 않아 학습이 되지를 않습니다.\n",
    "\n",
    "![그래프](img_20.png)\n",
    "\n",
    "위의 그림은 은닉층이 깊은 신경망에서 기울기 소실 문제로 인해 출력층과 가까운 은닉층에서는 기울기가 잘 전파되지만,\n",
    "앞단으로 갈수록 기울기가 제대로 전파되지 않는 모습을 보여줍니다. 결론적으로 시그모이드 함수의 은닉층에서의 사용은 지양됩니다.\n",
    "시그모이드 함수는 주로 이진 분류를 위해 출력층에서 사용합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a13c3d6d8c43d006"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (4) 하이퍼볼릭탄젠트 함수(Hyperbolic tangent function)\n",
    "\n",
    "하이퍼볼릭탄젠트 함수(tanh)는 입력값을 -1과 1사이의 값으로 변환합니다. 그래프를 그려보겠습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80f9e16b98410f2f"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-5.0, 5.0, 0.1) # -5.0부터 5.0까지 0.1 간격 생성\n",
    "y = np.tanh(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.plot([0,0],[1.0,-1.0], ':')\n",
    "plt.axhline(y=0, color='orange', linestyle='--')\n",
    "plt.title('Tanh Function')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T07:24:23.489747500Z",
     "start_time": "2024-01-26T07:24:23.363605300Z"
    }
   },
   "id": "e831261c835735d0",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (5) 렐루 함수(ReLU)\n",
    "\n",
    "인공 신경망의 은닉층에서 가장 인기있는 함수입니다. 수식은 $f(x) = max(0, x)$로 아주 간단합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bab71a047a750ca"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = relu(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.plot([0,0],[5.0,0.0], ':')\n",
    "plt.title('Relu Function')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T07:27:14.091121800Z",
     "start_time": "2024-01-26T07:27:13.981819900Z"
    }
   },
   "id": "862ef98fd1e9aed8",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "렐루 함수는 음수를 입력하면 0을 출력하고, 양수를 입력하면 입력값을 그대로 반환하는 것이 특징인 함수로 출력값이 특정 양수값에 수렴하지 않습니다.\n",
    "0이상의 입력값의 경우에는 미분값이 항상 1입니다. 깊은 신경망의 은닉층에서 시그모이드 함수보다 훨씬 더 잘 작동합니다.\n",
    "뿐만 아니라, 렐루 함수는 시그모이드 함수와 하이퍼볼릭탄젠트 함수와 같이 어떤 연산이 필요한 것이 아니라 단순 임계값이므로 연산 속도도 빠릅니다.\n",
    "\n",
    "하지만 여전히 문제점이 존재하는데, 입력값이 음수면 기울기. 즉, 미분값도 0이 됩니다.\n",
    "그리고 이 뉴런은 다시 회생하는 것이 매우 어렵습니다. 이 문제를 죽은 렐루(dying ReLU)라고 합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7db08ad1cd08425"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (6) 리키 렐루(Leaky ReLU)\n",
    "\n",
    "죽은 렐루를 보완하기 위해 ReLU의 변형 함수들이 등장하기 시작했습니다. 변형 함수는 여러 개가 있지만 여기서는 Leaky ReLU에 대해서만 소개합니다.\n",
    "Leaky ReLU는 입력값이 음수일 경우에 0이 아니라 0.001과 같은 매우 작은 수를 반환하도록 되어있습니다. 수식은 $f(x) = max(ax, x)$로 아주 간단합니다.\n",
    "a는 하이퍼파라미터로 Leaky('새는') 정도를 결정하며 일반적으로는 0.01의 값을 가집니다.\n",
    "여기서 말하는 '새는 정도'라는 것은 입력값의 음수일 때의 기울기를 비유하고 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51d0056011e11a0b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = 0.1\n",
    "\n",
    "def leaky_relu(x):\n",
    "    return np.maximum(a*x, x)\n",
    "\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = leaky_relu(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.plot([0,0],[5.0,0.0], ':')\n",
    "plt.title('Leaky ReLU Function')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T07:30:42.519426800Z",
     "start_time": "2024-01-26T07:30:42.416842300Z"
    }
   },
   "id": "1f20666f072402bd",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "위의 그래프에서는 새는 모습을 확실히 보여주기 위해 a를 0.1로 잡았습니다. 위와 같이 입력값이 음수라도 기울기가 0이 되지 않으면 ReLU는 죽지 않습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c47133c607aa4bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (7) 소프트맥스 함수(Softmax function)\n",
    "\n",
    "은닉층에서는 ReLU(또는 ReLU 변형) 함수들을 사용하는 것이 일반적입니다.\n",
    "반면, 소프트맥스 함수는 시그모이드 함수처럼 출력층에서 주로 사용됩니다.\n",
    "시그모이드 함수가 두 가지 선택지 중 하나를 고르는 이진 분류 (Binary Classification) 문제에 사용된다면\n",
    "소프트맥스 함수는 세 가지 이상의 (상호 배타적인) 선택지 중 하나를 고르는 다중 클래스 분류(MultiClass Classification) 문제에 주로 사용됩니다.\n",
    "다시 말해서 딥 러닝으로 이진 분류를 할 때는 출력층에 앞서 배운 로지스틱 회귀를 사용하고,\n",
    "딥 러닝으로 다중 클래스 분류 문제를 풀 때는 출력층에 소프트맥스 회귀를 사용한다고 생각할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e687b1e2db4c546e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(-5.0, 5.0, 0.1) # -5.0부터 5.0까지 0.1 간격 생성\n",
    "y = np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.title('Softmax Function')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T10:00:29.353780Z",
     "start_time": "2024-01-30T10:00:29.245671400Z"
    }
   },
   "id": "7b67edded893a287",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 07-03 행렬곱으로 이해하는 신경망\n",
    "***\n",
    "\n",
    "인공 신경망에서 입력층에서 출력층 방향으로 연산을 진행하는 과정을 순전파(Forward Propagation)라고 합니다.\n",
    "다르게 말하면 주어진 입력이 입력층으로 들어가서 은닉층을 지나 출력층에서 예측값을 얻는 과정을 순전파라고 합니다.\n",
    "여기서는 신경망의 순전파는 결과적으로 행렬의 곱셈으로 이해할 수 있다는 것과\n",
    "다층 퍼셉트론 내의 학습 가능한 매개변수인 가중치 $w$와 편향 $b$의 개수를 추정하는 방법에 대해서 학습합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b07b1c8687afe4e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. 순전파(Foward Propagation)\n",
    "***\n",
    "\n",
    "![그림](img_22.png)\n",
    "\n",
    "활성화 함수, 은닉층의 수, 각 은닉층의 뉴런 수 등 딥 러닝 모델을 설계하고나면\n",
    "입력값은 입력층, 은닉층을 지나면서 각 층에서의 가중치와 함께 연산되며 출력층으로 향합니다.\n",
    "그리고 출력층에서 모든 연산을 마친 예측값이 나오게 됩니다.\n",
    "이와 같이 입력층에서 출력층 방향으로 예측값의 연산이 진행되는 과정을 순전파라고 합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2718020c7ca991dc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. 행렬곱으로 순전파 이해하기\n",
    "***\n",
    "\n",
    "![그림](img_23.png)\n",
    "\n",
    "위와 같은 인공 신경망이 있다고 해봅시다. 입력의 차원이 3, 출력의 차원이 2인 위 인공 신경망을 구현해본다면 다음과 같습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad78a2801877d1db"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 3개의 입력과 2개의 출력\n",
    "model.add(Dense(2, input_dim=3, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T07:35:52.528542Z",
     "start_time": "2024-01-26T07:35:52.513102600Z"
    }
   },
   "id": "1244c775040e1309",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "소프트맥스 회귀를 한다고 가정하고 활성화 함수는 소프트맥스 함수를 임의로 기재하였습니다.\n",
    "인공 신경망이란 표현이 아직 어색한다면 앞에서 배운 소프트맥스 회귀 모델을 만들었다고 생각해도 되겠습니다.\n",
    "소프트맥스 회귀는 출력 벡터의 차원을 2로 두면 이진 분류를 수행하는 모델이 됩니다. 로지스틱 회귀가 아닌 소프트맥스 회귀로도 이진 분류는 수행 가능함을 기억해둡시다.\n",
    "\n",
    "케라스에서는 .summary()를 사용하면 해당 모델에 존재하는 모든 매개변수(가중치 $w$와 편향 $b$의 개수)를 확인할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fa876bed165f957"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 2)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8 (32.00 Byte)\n",
      "Trainable params: 8 (32.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T07:36:27.232688100Z",
     "start_time": "2024-01-26T07:36:27.219446400Z"
    }
   },
   "id": "4ecde98b5475fadf",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "매개변수의 수가 8개라고 나옵니다.\n",
    "위 신경망에서 학습가능한 매개변수 인 $w$와 $b$의 개수가 총 합해서 8개라는 의미입니다.\n",
    "실제로 그런지 위 신경망을 행렬의 곱셈 관점에서 이해해봅시다.\n",
    "\n",
    "![그림](img_24.png)\n",
    "\n",
    "위 모델은 입력의 차원이 3, 출력의 차원이 2입니다.\n",
    "또는 신경망의 용어로서 표현한다면, 입력층의 뉴런이 3개, 출력층의 뉴런이 2개라고 말할 수 있습니다.\n",
    "위 신경망 그림에서 화살표 각각은 가중치 $w$를 의미하고 있습니다.\n",
    "3개의 뉴런과 2개의 뉴런 사이에는 총 6개의 화살표가 존재하는데, 이는 위 신경망에서 가중치 $w$의 개수가 6개임을 의미합니다.\n",
    "\n",
    "이를 행렬곱 관점에서는 3차원 벡터에서 2차원 벡터가 되기 위해서 3 × 2 행렬을 곱했다고 이해할 수 있습니다. 그리고 이 행렬 각각의 원소가 각각의 \n",
    "$w$가 되는 것입니다. 위 그림에서는 \n",
    "$y1$에 연결되는 화살표 $w1$, $w2$, $w3$를 주황색으로 표현하고, \n",
    "$y2$에 연결되는 화살표 $w4$, $w5$, $w6$를 초록색으로 표현했습니다.\n",
    "\n",
    "일반적으로 동그란 뉴런과 화살표로 표현하는 인공 신경망의 그림에서는 편향 $b$의 경우에는 편의상 생략되는 경우가 많지만,\n",
    "인공 신경망 내부적으로는 편향 $b$의 연산 또한 존재합니다.\n",
    "위 그림에서 뉴런과 화살표로 표현한 인공 신경망의 그림에서는 편향을 표현하지 않았지만,\n",
    "행렬 연산식에서는 $b1$과 $b2$를 표현하였습니다.\n",
    "편향 $b$의 개수는 항상 출력의 차원을 기준으로 개수를 확인하면 됩니다.\n",
    "위의 인공 신경망의 경우에는 출력의 차원이 2인데, 이에 따라서 편향 또한 $b1$과 $b2$로 두 개입니다.\n",
    "\n",
    "가중치 $w$의 개수가 $w1$, $w2$, $w3$, $w4$, $w5$, $w6$로 총 6개이며\n",
    "편향 $b$의 개수가 $b1$과 $b2$로 두 개이므로 총 학습가능한 매개변수의 수는 8개입니다.\n",
    "이는 앞서 model.summary()를 하였을 때 확인한 매개변수의 수인 8개와 일치합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7603f6b311ba135d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "$y1$과 $y2$를 구하는 과정을 수식으로 표현한다면 다음과 같이 표현할 수 있습니다.\n",
    "\n",
    "![수식](img_25.png)\n",
    "\n",
    "좀 더 간단하게 식을 표현해보겠습니다. 입력 $x1, x2, x3$을 벡터 $X$로 명명합니다.\n",
    "$X = [x1, x2, x3]$\n",
    "\n",
    "그리고 $w1$, $w2$, $w3$, $w4$, $w5$, $w6$를 원소로 하는 3 × 2 행렬을 가중치 행렬 $W$,\n",
    "그리고 편향 $b1$, $b2$를 원소로 하는 벡터를 $B$,\n",
    "그리고 $y1$, $y2$를 원소로하는 출력 벡터를 $Y$로 명명합시다.\n",
    "이 경우, 위의 인공 신경망은 다음과 같이 표현할 수 있습니다.\n",
    "\n",
    "![그림](img_26.png)\n",
    "\n",
    "다시 말해 수식은 다음과 같습니다.\n",
    "\n",
    "$Y = XW + B$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e8edaff692c0523"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. 행렬곱으로 병렬 연산 이해하기\n",
    "***\n",
    "\n",
    "인공 신경망을 행렬곱으로 구현할 때의 흥미로운 점은 행렬곱을 사용하면 병렬 연산도 가능하다는 점입니다.\n",
    "위의 예시에서는 데이터 중 1개의 샘플만을 처리한다고 가정했습니다.\n",
    "이번에는 인공 신경망이 4개의 샘플을 동시에 처리해본다고 가정해봅시다.\n",
    "4개의 샘플을 하나의 행렬 $X$로 정의하고 인공 신경망의 순전파를 행렬곱으로 표현하면 다음과 같습니다.\n",
    "\n",
    "![그림](img_27.png)\n",
    "\n",
    "여기서 혼동하지 말아야 할 것은 인공 신경망의 4개의 샘플을 동시에 처리하고 있지만, 여기서 학습가능한 매개변수의 수는 여전히 8개라는 점입니다.\n",
    "이렇게 인공 신경망이 다수의 샘플을 동시에 처리하는 것을 우리는 '배치 연산'이라고 부릅니다.\n",
    "\n",
    "난이도를 올려서 중간에 층을 더 추가해봅시다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "267d9fd70a5d76c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. 행렬곱으로 다층 퍼셉트론의 순전파 이해하기\n",
    "***\n",
    "\n",
    "![그림](img_28.png)\n",
    "\n",
    "위와 같은 인공 신경망이 있다고 합시다. 주어진 인공 신경망을 케라스로 구현해본다면 아래와 같이 구현할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70b594375093df40"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) 코드로 구현하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71be371e968c9ab4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 4개의 입력과 8개의 출력\n",
    "model.add(Dense(8, input_dim=4, activation='relu'))\n",
    "\n",
    "# 이어서 8개의 출력\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# 이어서 3개의 출력\n",
    "model.add(Dense(3, activation='softmax'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T08:28:40.482567Z",
     "start_time": "2024-01-26T08:28:40.433293900Z"
    }
   },
   "id": "282101a6b48ad07e",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "위의 코드의 주석에서 () 괄호 안의 값은 각 층에서의 뉴런의 수를 의미하며 입력층부터 출력층까지 순차적으로 인공 신경망의 층을 한 층씩 추가하였습니다.\n",
    "케라스를 사용하면 이렇게 간단하게 층을 딥하게 쌓은 딥 러닝 모델을 구현할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0e57ca0f1c12fae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) 행렬의 크기 추정해보기\n",
    "\n",
    "우선 각 층을 기준으로 입력과 출력의 개수를 정리하면 다음과 같습니다.\n",
    "\n",
    "입력층 : 4개의 입력과 8개의 출력\n",
    "은닉층1 : 8개의 입력과 8개의 출력\n",
    "은닉층2 : 8개의 입력과 3개의 출력\n",
    "출력층 : 3개의 입력과 3개의 출력\n",
    "\n",
    "위의 정보를 가지고 층마다 생기는 가중치와 편향 행렬의 크기를 추정해봅시다. 단, 배치 크기는 1을 가정합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e9df12fcdde232c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1. 입력층 ⇒ 은닉층1\n",
    "\n",
    "![설명](img_29.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "222be34b3753e50"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2. 은닉층1 ⇒ 은닉층2\n",
    "\n",
    "![설명](img_30.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c5cd6d07cdaa14a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3. 은닉층2 ⇒ 은닉층3\n",
    "\n",
    "![설명](img_31.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eff40670a4d33a9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 07-04 딥 러닝의 학습 방법\n",
    "***\n",
    "\n",
    "딥 러닝의 학습 방법의 이해를 위해 필요한 개념인 손실 함수, 옵티마이저, 에포크의 개념에 대해서 정리합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57d3f9c9242e5741"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. 손실 함수(Loss function)\n",
    "***\n",
    "\n",
    "![그림](img_32.png)\n",
    "\n",
    "손실 함수는 실제값과 예측값의 차이를 수치화해주는 함수입니다. 이 두 값의 차이.\n",
    "즉, 오차가 클 수록 손실 함수의 값은 크고 오차가 작을 수록 손실 함수의 값은 작아집니다.\n",
    "회귀에서는 평균 제곱 오차, 분류 문제에서는 크로스 엔트로피를 주로 손실 함수로 사용합니다.\n",
    "손실 함수의 값을 최소화하는 두 개의 매개변수인 가중치 $w$와 편향 $b$의 값을 찾는 것이 딥 러닝의 학습 과정이므로 손실 함수의 선정은 매우 중요합니다.\n",
    "앞서 설명했던 손실 함수를 정리해봅시다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9d661a0a91e5fdd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) MSE(Mean Squared Error, MSE)\n",
    "\n",
    "평균 제곱 오차는 선형 회귀를 학습할 때 배웠던 손실 함수입니다. 연속형 변수를 예측할 때 사용됩니다.\n",
    "\n",
    "다음과 같이 compile의 loss에 문자열 'mse'라고 기재하여 사용할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6f18f705e81d650"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T05:41:23.599458800Z",
     "start_time": "2024-01-29T05:41:23.589679500Z"
    }
   },
   "id": "ea4bcec4d6c96856",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "compile의 loss는 tf.keras.losses.Loss 인스턴스를 호출하므로 위 코드는 아래와 같이 사용할 수도 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3be592442efebfbe"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError(), metrics=['mse'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T05:41:25.909513Z",
     "start_time": "2024-01-29T05:41:25.899517400Z"
    }
   },
   "id": "a33ed8950d042da5",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "딥 러닝 자연어 처리는 대부분 분류 문제이므로 평균 제곱 오차보다는 아래의 크로스 엔트로피 함수들을 주로 사용합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "496f8c2cdfd397b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) 이진 크로스 엔트로피(Binary Cross-Entropy)\n",
    "\n",
    "이항 교차 엔트로피라고도 부르는 손실 함수입니다.\n",
    "출력층에서 시그모이드 함수를 사용하는 이진 분류 (Binary Classification)의 경우 binary_crossentropy를 사용합니다.\n",
    "compile의 loss에 문자열로 'binary_crossentropy'를 기재해주면 됩니다. 이는 로지스틱 회귀에서 사용했던 손실 함수입니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88a14bdc40d67c46"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T05:56:42.759307200Z",
     "start_time": "2024-01-29T05:56:42.743797200Z"
    }
   },
   "id": "effd7dfec5d00ead",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "compile의 loss는 tf.keras.losses.Loss 인스턴스를 호출하므로 위 코드는 아래와 같이 사용할 수도 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5630fd5bc82b698"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer='adam', metrics=['acc'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T05:56:56.079282Z",
     "start_time": "2024-01-29T05:56:56.055420100Z"
    }
   },
   "id": "97ba952b62835686",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3) 카테고리칼 크로스 엔트로피(Categorical Cross-Entropy)\n",
    "\n",
    "범주형 교차 엔트로피라고도 부르는 손실 함수입니다.\n",
    "출력층에서 소프트맥스 함수를 사용하는 다중 클래스 분류(Multi-Class Classification)일 경우 categorical_crossentropy를 사용합니다.\n",
    "compile의 loss에 문자열로 'categorical_crossentropy'를 기재해주면 됩니다. 소프트맥스 회귀에서 사용했던 손실 함수입니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6726286ea437a170"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T05:59:14.944649200Z",
     "start_time": "2024-01-29T05:59:14.931379100Z"
    }
   },
   "id": "915bccc8b22e870e",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "compile의 loss는 tf.keras.losses.Loss 인스턴스를 호출하므로 위 코드는 아래와 같이 사용할 수도 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fc526371f580ec6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer='adam', metrics=['acc'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T05:59:38.708928Z",
     "start_time": "2024-01-29T05:59:38.693593600Z"
    }
   },
   "id": "17db8b2adb0fbcaa",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "만약 레이블에 대해서 원-핫 인코딩 과정을 생략하고, 정수값을 가진 레이블에 대해서 다중 클래스 분류를 수행하고 싶다면\n",
    "다음과 같이 'sparse_categorical_crossentropy'를 사용합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30b6cba984dfe06e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T06:00:09.829521300Z",
     "start_time": "2024-01-29T06:00:09.815925900Z"
    }
   },
   "id": "d41778eb59aa79d9",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "위 코드는 아래와 같이 사용할 수도 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53289210ded64743"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer='adam', metrics=['acc'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T06:00:56.083884Z",
     "start_time": "2024-01-29T06:00:56.067508900Z"
    }
   },
   "id": "c360978b3b203206",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4) 그 외에 다양한 손실 함수들\n",
    "\n",
    "아래의 텐서플로우 공식 문서 링크에서 방금 언급하지 않은 손실 함수 외에도 다양한 손실 함수들을 확인할 수 있습니다.\n",
    "\n",
    "[손실함수 참조링크](https://www.tensorflow.org/api_docs/python/tf/keras/losses)\n",
    "\n",
    "지금까지 자주 사용하는 손실 함수 몇 가지에 대해서 정리해봤습니다.\n",
    "위 compile 코드에서 optimizer='adam' 이라는 부분에 주목해봅시다.\n",
    "이는 아담이라는 옵티마이저를 사용했다라는 의미입니다.\n",
    "손실 함수의 선정만큼이나 옵티마이저의 선정 또한 중요합니다.\n",
    "이어서 옵티마이저에 대해서 정리해봅시다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ca24274dfd67a6a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. 배치 크기(Batch Size)에 따른 경사 하강법\n",
    "***\n",
    "\n",
    "![그림](img_33.png)\n",
    "\n",
    "손실 함수의 값을 줄여나가면서 학습하는 방법은 어떤 옵티마이저를 사용하느냐에 따라 달라집니다.\n",
    "여기서 배치(Batch)라는 개념에 대한 이해가 필요합니다. 배치는 가중치 등의 매개 변수의 값을 조정하기 위해 사용하는 데이터의 양을 말합니다.\n",
    "전체 데이터를 가지고 매개 변수의 값을 조정할 수도 있고, 정해준 양의 데이터만 가지고도 매개 변수의 값을 조정할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2922ad11f8a7631"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) 배치 경사 하강법(Batch Gradient Descent)\n",
    "\n",
    "배치 경사 하강법(Batch Gradient Descent)은 가장 기본적인 경사 하강법입니다.\n",
    "배치 경사 하강법은 옵티마이저 중 하나로 오차(loss)를 구할 때 전체 데이터를 고려합니다.\n",
    "딥 러닝에서는 전체 데이터에 대한 한 번의 훈련 횟수를 1 에포크라고 하는데, 배치 경사 하강법은 한 번의 에포크에 모든 매개변수 업데이트를 단 한 번 수행합니다.\n",
    "배치 경사 하강법은 전체 데이터를 고려해서 학습하므로 한 번의 매개 변수 업데이트에 시간이 오래 걸리며, 메모리를 크게 요구한다는 단점이 있습니다.\n",
    "<br/>\n",
    "```\n",
    "model.fit(X_train, y_train, batch_size=len(X_train))\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c196f0a6e5639d86"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) 배치 크기가 1인 확률적 경사 하강법(Stochastic Gradient Descent, SGD)\n",
    "\n",
    "기존의 배치 경사 하강법은 전체 데이터에 대해서 계산을 하다보니 시간이 너무 오래걸린다는 단점이 있습니다.\n",
    "배치 크기가 1인 확률적 경사 하강법은 매개변수 값을 조정 시 전체 데이터가 아니라 랜덤으로 선택한 하나의 데이터에 대해서만 계산하는 방법입니다.\n",
    "더 적은 데이터를 사용하므로 더 빠르게 계산할 수 있습니다.\n",
    "\n",
    "![그림](img_34.png)\n",
    "\n",
    "위 그림에서 좌측은 배치 경사 하강법, 우측은 배치 크기가 1인 확률적 경사 하강법이 최적해를 찾아가는 모습을 보여주고 있습니다.\n",
    "확률적 경사 하강법은 매개변수의 변경폭이 불안정하고, 때로는 배치 경사 하강법보다 정확도가 낮을 수도 있지만\n",
    "하나의 데이터에 대해서만 메모리에 저장하면 되므로 자원이 적은 컴퓨터에서도 쉽게 사용가능 하다는 장점이 있습니다. 케라스에서는 아래와 같이 사용합니다.\n",
    "<br/>\n",
    "```\n",
    "model.fit(X_train, y_train, batch_size=1)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22ce866978ee4e9e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3) 미니 배치 경사 하강법(Mini-Batch Gradient Descent)\n",
    "\n",
    "전체 데이터도, 1개의 데이터도 아닐 때, 배치 크기를 지정하여 해당 데이터 개수만큼에 대해서 계산하여 매개 변수의 값을 조정하는 경사 하강법을 미니 배치 경사 하강법이라고 합니다.\n",
    "미니 배치 경사 하강법은 전체 데이터를 계산하는 것보다 빠르며, SGD보다 안정적이라는 장점이 있습니다.\n",
    "가장 많이 사용되는 경사 하강법으로 앞으로 이 책에서도 주로 배치 크기를 지정하여 미니 배치 경사 하강법으로 학습하게 될 것입니다.\n",
    "아래의 코드는 배치 크기를 128로 지정했을 경우를 보여줍니다.\n",
    "<br/>\n",
    "```\n",
    "model.fit(X_train, y_train, batch_size=128)\n",
    "```\n",
    "\n",
    "배치 크기는 일반적으로 2의 n제곱에 해당하는 숫자로 선택하는 것이 보편적입니다.\n",
    "만약, model.fit()에서 배치 크기를 별도로 지정해주지 않을 경우에 기본값은 2의 5제곱에 해당하는 숫자인 32로 설정됩니다.\n",
    "지금까지 배치 크기에 따른 학습 방법의 차이를 알아봤습니다.\n",
    "앞으로는 경사 하강법의 알고리즘 자체를 조금씩 달리한 다양한 옵티마이저에 대해서 설명합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf3221315c694ab5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. 옵티마이저(Optimizer)\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cae1061e761799f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) 모멘텀(Momentum)\n",
    "\n",
    "모멘텀(Momentum)은 관성이라는 물리학의 법칙을 응용한 방법입니다.\n",
    "모멘텀 경사 하강법에 관성을 더 해줍니다.\n",
    "모멘텀은 경사 하강법에서 계산된 접선의 기울기에 한 시점 전의 접선의 기울기값을 일정한 비율만큼 반영합니다.\n",
    "이렇게 하면 마치 언덕에서 공이 내려올 때, 중간에 작은 웅덩이에 빠지더라도 관성의 힘으로 넘어서는 효과를 줄 수 있습니다.\n",
    "\n",
    "![그래프](img_35.png)\n",
    "\n",
    "전체 함수에 걸쳐 최소값을 글로벌 미니멈(Global Minimum) 이라고 하고, 글로벌 미니멈이 아닌 특정 구역에서의 최소값인 로컬 미니멈(Local Minimum) 이라고 합니다. 로컬 미니멈에 도달하였을 때 글로벌 미니멈으로 잘못 인식하여 탈출하지 못하였을 상황에서 모멘텀. 즉, 관성의 힘을 빌리면 값이 조절되면서 현재의 로컬 미니멈에서 탈출하고 글로벌 미니멈 내지는 더 낮은 로컬 미니멈으로 갈 수 있는 효과를 얻을 수도 있습니다.\n",
    "<br/>\n",
    "```\n",
    "tf.keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4ccf08304ad5388"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) 아다그라드(Adagrad)\n",
    "\n",
    "매개변수들은 각자 의미하는 바가 다른데, 모든 매개변수에 동일한 학습률(learning rate)을 적용하는 것은 비효율적입니다. 아다그라드는 각 매개변수에 서로 다른 학습률을 적용시킵니다. 이때 변화가 많은 매개변수는 학습률이 작게 설정되고 변화가 적은 매개변수는 학습률을 높게 설정시킵니다.\n",
    "<br/>\n",
    "```\n",
    "tf.keras.optimizers.Adagrad(lr=0.01, epsilon=1e-6)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be8854ac1201373e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3) 알엠에스프롭(RMSprop)\n",
    "\n",
    "아다그라드는 학습을 계속 진행한 경우에는, 나중에 가서는 학습률이 지나치게 떨어진다는 단점이 있는데 이를 다른 수식으로 대체하여 이러한 단점을 개선하였습니다.\n",
    "<br/>\n",
    "```\n",
    "tf.keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46a56953b84ae535"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4) 아담(Adam)\n",
    "\n",
    "아담은 알엠에스프롭과 모멘텀 두 가지를 합친 듯한 방법으로, 방향과 학습률 두 가지를 모두 잡기 위한 방법입니다.\n",
    "<br/>\n",
    "```\n",
    "tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4f87197ba4df37a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5) 사용 방법\n",
    "\n",
    "각 옵티마이저 인스턴스는 compile의 optimizer에서 호출합니다. 예를 들어 아담(adam)은 다음과 같이 코드를 작성합니다.\n",
    "<br/>\n",
    "```\n",
    "adam = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['acc'])\n",
    "```\n",
    "\n",
    "하지만 다음과 같이 단순히 문자열로 'adam'으로 작성하더라도 동작합니다.\n",
    "<br/>\n",
    "```\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "```\n",
    "\n",
    "다른 옵티마이저들도 마찬가지입니다.\n",
    "optimizer='sgd', optimizer='rmsprop'와 같이 각 옵티마이저를 문자열로 호출할 수 있습니다.\n",
    "케라스의 옵티마이저 사용법은 아래의 링크에서 좀 더 상세히 확인할 수 있습니다.\n",
    "\n",
    "[옵티마이저 참조링크](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b41594a2857b51e9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. 역전파(BackPropagation)\n",
    "***\n",
    "\n",
    "이 부분은 05) 역전파 챕터로 별도 작성되었습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19d37418e4bb57a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. 에포크와 배치 크기와 이터레이션(Epochs and Batch size and Iteration)\n",
    "***\n",
    "\n",
    "기계는 실제값과 예측값의 오차로부터 옵티마이저를 통해서 가중치를 업데이트합니다.\n",
    "머신 러닝에서는 이 과정을 학습이라고 합니다.\n",
    "이를 현실의 학습에 비유하면 사람은 문제지의 문제를 풀고,\n",
    "정답지의 정답을 보면서 채점을 하면서 부족했던 점을 깨달으며 머릿속의 지식이 업데이트되는 과정입니다.\n",
    "\n",
    "그런데 사람마다 동일한 문제지와 정답지를 주더라도 공부 방법은 사실 천차만별입니다.\n",
    "어떤 사람은 문제지 하나를 다 풀고 나서 정답을 채점하는데 어떤 사람은 문제지의 문제를 10개 단위로 끊어서 공부합니다.\n",
    "문제 10개를 풀고 채점하고 다시 다음 문제 10개를 풀고 채점하고 반복하는 방식으로 학습하는 방식입니다.\n",
    "또한 게으른 사람은 문제지를 세 번 공부하는데, 성실한 사람은 문제지의 문제를 달달 외울만큼 문제지를 100번 공부합니다.\n",
    "기계도 똑같습니다. 같은 문제지와 정답지를 주더라도 공부 방법을 다르게 설정할 수 있습니다.\n",
    "\n",
    "![그림](img_36.png)\n",
    "\n",
    "위 그림은 에포크와 배치 크기와 이터레이션의 차이를 보여줍니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8f512e7959cf76d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) 에포크(Epoch)\n",
    "\n",
    "에포크란 인공 신경망에서 전체 데이터에 대해서 순전파와 역전파가 끝난 상태를 말합니다.\n",
    "전체 데이터를 하나의 문제지에 비유한다면 문제지의 모든 문제를 끝까지 다 풀고, 정답지로 채점을 하여 문제지에 대한 공부를 한 번 끝낸 상태를 말합니다.\n",
    "\n",
    "만약 에포크가 50이라고 하면, 전체 데이터 단위로는 총 50번 학습합니다.\n",
    "문제지에 비유하면 문제지를 50번 푼 셈입니다.\n",
    "이 에포크 횟수가 지나치거나 너무 적으면 앞서 배운 과적합과 과소적합이 발생할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e183340dbc9d1c9f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) 배치 크기(Batch size)\n",
    "\n",
    "배치 크기는 몇 개의 데이터 단위로 매개변수를 업데이트 하는지를 말합니다.\n",
    "현실에 비유하면 문제지에서 몇 개씩 문제를 풀고나서 정답지를 확인하느냐의 문제입니다.\n",
    "사람은 문제를 풀고 정답을 보는 순간 부족했던 점을 깨달으며 지식이 업데이트 된다고 하였습니다.\n",
    "기계 입장에서는 실제값과 예측값으로부터 오차를 계산하고 옵티마이저가 매개변수를 업데이트합니다.\n",
    "여기서 중요한 포인트는 업데이트가 시작되는 시점이 정답지/실제값을 확인하는 시점이라는 겁니다.\n",
    "\n",
    "사람이 2,000 문제가 수록되어있는 문제지의 문제를 200개 단위로 풀고 채점한다고 하면 이때 배치 크기는 200입니다.\n",
    "기계는 배치 크기가 200이면 200개의 샘플 단위로 가중치를 업데이트 합니다.\n",
    "\n",
    "여기서 주의할 점은 배치 크기와 배치의 수는 다른 개념이라는 점입니다.\n",
    "**전체 데이터가 2,000일때 배치 크기를 200으로 준다면 배치의 수는 10입니다.**\n",
    "이는 에포크에서 배치 크기를 나눠준 값(2,000/200 = 10)이기도 합니다.\n",
    "이때 **배치의 수**를 **이터레이션**이라고 합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4b5e2a12460f750"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3) 이터레이션(Iteration) 또는 스텝(Step)\n",
    "\n",
    "이터레이션이란 한 번의 에포크를 끝내기 위해서 필요한 배치의 수를 말합니다.\n",
    "또는 한 번의 에포크 내에서 이루어지는 매개변수의 업데이트 횟수이기도 합니다.\n",
    "전체 데이터가 2,000일 때 배치 크기를 200으로 한다면 이터레이션의 수는 총 10입니다.\n",
    "이는 한 번의 에포크 당 매개변수 업데이트가 10번 이루어진다는 것을 의미합니다.\n",
    "배치 크기가 1인 확률적 경사 하강법을 이 개념을 가지고 다시 설명하면 배치 크기가 1이므로 모든 이터레이션마다 하나의 데이터를 선택하여 경사 하강법을 수행합니다.\n",
    "이터레이션은 스텝(Step)이라고 부르기도 하므로 두 용어 모두 기억해둡시다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49654ad93a0a4a56"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 07-05 역전파(BackPropagation) 이해하기\n",
    "***\n",
    "인공 신경망이 순전파 과정을 진행하여 예측값과 실제값의 오차를 계산하였을 때 어떻게 역전파 과정에서 경사 하강법을 사용하여 가중치를 업데이트하는지 직접 계산을 통해 이해해봅시다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a06a8eb519a483d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. 인공 신경망의 이해(Neural Network Overview)\n",
    "***\n",
    "\n",
    "우선 예제를 위해 사용될 인공 신경망을 소개합니다. 역전파의 이해를 위해서 여기서 사용할 인공 신경망은 입력층, 은닉층, 출력층 이렇게 3개의 층을 가집니다. 또한 해당 인공 신경망은 두 개의 입력과, 두 개의 은닉층 뉴런, 두 개의 출력층 뉴런을 사용합니다. 은닉층과 출력층의 모든 뉴런은 활성화 함수로 시그모이드 함수를 사용합니다.\n",
    "\n",
    "![그림](img_37.png)\n",
    "\n",
    "위의 그림은 여기서 사용할 인공 신경망의 모습을 보여줍니다. 은닉층과 출력층의 모든 뉴런에서 변수 $z$\n",
    "가 존재하는데 여기서 변수 $z$\n",
    "는 이전층의 모든 입력이 각각의 가중치와 곱해진 값들이 모두 더해진 가중합을 의미합니다. 이 값은 뉴런에서 아직 시그모이드 함수를 거치지 않은 상태입니다. 즉, 활성화 함수의 입력을 의미합니다. \n",
    " $z$우측의 |를 지나서 존재하는 변수 $h$ \n",
    " 또는 $o$\n",
    "는 $z$\n",
    "가 시그모이드 함수를 지난 후의 값으로 각 뉴런의 출력값을 의미합니다. 이번 역전파 예제에서는 인공 신경망에 존재하는 모든 가중치 $w$\n",
    "에 대해서 역전파를 통해 업데이트하는 것을 목표로합니다. 해당 인공 신경망은 편향 \n",
    "$b$는 고려하지 않습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65da2943fbc54110"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. 순전파(Forward Propagation)\n",
    "***\n",
    "\n",
    "![그림](img_38.png)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55bf347f217d6222"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. 역전파 1단계(BackPropagation Step 1)\n",
    "***\n",
    "\n",
    "![그림](img_39.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6855aebbaa402dff"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. 역전파 2단계(BackPropagation Step 2)\n",
    "***\n",
    "\n",
    "![그림](img_40.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5470bf1c446068"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. 결과 확인\n",
    "***\n",
    "\n",
    "![그림](img_41.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9c299a6764200f9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 07-06 과적합(Overfitting)을 막는 방법들\n",
    "***\n",
    "\n",
    "학습 데이터에 모델이 과적합되는 현상은 모델의 성능을 떨어트리는 주요 이슈입니다.\n",
    "모델이 과적합되면 훈련 데이터에 대한 정확도는 높을지라도, 새로운 데이터. 즉, 검증 데이터나 테스트 데이터에 대해서는 제대로 동작하지 않습니다.\n",
    "이는 모델이 학습 데이터를 불필요할정도로 과하게 암기하여 훈련 데이터에 포함된 노이즈까지 학습한 상태라고 해석할 수 있습니다.\n",
    "이번에는 모델의 과적합을 막을 수 있는 여러가지 방법에 대해서 논의합니다.\n",
    "\n",
    "특히 이 책은 딥 러닝을 다루고 있으므로, 인공 신경망의 과적합을 막는 방법에 초점을 둡니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27ee1270d8c89b68"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. 데이터의 양을 늘리기\n",
    "***\n",
    "\n",
    "모델은 데이터의 양이 적을 경우, 해당 데이터의 특정 패턴이나 노이즈까지 쉽게 암기하기 되므로 과적합 현상이 발생할 확률이 늘어납니다.\n",
    "그렇기 때문에 데이터의 양을 늘릴 수록 모델은 데이터의 일반적인 패턴을 학습하여 과적합을 방지할 수 있습니다.\n",
    "\n",
    "만약, 데이터의 양이 적을 경우에는 의도적으로 기존의 데이터를 조금씩 변형하고 추가하여 데이터의 양을 늘리기도 하는데 이를 데이터 증식 또는 증강(Data Augmentation)이라고 합니다.\n",
    "이미지의 경우에는 데이터 증식이 많이 사용되는데 이미지를 돌리거나 노이즈를 추가하고, 일부분을 수정하는 등으로 데이터를 증식시킵니다.\n",
    "텍스트 데이터의 경우에는 데이터를 증강하는 방법으로 번역 후 재번역을 통해 새로운 데이터를 만들어내는 역번역(Back Translation) 등의 방법이 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12e48a9b81be5ed9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. 모델의 복잡도 줄이기\n",
    "***\n",
    "\n",
    "인공 신경망의 복잡도는 은닉층(hidden layer)의 수나 매개변수의 수 등으로 결정됩니다.\n",
    "과적합 현상이 포착되었을 때, 인공 신경망 모델에 대해서 할 수 있는 한 가지 조치는 인공 신경망의 복잡도를 줄이는 것 입니다.\n",
    "\n",
    "**인공 신경망에서는 모델에 있는 매개변수들의 수를 모델의 수용력(capacity)이라고 하기도 합니다.**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c97f69d14cf15ce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. 가중치 규제(Regularization) 적용하기\n",
    "***\n",
    "\n",
    "복잡한 모델이 간단한 모델보다 과적합될 가능성이 높습니다.\n",
    "그리고 간단한 모델은 적은 수의 매개변수를 가진 모델을 말합니다.\n",
    "복잡한 모델을 좀 더 간단하게 하는 방법으로 가중치 규제(Regularization)가 있습니다.\n",
    "\n",
    "- L1 규제 : 가중치 w들의 절대값 합계를 비용 함수에 추가합니다. L1 노름이라고도 합니다.\n",
    "- L2 규제 : 모든 가중치 w들의 제곱합을 비용 함수에 추가합니다. L2 노름이라고도 합니다.\n",
    "\n",
    "L1 규제는 기존의 비용 함수에 모든 가중치에 대해서 $ \\lambda | w $를 더 한 값을 비용 함수로 하고,\n",
    "L2 규제는 기존의 비용 함수에 모든 가중치에 대해서 $ \\frac{1}{2} \\lambda w^2$를 더 한 값을 비용 함수로 합니다. \n",
    "$\\lambda$는 규제의 강도를 정하는 하이퍼파라미터입니다. \n",
    "$\\lambda$가 크다면 모델이 훈련 데이터에 대해서 적합한 매개 변수를 찾는 것보다 규제를 위해 추가된 항들을 작게 유지하는 것을 우선한다는 의미가 됩니다.\n",
    "\n",
    "이 두 식 모두 비용 함수를 최소화하기 위해서는 가중치 w들의 값이 작아져야 한다는 특징이 있습니다.\n",
    "L1 규제로 예를 들어봅시다.\n",
    "L1 규제를 사용하면 비용 함수가 최소가 되게 하는 가중치와 편향을 찾는 동시에 가중치들의 절대값의 합도 최소가 되어야 합니다.\n",
    "이렇게 되면, 가중치 w의 값들은 0 또는 0에 가까이 작아져야 하므로 어떤 특성들은 모델을 만들 때 거의 사용되지 않게 됩니다.\n",
    "\n",
    "예를 들어 \n",
    "$H(X) = w1x1 + w2x2 + w3x3 + w4x4$라는 수식이 있다고 해봅시다.\n",
    "여기에 L1 규제를 사용하였더니, $w3$의 값이 0이 되었다고 해봅시다.\n",
    "이는 $x3$특성은 사실 모델의 결과에 별 영향을 주지 못하는 특성임을 의미합니다.\n",
    "\n",
    "L2 규제는 L1 규제와는 달리 가중치들의 제곱을 최소화하므로 w의 값이 완전히 0이 되기보다는 0에 가까워지기는 경향을 띕니다.\n",
    "L1 규제는 어떤 특성들이 모델에 영향을 주고 있는지를 정확히 판단하고자 할 때 유용합니다.\n",
    "만약, 이런 판단이 필요없다면 경험적으로는 L2 규제가 더 잘 동작하므로 L2 규제를 더 권장합니다.\n",
    "인공 신경망에서 L2 규제는 가중치 감쇠(weight decay)라고도 부릅니다.\n",
    "\n",
    "책에 따라서는 Regularization를 정규화로 번역하기도 하지만, 이는 정규화(Normalization)와 혼동될 수 있으므로 규제 또는 정형화라는 번역이 바람직한 것 같습니다.\n",
    "\n",
    "인공 신경망에서 정규화(Normalization)라는 용어가 쓰이는 기법으로는 또 배치 정규화, 층 정규화 등이 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6503e0fe4d6e002f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. 드롭아웃(Dropout)\n",
    "***\n",
    "\n",
    "드롭아웃은 학습 과정에서 신경망의 일부를 사용하지 않는 방법입니다.\n",
    "\n",
    "![그림](img_42.png)\n",
    "\n",
    "위의 그림은 드롭아웃 전과 후의 신경망을 비교하고 있습니다.\n",
    "예를 들어 드롭아웃의 비율을 0.5로 한다면 학습 과정마다 랜덤으로 절반의 뉴런을 사용하지 않고, 절반의 뉴런만을 사용합니다.\n",
    "\n",
    "드롭아웃은 신경망 학습 시에만 사용하고, 예측 시에는 사용하지 않는 것이 일반적입니다.\n",
    "학습 시에 인공 신경망이 특정 뉴런 또는 특정 조합에 너무 의존적이게 되는 것을 방지해주고,\n",
    "매번 랜덤 선택으로 뉴런들을 사용하지 않으므로 서로 다른 신경망들을 앙상블하여 사용하는 것 같은 효과를 내어 과적합을 방지합니다.\n",
    "\n",
    "케라스에서는 다음과 같은 방법으로 드롭아웃을 모델에 추가할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0dbd3614567ea34"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ISY\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "WARNING:tensorflow:From C:\\Users\\ISY\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Dense\n",
    "\n",
    "max_words = 10000\n",
    "num_classes = 46\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,), activation='relu'))\n",
    "model.add(Dropout(0.5)) # 드롭아웃 추가. 비율은 50%\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5)) # 드롭아웃 추가. 비율은 50%\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T06:51:40.584202400Z",
     "start_time": "2024-02-06T06:51:31.996498600Z"
    }
   },
   "id": "2a234250d2660484",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 07-07 기울기 소실(Gradient Vanishing)과 폭주(Exploding)\n",
    "***\n",
    "\n",
    "깊은 인공 신경망을 학습하다보면 역전파 과정에서 입력층으로 갈 수록 기울기(Gradient)가 점차적으로 작아지는 현상이 발생할 수 있습니다.\n",
    "입력층에 가까운 층들에서 가중치들이 업데이트가 제대로 되지 않으면 결국 최적의 모델을 찾을 수 없게 됩니다. 이를 기울기 소실(Gradient Vanishing) 이라고 합니다.\n",
    "\n",
    "반대의 경우도 있습니다. 기울기가 점차 커지더니 가중치들이 비정상적으로 큰 값이 되면서 결국 발산되기도 합니다.\n",
    "이를 기울기 폭주(Gradient Exploding) 라고 하며, 다음 챕터에서 배울 순환 신경망(Recurrent Neural Network, RNN)에서 쉽게 발생할 수 있습니다.\n",
    "여기서는 기울기 소실 또는 기울기 폭주를 막는 방법들에 대해서 다룹니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bedd931c34856884"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. ReLU와 ReLU의 변형들\n",
    "***\n",
    "\n",
    "시그모이드 함수를 사용하면 입력의 절대값이 클 경우에 시그모이드 함수의 출력값이 0 또는 1에 수렴하면서 기울기가 0에 가까워집니다.\n",
    "그래서 역전파 과정에서 전파 시킬 기울기가 점차 사라져서 입력층 방향으로 갈 수록 제대로 역전파가 되지 않는 기울기 소실 문제가 발생할 수 있습니다.\n",
    "\n",
    "기울기 소실을 완화하는 가장 간단한 방법은 은닉층의 활성화 함수로 시그모이드나 하이퍼볼릭탄젠트 함수 대신에 ReLU나 ReLU의 변형 함수와 같은 Leaky ReLU를 사용하는 것입니다.\n",
    "\n",
    "- 은닉층에서는 시그모이드 함수를 사용하지 마세요.\n",
    "- Leaky ReLU를 사용하면 모든 입력값에 대해서 기울기가 0에 수렴하지 않아 죽은 ReLU 문제를 해결합니다.\n",
    "- 은닉층에서는 ReLU나 Leaky ReLU와 같은 ReLU 함수의 변형들을 사용하세요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6d000b1257d4be0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. 그래디언트 클리핑(Gradient Clipping)\n",
    "***\n",
    "\n",
    "그래디언트 클리핑은 말 그대로 기울기 값을 자르는 것을 의미합니다.\n",
    "기울기 폭주를 막기 위해 임계값을 넘지 않도록 값을 자릅니다. 다시 말해서 임계치만큼 크기를 감소시킵니다.\n",
    "이는 뒤에서 배울 신경망인 RNN에서 유용합니다. RNN은 역전파 과정에서 시점을 역행하면서 기울기를 구하는데, 이때 기울기가 너무 커질 수 있기 때문입니다.\n",
    "케라스에서는 다음과 같은 방법으로 그래디언트 클리핑을 수행합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cd8fd0644bb57c7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "Adam = optimizers.Adam(lr=0.0001, clipnorm=1.)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3073933586cedbde"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. 가중치 초기화(Weight initialization)\n",
    "***\n",
    "\n",
    "같은 모델을 훈련시키더라도 가중치가 초기에 어떤 값을 가졌느냐에 따라서 모델의 훈련 결과가 달라지기도 합니다.\n",
    "다시 말해 가중치 초기화만 적절히 해줘도 기울기 소실 문제과 같은 문제를 완화시킬 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bbd0b0da21f0779"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) 세이비어 초기화(Xavier Initialization)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69c1b26cd9b640c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) He 초기화(He initialization)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b20737ac136c11f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. 배치 정규화(Batch Normalization)\n",
    "***\n",
    "ReLU 계열의 함수와 He 초기화를 사용하는 것만으로도 어느 정도 기울기 소실과 폭주를 완화시킬 수 있지만,\n",
    "이 두 방법을 사용하더라도 훈련 중에 언제든 다시 발생할 수 있습니다.\n",
    "기울기 소실이나 폭주를 예방하는 또 다른 방법은 배치 정규화(Batch Normalization)입니다.\n",
    "배치 정규화는 인공 신경망의 각 층에 들어가는 입력을 평균과 분산으로 정규화하여 학습을 효율적으로 만듭니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21aaefc3f488d734"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) 내부 공변량 변화(Internal Covariate Shift)\n",
    "\n",
    "배치 정규화를 이해하기 위해서는 내부 공변량 변화(Internal Covariate Shift)를 이해할 필요가 있습니다. 내부 공변량 변화란 학습 과정에서 층 별로 입력 데이터 분포가 달라지는 현상을 말합니다. 이전 층들의 학습에 의해 이전 층의 가중치 값이 바뀌게 되면, 현재 층에 전달되는 입력 데이터의 분포가 현재 층이 학습했던 시점의 분포와 차이가 발생합니다. 배치 정규화를 제안한 논문에서는 기울기 소실/폭주 등의 딥 러닝 모델의 불안전성이 층마다 입력의 분포가 달라지기 때문이라고 주장합니다. (배치 정규화를 제안한 논문에서는 이렇게 주장했지만, 뒤에 이어서는 이에 대한 반박들이 나오기는 했습니다. 하지만 그 이유가 어찌되었든 배치 정규화가 학습을 돕는다는 것은 명백합니다.)\n",
    "\n",
    "공변량 변화는 훈련 데이터의 분포와 테스트 데이터의 분포가 다른 경우를 의미합니다.\n",
    "내부 공변량 변화는 신경망 층 사이에서 발생하는 입력 데이터의 분포 변화를 의미합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14b9acc9d37c12b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) 배치 정규화(Batch Normalization)\n",
    "\n",
    "배치 정규화(Batch Normalization)는 표현 그대로 한 번에 들어오는 배치 단위로 정규화하는 것을 말합니다.\n",
    "배치 정규화는 각 층에서 활성화 함수를 통과하기 전에 수행됩니다. 배치 정규화를 요약하면 다음과 같습니다.\n",
    "입력에 대해 평균을 0으로 만들고, 정규화를 합니다. 그리고 정규화 된 데이터에 대해서 스케일과 시프트를 수행합니다.\n",
    "이때 두 개의 매개변수 γ와 β를 사용하는데, γ는 스케일을 위해 사용하고, β는 시프트를 하는 것에 사용하며 다음 레이어에 일정한 범위의 값들만 전달되게 합니다.\n",
    "\n",
    "배치 정규화의 수식은 다음과 같습니다. 아래에서 $BN$은 배치 정규화를 의미합니다.\n",
    "\n",
    "![그림](img_43.png)\n",
    "\n",
    "배치 정규화는 학습 시 배치 단위의 평균과 분산들을 차례대로 받아 이동 평균과 이동 분산을 저장해놓았다가 테스트 할 때는 해당 배치의 평균과 분산을 구하지 않고 구해놓았던 평균과 분산으로 정규화를 합니다.\n",
    "\n",
    "- 배치 정규화를 사용하면 시그모이드 함수나 하이퍼볼릭탄젠트 함수를 사용하더라도 기울기 소실 문제가 크게 개선됩니다.\n",
    "- 가중치 초기화에 훨씬 덜 민감해집니다.\n",
    "- 훨씬 큰 학습률을 사용할 수 있어 학습 속도를 개선시킵니다.\n",
    "- 미니 배치마다 평균과 표준편차를 계산하여 사용하므로 훈련 데이터에 일종의 잡음 주입의 부수 효과로 과적합을 방지하는 효과도 냅니다. 다시 말해, 마치 드롭아웃과 비슷한 효과를 냅니다. 물론, 드롭 아웃과 함께 사용하는 것이 좋습니다.\n",
    "- 배치 정규화는 모델을 복잡하게 하며, 추가 계산을 하는 것이므로 테스트 데이터에 대한 예측 시에 실행 시간이 느려집니다. 그래서 서비스 속도를 고려하는 관점에서는 배치 정규화가 꼭 필요한지 고민이 필요합니다.\n",
    "- 배치 정규화의 효과는 굉장하지만 내부 공변량 변화때문은 아니라는 논문도 있습니다. : [논문 링크](https://arxiv.org/pdf/1805.11604.pdf)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea02b18c2d268e9b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3) 배치 정규화의 한계\n",
    "\n",
    "배치 정규화는 뛰어난 방법이지만 몇 가지 한계가 존재합니다.\n",
    "\n",
    "1. 미니 배치 크기에 의존적이다.\n",
    "배치 정규화는 너무 작은 배치 크기에서는 잘 동작하지 않을 수 있습니다. 단적으로 배치 크기를 1로 하게되면 분산은 0이 됩니다. 작은 미니 배치에서는 배치 정규화의 효과가 극단적으로 작용되어 훈련에 악영향을 줄 수 있습니다. 배치 정규화를 적용할때는 작은 미니 배치보다는 크기가 어느정도 되는 미니 배치에서 하는 것이 좋습니다. 이처럼 배치 정규화는 배치 크기에 의존적인 면이 있습니다.\n",
    "\n",
    "<br/>\n",
    "\n",
    "2. RNN에 적용하기 어렵다.\n",
    "뒤에서 배우겠지만, RNN은 각 시점(time step)마다 다른 통계치를 가집니다. 이는 RNN에 배치 정규화를 적용하는 것을 어렵게 만듭니다. RNN에서 배치 정규화를 적용하기 위한 몇 가지 논문이 제시되어 있지만, 여기서는 이를 소개하는 대신 배치 크기에도 의존적이지 않으며, RNN에도 적용하는 것이 수월한 층 정규화(layer normalization)라는 방법을 소개하고자 합니다.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67c901ad80a473c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. 층 정규화(Layer Normalization)\n",
    "***\n",
    "\n",
    "층 정규화를 이해하기에 앞서 배치 정규화를 시각화해보겠습니다. 다음은 $m$이 3이고, 특성의 수가 4일 때의 배치 정규화를 보여줍니다.\n",
    "미니 배치란 동일한 특성(feature) 개수들을 가진 다수의 샘플들을 의미함을 상기합시다.\n",
    "\n",
    "![그림](img_44.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "239d0cbc3bde3e10"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 07-08 케라스(Keras) 훑어보기\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad42d00e3811cec2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. 전처리(Preprocessing)\n",
    "***\n",
    "Tokenizer() : 토큰화와 정수 인코딩을 위해 사용됩니다. 다음은 훈련 데이터로부터 단어 집합을 생성하고, 해당 단어 집합으로 임의의 문장을 정수 인코딩하는 과정을 보여줍니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "723132683c723eb7"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 :  [1, 2, 3, 4, 6, 7]\n",
      "단어 집합 :  {'the': 1, 'earth': 2, 'is': 3, 'an': 4, 'awesome': 5, 'place': 6, 'live': 7}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "train_text = \"The earth is an awesome place live\"\n",
    "\n",
    "# 단어 집합 생성\n",
    "tokenizer.fit_on_texts([train_text])\n",
    "\n",
    "# 정수 인코딩\n",
    "sub_text = \"The earth is an great place live\"\n",
    "sequences = tokenizer.texts_to_sequences([sub_text])[0]\n",
    "\n",
    "print(\"정수 인코딩 : \",sequences)\n",
    "print(\"단어 집합 : \",tokenizer.word_index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T07:34:34.017023400Z",
     "start_time": "2024-02-06T07:34:33.991854Z"
    }
   },
   "id": "30bb27f92f6050f3",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "출력 결과를 보면 great는 단어 집합(vocabulary)에 없으므로 출력되지 않습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69ad2ec7ab6cec10"
  },
  {
   "cell_type": "markdown",
   "source": [
    "pad_sequence() : 전체 훈련 데이터에서 각 샘플의 길이는 서로 다를 수 있습니다. 또는 각 문서 또는 각 문장은 단어의 수가 제각각입니다. 모델의 입력으로 사용하려면 모든 샘플의 길이를 동일하게 맞추어야할 때가 있습니다. 이를 자연어 처리에서는 패딩(padding) 작업이라고 하는데, 보통 숫자 0을 넣어서 길이가 다른 샘플들의 길이를 맞춰줍니다. 케라스에서는 pad_sequence()를 사용합니다. pad_sequence()는 정해준 길이보다 길이가 긴 샘플은 값을 일부 자르고, 정해준 길이보다 길이가 짧은 샘플은 값을 0으로 채웁니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21045a3fea0a4cdd"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 2, 3],\n       [4, 5, 6],\n       [0, 7, 8]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequences([[1, 2, 3], [3, 4, 5, 6], [7, 8]], maxlen=3, padding='pre')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T07:35:08.173658800Z",
     "start_time": "2024-02-06T07:35:08.134752800Z"
    }
   },
   "id": "30ec6147875fc6a5",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "첫번째 인자 = 패딩을 진행할 데이터\n",
    "maxlen = 모든 데이터에 대해서 정규화 할 길이\n",
    "padding = 'pre'를 선택하면 앞에 0을 채우고 'post'를 선택하면 뒤에 0을 채움."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c36f8621ad3d74f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. 워드 임베딩(Word Embedding)\n",
    "***\n",
    "\n",
    "워드 임베딩 챕터에서 다루겠지만, 워드 임베딩이란 텍스트 내의 단어들을 밀집 벡터(dense vector)로 만드는 것을 말합니다. 앞서 배운 개념인 원-핫 벡터와 비교해봅시다. 원-핫 벡터는 대부분이 0의 값을 가지고, 단 하나의 1의 값을 가지는 벡터이며 벡터의 차원이 대체적으로 크다는 성질을 가졌습니다.\n",
    "\n",
    "Ex) [0 1 0 0 0 0 ... 중략 ... 0 0 0 0 0 0 0] # 차원이 굉장히 크면서 대부분의 값이 0\n",
    "원-핫 벡터는 단어 집합의 크기만큼 벡터의 차원을 가지며 단어 벡터 간의 유의미한 유사도를 구할 수 없다는 단점이 있습니다. 반면 워드 임베딩으로부터 얻은 임베딩 벡터는 상대적으로 저차원을 가지며 모든 원소의 값이 실수입니다.\n",
    "\n",
    "Ex) [0.1 -1.2 0.8 0.2 1.8] # 상대적으로 저차원이며 실수값을 가짐\n",
    "간단히 표로 정리하면 아래와 같습니다.\n",
    "\n",
    "![표](img_45.png)\n",
    "\n",
    "단어를 원-핫 벡터로 만드는 과정을 원-핫 인코딩이라고 한다면, 단어를 밀집 벡터로 만드는 작업을 워드 임베딩(word embedding) 이라고 합니다. 밀집 벡터는 워드 임베딩 과정을 통해 나온 결과므로 임베딩 벡터(embedding vector)라고도 합니다. 원-핫 벡터의 차원이 주로 20,000 이상을 넘어가는 것과는 달리 임베딩 벡터는 주로 256, 512, 1024 등의 차원을 가집니다. 임베딩 벡터는 초기에는 랜덤값을 가지지만, 인공 신경망의 가중치가 학습되는 방법과 같은 방식으로 값이 학습되며 변경됩니다.\n",
    "\n",
    "Embedding() : Embedding()은 단어를 밀집 벡터로 만드는 역할을 합니다. 인공 신경망 용어로는 임베딩 층(embedding layer)을 만드는 역할을 합니다. Embedding()은 정수 인코딩이 된 단어들을 입력을 받아서 임베딩을 수행합니다.\n",
    "\n",
    "Embedding()은 (number of samples, input_length)인 2D 정수 텐서를 입력받습니다. 이때 각 sample은 정수 인코딩이 된 결과로, 정수의 시퀀스입니다. Embedding()은 워드 임베딩 작업을 수행하고 (number of samples, input_length, embedding word dimensionality)인 3D 텐서를 리턴합니다.\n",
    "\n",
    "아래의 코드는 실제 동작되는 코드가 아니라 의사 코드(pseudo-code)로 임베딩의 개념 이해를 돕기 위해서 작성되었습니다.\n",
    "\n",
    "\n",
    "```python\n",
    "# 1. 토큰화\n",
    "tokenized_text = [['Hope', 'to', 'see', 'you', 'soon'], ['Nice', 'to', 'see', 'you', 'again']]\n",
    "\n",
    "# 2. 각 단어에 대한 정수 인코딩\n",
    "encoded_text = [[0, 1, 2, 3, 4],[5, 1, 2, 3, 6]]\n",
    "\n",
    "# 3. 위 정수 인코딩 데이터가 아래의 임베딩 층의 입력이 된다.\n",
    "vocab_size = 7\n",
    "embedding_dim = 2\n",
    "Embedding(vocab_size, embedding_dim, input_length=5)\n",
    "\n",
    "# 각 정수는 아래의 테이블의 인덱스로 사용되며 Embedding()은 각 단어마다 임베딩 벡터를 리턴한다.\n",
    "+------------+------------+\n",
    "|   index    | embedding  |\n",
    "+------------+------------+\n",
    "|     0      | [1.2, 3.1] |\n",
    "|     1      | [0.1, 4.2] |\n",
    "|     2      | [1.0, 3.1] |\n",
    "|     3      | [0.3, 2.1] |\n",
    "|     4      | [2.2, 1.4] |\n",
    "|     5      | [0.7, 1.7] |\n",
    "|     6      | [4.1, 2.0] |\n",
    "+------------+------------+\n",
    "\n",
    "# 위의 표는 임베딩 벡터가 된 결과를 예로서 정리한 것이고 Embedding()의 출력인 3D 텐서를 보여주는 것이 아님.\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8f38b71cdeeeced"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Embedding()의 대표적인 인자는 다음과 같습니다.\n",
    "\n",
    "첫번째 인자 = 단어 집합의 크기. 즉, 총 단어의 개수\n",
    "두번째 인자 = 임베딩 벡터의 출력 차원. 결과로서 나오는 임베딩 벡터의 크기\n",
    "input_length = 입력 시퀀스의 길이"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58bfad43e7c8d25"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. 모델링(Modeling)\n",
    "***\n",
    "\n",
    "Sequential() : 인공 신경망 챕터에서 입력층, 은닉층, 출력층에 대해서 배웠습니다. 케라스에서는 이러한 층을 구성하기 위해 Sequential()을 사용합니다. Sequential()을 model로 선언한 뒤에 model.add()라는 코드를 통해 층을 단계적으로 추가합니다. 아래는 model.add()로 층을 추가하는 예제 코드를 보여줍니다. 실제로는 세 개의 온점 대신에 층의 이름을 기재해야 합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "894f6b8787c6e9ba"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(...) # 층 추가\n",
    "model.add(...) # 층 추가\n",
    "model.add(...) # 층 추가"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e02fdf1381944e2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Embedding()을 통해 생성하는 임베딩 층(embedding layer)을 추가하는 예시를 봅시다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "407c3b47a46dc3fb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(vocab_size, output_dim, input_length))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85ac19732f89df67"
  },
  {
   "cell_type": "markdown",
   "source": [
    "전결합층(fully-connected layer)을 추가하는 예시를 보겠습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d52ab41bc86f028"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=3, activation='relu'))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59fe600ba7ad36f8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "위의 코드에서 Dense()는 한번 사용되었지만 더 많은 층을 추가할 수 있습니다. Dense()의 대표적인 인자를 보겠습니다.\n",
    "\n",
    "첫번째 인자 = 출력 뉴런의 수.\n",
    "input_dim = 입력 뉴런의 수. (입력의 차원)\n",
    "activation = 활성화 함수.\n",
    "- linear : 디폴트 값으로 별도 활성화 함수 없이 입력 뉴런과 가중치의 계산 결과 그대로 출력.\n",
    "- sigmoid : 이진 분류 문제에서 출력층에 주로 사용되는 활성화 함수.\n",
    "- softmax : 셋 이상의 선택지 중 하나를 택하는 다중 클래스 분류 문제에서 출력층에 주로 사용되는 활성화 함수.\n",
    "- relu : 은닉층에 주로 사용되는 활성화 함수."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddcb6ea3bcf57adf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "위 코드에서 사용된 Dense()의 의미를 보겠습니다. 첫번째 인자의 값은 1인데 이는 총 1개의 출력 뉴런을 의미합니다. Dense()의 두번째 인자인 input_dim은 입력층의 뉴런 수를 의미합니다. 이 경우에는 3입니다. 3개의 입력층 뉴런과 1개의 출력층 뉴런을 만들었습니다. 이를 시각화하면 다음과 같습니다.\n",
    "\n",
    "![그림](img_46.png)\n",
    "\n",
    "Dense()를 사용하여 전결합층을 하나 더 추가해보겠습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea31fd1de7cf811e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) # 출력층"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c48bdec8f53a9846"
  },
  {
   "cell_type": "markdown",
   "source": [
    "이번에는 Dense()가 두 번 사용되었습니다. Dense()가 처음 사용되었을 때와 추가로 사용되었을 때의 인자는 조금 다릅니다. 첫번째 사용된 Dense()의 8이라는 값은 더 이상 출력층의 뉴런이 아니라 은닉층의 뉴런입니다. 층이 하나 더 생겼기 때문입니다.\n",
    "\n",
    "두번째 Dense()는 input_dim 인자가 없는데, 이는 이미 이전 층의 뉴런 수가 8개임을 알고있기 때문입니다. 위 코드에서 두번째 Dense()는 마지막 층이므로, 첫번째 인자 1은 결국 출력층의 뉴런 개수가 됩니다. 이를 시각화하면 다음과 같습니다.\n",
    "\n",
    "![그림](img_47.png)\n",
    "\n",
    "이 외에도 LSTM, GRU, Convolution2D, BatchNormalization 등 다양한 층을 만들 수 있습니다. 일부는 뒤에서 배웁니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52b49cf2c07826fe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "summary() : 모델의 정보를 요약해서 보여줍니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62c0e04b3db3ba5b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               2560256   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 46)                5934      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2599086 (9.91 MB)\n",
      "Trainable params: 2599086 (9.91 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T08:06:55.681972300Z",
     "start_time": "2024-02-06T08:06:55.576554600Z"
    }
   },
   "id": "2cf495d154318ac1",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. 컴파일(Compile)과 훈련(Training)\n",
    "***\n",
    "\n",
    "아래의 코드는 RNN을 이용하여 이진 분류를 하는 전형적인 코드를 보여줍니다. RNN은 다음 챕터에서 학습합니다.\n",
    "임베딩층, 은닉층, 출력층을 추가하여 모델을 설계한 후에, 마지막으로 컴파일을 합니다.\n",
    "\n",
    "compile() : 모델을 기계가 이해할 수 있도록 컴파일 합니다. 손실 함수와 옵티마이저, 메트릭 함수를 선택합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b1b81559c47b368"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN, Embedding, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "vocab_size = 10000\n",
    "embedding_dim = 32\n",
    "hidden_units = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(SimpleRNN(hidden_units))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab80155f68d0a3a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "optimizer = 훈련 과정을 설정하는 옵티마이저를 설정합니다.\n",
    "loss = 훈련 과정에서 사용할 손실 함수(loss function)를 설정합니다.\n",
    "metrics = 훈련을 모니터링하기 위한 지표를 선택합니다.\n",
    "\n",
    "대표적으로 사용되는 손실 함수와 활성화 함수의 조합은 다음과 같습니다. 더 많은 함수는 공식문서를 참고바랍니다.\n",
    "\n",
    "![그림](img_48.png)\n",
    "\n",
    "sparse_categorical_crossentropy는 categorical_crossentropy와 동일하게 다중 클래스 분류에서 사용하지만,\n",
    "레이블을 원-핫 인코딩하지 않고 정수 인코딩 된 상태에서 수행 가능하다는 점이 다릅니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b88cebf1a5e677aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "fit() : 모델을 학습합니다. 모델이 오차로부터 매개 변수를 업데이트 시키는 과정을 학습, 훈련, 또는 적합(fitting)이라고 하는데, 모델이 데이터에 적합해가는 과정이기 때문입니다. 그런 의미에서 fit()은 모델의 훈련을 시작합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7700fd90938f5d72"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 위의 compile() 코드의 연장선상인 코드\n",
    "# model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc4f0f0aee391d29"
  },
  {
   "cell_type": "markdown",
   "source": [
    "첫번째 인자 = 훈련 데이터에 해당됩니다.\n",
    "두번째 인자 = 지도 학습에서 레이블 데이터에 해당됩니다.\n",
    "epochs = 에포크. 에포크 1은 전체 데이터를 한 차례 훑고 지나갔음을 의미함. 정수값 기재 필요. 총 훈련 횟수를 정의합니다.\n",
    "batch_size = 배치 크기. 기본값은 32. 미니 배치 경사 하강법을 사용하고 싶지 않을 경우에는 batch_size=None을 기재합니다.\n",
    "\n",
    "좀 더 많은 인자를 사용할 때를 보겠습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cef5cfc5bd720763"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0, validation_data(X_val, y_val))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85a4b20f025d9a4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "validation_data(x_val, y_val) = 검증 데이터(validation data)를 사용합니다. 일반적으로 검증 데이터를 사용하면 각 에포크마다 검증 데이터의 정확도나 오차를 함께 출력하는데, 이 정확도는 훈련이 잘 되고 있는지를 보여줄 뿐이며 실제로 모델이 검증 데이터를 학습하지는 않습니다. 검증 데이터의 오차(loss)가 낮아지다가 높아지기 시작하면 이는 과적합(overfitting)의 신호입니다.\n",
    "\n",
    "validation_split = validation_data와 동일하게 검증 데이터를 사용하기 위한 용도로 validation_data 대신 사용할 수 있습니다. 검증 데이터를 지정하는 것이 아니라 훈련 데이터와 훈련 데이터의 레이블인 X_train과 y_train에서 일정 비율 분리하여 이를 검증 데이터로 사용합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "215d871d016c0b20"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 훈련 데이터의 20%를 검증 데이터로 사용.\n",
    "# model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0, validation_split=0.2))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "447aaa9e4ee0309d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "verbose = 학습 중 출력되는 문구를 설정합니다.\n",
    "- 0 : 아무 것도 출력하지 않습니다.\n",
    "- 1 : 훈련의 진행도를 보여주는 진행 막대를 보여줍니다.\n",
    "- 2 : 미니 배치마다 손실 정보를 출력합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfef7fdc85ef0d56"
  },
  {
   "cell_type": "markdown",
   "source": [
    "아래는 verbose의 값이 1일 때와 2일 때를 보여줍니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b16ee1bed0d8378"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# verbose = 1일 경우.\n",
    "# Epoch 88/100\n",
    "# 7/7 [==============================] - 0s 143us/step - loss: 0.1029 - acc: 1.0000"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "252d6246eeef3673"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# verbose = 2일 경우.\n",
    "# Epoch 88/100\n",
    "#  - 0s - loss: 0.1475 - acc: 1.0000"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21ae188ce9553368"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. 평가(Evaluation)와 예측(Prediction)\n",
    "***\n",
    "\n",
    "evaluate() : 테스트 데이터를 통해 학습한 모델에 대한 정확도를 평가합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cc362f7afcefaa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 위의 fit() 코드의 연장선상인 코드\n",
    "# model.evaluate(X_test, y_test, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2959cbb9a60786e7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "첫번째 인자 = 테스트 데이터에 해당됩니다.\n",
    "두번째 인자 = 지도 학습에서 레이블 테스트 데이터에 해당됩니다.\n",
    "batch_size = 배치 크기."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fc57e9b88b78188"
  },
  {
   "cell_type": "markdown",
   "source": [
    "predict() : 임의의 입력에 대한 모델의 출력값을 확인합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8db1a2e378fd84b3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 위의 fit() 코드의 연장선상인 코드\n",
    "# model.predict(X_input, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ba8c9bcccb6baa3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "첫번째 인자 = 예측하고자 하는 데이터.\n",
    "batch_size = 배치 크기."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "551f4f5b9645ffe9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. 모델의 저장(Save)과 로드(Load)\n",
    "***\n",
    "\n",
    "복습을 위한 스터디나 실제 어플리케이션 개발 단계에서 구현한 모델을 저장하고 불러오는 일은 중요합니다. 모델을 저장한다는 것은 학습이 끝난 신경망의 구조를 보존하고 계속해서 사용할 수 있다는 의미입니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38deb0e7500a15fd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "save() : 인공 신경망 모델을 hdf5 파일에 저장합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10b83015a182e227"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.save(\"model_name.h5\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dba1c2ef57fee9f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "load_model() : 저장해둔 모델을 불러옵니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cca8e2c331448eec"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"model_name.h5\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b738fbd12487a9da"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 07-09 케라스의 함수형 API(Keras Functional API)\n",
    "***\n",
    "\n",
    "더욱 복잡한 모델을 생성할 수 있는 방식인 Functional API(함수형 API)에 대해서 알아봅니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a999bfa31e6b8fe8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Sequential API로 만든 모델\n",
    "***\n",
    "\n",
    "두 가지 API의 차이를 이해하기 위해서 앞서 배운 Sequential API를 사용하여 기본적인 모델을 만들어봅시다.\n",
    "\n",
    "아래와 같은 방식은 직관적이고 편리하지만 단순히 층을 쌓는 것만으로는 구현할 수 없는 복잡한 신경망을 구현할 수 없습니다. 따라서 초심자에게 적합한 API이지만, 전문가가 되기 위해서는 결과적으로 Functional API를 학습해야 합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "398de512d56efbe5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(3, input_dim=4, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T03:35:47.743791400Z",
     "start_time": "2024-02-08T03:35:47.694937800Z"
    }
   },
   "id": "6e0584d3059df25b",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Functional API로 만든 모델\n",
    "***\n",
    "\n",
    "Functional API는 각 층을 일종의 함수(function)로서 정의합니다. 그리고 각 함수를 조합하기 위한 연산자들을 제공하는데, 이를 이용하여 신경망을 설계합니다.\n",
    "Functional API로 FFNN, RNN 등 다양한 모델을 만들면서 기존의 sequential API와의 차이를 이해해봅시다.\n",
    "\n",
    "- Functional API는 입력의 크기(shape)를 명시한 입력층(Input layer)을 모델의 앞단에 정의해주어야 합니다.\n",
    "\n",
    "#### 1) 전결합 피드 포워드 신경망(Fully-connected FFNN)\n",
    "Sequential API와는 다르게 functional API에서는 입력 데이터의 크기(shape)를 인자로 입력층을 정의해주어야 합니다.\n",
    "피드 포워드 신경망(Fully-connected FFNN)을 만든다고 가정해보겠습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbfcc228ea009448"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(10,))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T03:39:39.356367Z",
     "start_time": "2024-02-08T03:39:39.320615400Z"
    }
   },
   "id": "6c4f4742e96678eb",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "위의 코드는 10개의 입력을 받는 입력층을 보여줍니다. 위의 코드에 은닉층과 출력층을 추가해봅시다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78eebba662c10035"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "inputs = Input(shape=(10,))\n",
    "hidden1 = Dense(64, activation='relu')(inputs)  # <- 새로 추가\n",
    "hidden2 = Dense(64, activation='relu')(hidden1) # <- 새로 추가\n",
    "output = Dense(1, activation='sigmoid')(hidden2) # <- 새로 추가"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T04:05:57.088378900Z",
     "start_time": "2024-02-08T04:05:57.020536800Z"
    }
   },
   "id": "44de234e4e7ac125",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "위의 코드를 하나의 모델로 구성해보겠습니다. 이는 Model에 입력 텐서와 출력 텐서를 정의하여 완성됩니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff190fef1db9c1d5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "inputs = Input(shape=(10,))\n",
    "hidden1 = Dense(64, activation='relu')(inputs)\n",
    "hidden2 = Dense(64, activation='relu')(hidden1)\n",
    "output = Dense(1, activation='sigmoid')(hidden2)\n",
    "model = Model(inputs=inputs, outputs=output) # <- 새로 추가"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T03:40:09.683401500Z",
     "start_time": "2024-02-08T03:40:09.613479300Z"
    }
   },
   "id": "61d1365c752dda88",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "지금까지의 내용을 정리하면 다음과 같습니다.\n",
    "\n",
    "- Input() 함수에 입력의 크기를 정의합니다.\n",
    "- 이전층을 다음층 함수의 입력으로 사용하고, 변수에 할당합니다.\n",
    "- Model() 함수에 입력과 출력을 정의합니다.\n",
    "\n",
    "이를 model로 저장하면 sequential API를 사용할 때와 마찬가지로 model.compile, model.fit 등을 사용 가능합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e5f7b1218946766"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.fit(data, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T04:08:28.858940900Z",
     "start_time": "2024-02-08T04:08:28.794018400Z"
    }
   },
   "id": "7bb668d46e79f527",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "이번에는 변수명을 달리해서 FFNN을 만들어보겠습니다. 이번에는 은닉층과 출력층의 변수를 전부 x로 통일하였습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7f7836f8178f4a2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "inputs = Input(shape=(10,))\n",
    "x = Dense(8, activation=\"relu\")(inputs)\n",
    "x = Dense(4, activation=\"relu\")(x)\n",
    "x = Dense(1, activation=\"linear\")(x)\n",
    "model = Model(inputs, x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T04:08:44.326563500Z",
     "start_time": "2024-02-08T04:08:44.249482700Z"
    }
   },
   "id": "9a12b5bbcea97a6f",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "이번에는 위에서 배운 내용을 바탕으로 선형 회귀와 로지스틱 회귀를 Functional API로 구현해봅시다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42551dd2a1ae68f5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) 선형 회귀(Linear Regression)\n",
    "\n",
    "앞서 Sequential API로 구현했던 선형 회귀를 Functional API로 구현해봅시다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af1f8db6d6061146"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 4963.6479 - mse: 4963.6479\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 611.9047 - mse: 611.9047\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 76.4535 - mse: 76.4535\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5683 - mse: 10.5683\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4597 - mse: 2.4597\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4602 - mse: 1.4602\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3353 - mse: 1.3353\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3181 - mse: 1.3181\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3141 - mse: 1.3141\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3118 - mse: 1.3118\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3097 - mse: 1.3097\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3077 - mse: 1.3077\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3056 - mse: 1.3056\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3036 - mse: 1.3036\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3016 - mse: 1.3016\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2996 - mse: 1.2996\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2977 - mse: 1.2977\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2957 - mse: 1.2957\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2938 - mse: 1.2938\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2919 - mse: 1.2919\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2900 - mse: 1.2900\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2881 - mse: 1.2881\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2862 - mse: 1.2862\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2844 - mse: 1.2844\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2825 - mse: 1.2825\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2807 - mse: 1.2807\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2789 - mse: 1.2789\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2771 - mse: 1.2771\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2753 - mse: 1.2753\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2735 - mse: 1.2735\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2718 - mse: 1.2718\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2700 - mse: 1.2700\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2683 - mse: 1.2683\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2666 - mse: 1.2666\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2649 - mse: 1.2649\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2632 - mse: 1.2632\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2616 - mse: 1.2616\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2599 - mse: 1.2599\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2583 - mse: 1.2583\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2567 - mse: 1.2567\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2550 - mse: 1.2550\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2534 - mse: 1.2534\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2519 - mse: 1.2519\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2503 - mse: 1.2503\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2487 - mse: 1.2487\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2472 - mse: 1.2472\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2456 - mse: 1.2456\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2441 - mse: 1.2441\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2426 - mse: 1.2426\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2411 - mse: 1.2411\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2396 - mse: 1.2396\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2381 - mse: 1.2381\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2367 - mse: 1.2367\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2352 - mse: 1.2352\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2338 - mse: 1.2338\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2324 - mse: 1.2324\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2310 - mse: 1.2310\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2296 - mse: 1.2296\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2282 - mse: 1.2282\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2268 - mse: 1.2268\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2254 - mse: 1.2254\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2241 - mse: 1.2241\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2227 - mse: 1.2227\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2214 - mse: 1.2214\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2201 - mse: 1.2201\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2187 - mse: 1.2187\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2174 - mse: 1.2174\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2161 - mse: 1.2161\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2149 - mse: 1.2149\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2136 - mse: 1.2136\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2123 - mse: 1.2123\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2111 - mse: 1.2111\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2098 - mse: 1.2098\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2086 - mse: 1.2086\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2074 - mse: 1.2074\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2062 - mse: 1.2062\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2050 - mse: 1.2050\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2038 - mse: 1.2038\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2026 - mse: 1.2026\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2014 - mse: 1.2014\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2003 - mse: 1.2003\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1991 - mse: 1.1991\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1980 - mse: 1.1980\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1969 - mse: 1.1969\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1957 - mse: 1.1957\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1946 - mse: 1.1946\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1935 - mse: 1.1935\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1924 - mse: 1.1924\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1913 - mse: 1.1913\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1903 - mse: 1.1903\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1892 - mse: 1.1892\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1881 - mse: 1.1881\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1871 - mse: 1.1871\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1860 - mse: 1.1860\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1850 - mse: 1.1850\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1840 - mse: 1.1840\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1830 - mse: 1.1830\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1819 - mse: 1.1819\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1809 - mse: 1.1809\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1800 - mse: 1.1800\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1790 - mse: 1.1790\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1780 - mse: 1.1780\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1770 - mse: 1.1770\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1761 - mse: 1.1761\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1751 - mse: 1.1751\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1742 - mse: 1.1742\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1732 - mse: 1.1732\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1723 - mse: 1.1723\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1714 - mse: 1.1714\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1705 - mse: 1.1705\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1696 - mse: 1.1696\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1687 - mse: 1.1687\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1678 - mse: 1.1678\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1669 - mse: 1.1669\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1660 - mse: 1.1660\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1651 - mse: 1.1651\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1643 - mse: 1.1643\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1634 - mse: 1.1634\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1626 - mse: 1.1626\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1617 - mse: 1.1617\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1609 - mse: 1.1609\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1601 - mse: 1.1601\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1592 - mse: 1.1592\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1584 - mse: 1.1584\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1576 - mse: 1.1576\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1568 - mse: 1.1568\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1560 - mse: 1.1560\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1552 - mse: 1.1552\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1545 - mse: 1.1545\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1537 - mse: 1.1537\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1529 - mse: 1.1529\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1521 - mse: 1.1521\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1514 - mse: 1.1514\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1506 - mse: 1.1506\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1499 - mse: 1.1499\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1492 - mse: 1.1492\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1484 - mse: 1.1484\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1477 - mse: 1.1477\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1470 - mse: 1.1470\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1463 - mse: 1.1463\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1456 - mse: 1.1456\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1449 - mse: 1.1449\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1442 - mse: 1.1442\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1435 - mse: 1.1435\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1428 - mse: 1.1428\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1421 - mse: 1.1421\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1414 - mse: 1.1414\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1408 - mse: 1.1408\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1401 - mse: 1.1401\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1394 - mse: 1.1394\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1388 - mse: 1.1388\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1381 - mse: 1.1381\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1375 - mse: 1.1375\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1369 - mse: 1.1369\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1362 - mse: 1.1362\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1356 - mse: 1.1356\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1350 - mse: 1.1350\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1344 - mse: 1.1344\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1338 - mse: 1.1338\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1332 - mse: 1.1332\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1326 - mse: 1.1326\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1320 - mse: 1.1320\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1314 - mse: 1.1314\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1308 - mse: 1.1308\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1302 - mse: 1.1302\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1296 - mse: 1.1296\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1290 - mse: 1.1290\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1285 - mse: 1.1285\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1279 - mse: 1.1279\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1274 - mse: 1.1274\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1268 - mse: 1.1268\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1263 - mse: 1.1263\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1257 - mse: 1.1257\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1252 - mse: 1.1252\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1246 - mse: 1.1246\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1241 - mse: 1.1241\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1236 - mse: 1.1236\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1231 - mse: 1.1231\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1225 - mse: 1.1225\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1220 - mse: 1.1220\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1215 - mse: 1.1215\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1210 - mse: 1.1210\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1205 - mse: 1.1205\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1200 - mse: 1.1200\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1195 - mse: 1.1195\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1190 - mse: 1.1190\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1186 - mse: 1.1186\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1181 - mse: 1.1181\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1176 - mse: 1.1176\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1171 - mse: 1.1171\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1166 - mse: 1.1166\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1162 - mse: 1.1162\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1157 - mse: 1.1157\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1153 - mse: 1.1153\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1148 - mse: 1.1148\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1144 - mse: 1.1144\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1139 - mse: 1.1139\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1135 - mse: 1.1135\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1130 - mse: 1.1130\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1126 - mse: 1.1126\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1122 - mse: 1.1122\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1117 - mse: 1.1117\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1113 - mse: 1.1113\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1109 - mse: 1.1109\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1105 - mse: 1.1105\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1101 - mse: 1.1101\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1096 - mse: 1.1096\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1092 - mse: 1.1092\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1088 - mse: 1.1088\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1084 - mse: 1.1084\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1080 - mse: 1.1080\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1076 - mse: 1.1076\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1072 - mse: 1.1072\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1069 - mse: 1.1069\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1065 - mse: 1.1065\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1061 - mse: 1.1061\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1057 - mse: 1.1057\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1053 - mse: 1.1053\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1050 - mse: 1.1050\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1046 - mse: 1.1046\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1042 - mse: 1.1042\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1039 - mse: 1.1039\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1035 - mse: 1.1035\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1031 - mse: 1.1031\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1028 - mse: 1.1028\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1024 - mse: 1.1024\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1021 - mse: 1.1021\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1017 - mse: 1.1017\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1014 - mse: 1.1014\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1011 - mse: 1.1011\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1007 - mse: 1.1007\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1004 - mse: 1.1004\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1001 - mse: 1.1001\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0997 - mse: 1.0997\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0994 - mse: 1.0994\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0991 - mse: 1.0991\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0988 - mse: 1.0988\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0984 - mse: 1.0984\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0981 - mse: 1.0981\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0978 - mse: 1.0978\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0975 - mse: 1.0975\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0972 - mse: 1.0972\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0969 - mse: 1.0969\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0966 - mse: 1.0966\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0963 - mse: 1.0963\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0960 - mse: 1.0960\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0957 - mse: 1.0957\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0954 - mse: 1.0954\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0951 - mse: 1.0951\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0948 - mse: 1.0948\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0945 - mse: 1.0945\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0942 - mse: 1.0942\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0940 - mse: 1.0940\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0937 - mse: 1.0937\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0934 - mse: 1.0934\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0931 - mse: 1.0931\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0929 - mse: 1.0929\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0926 - mse: 1.0926\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0923 - mse: 1.0923\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0921 - mse: 1.0921\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0918 - mse: 1.0918\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0915 - mse: 1.0915\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0913 - mse: 1.0913\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0910 - mse: 1.0910\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0907 - mse: 1.0907\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0905 - mse: 1.0905\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0902 - mse: 1.0902\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0900 - mse: 1.0900\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0898 - mse: 1.0898\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0895 - mse: 1.0895\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0893 - mse: 1.0893\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0890 - mse: 1.0890\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0888 - mse: 1.0888\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0885 - mse: 1.0885\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0883 - mse: 1.0883\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0881 - mse: 1.0881\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0878 - mse: 1.0878\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0876 - mse: 1.0876\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0874 - mse: 1.0874\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0872 - mse: 1.0872\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0869 - mse: 1.0869\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0867 - mse: 1.0867\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0865 - mse: 1.0865\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0863 - mse: 1.0863\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0861 - mse: 1.0861\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0859 - mse: 1.0859\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0856 - mse: 1.0856\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0854 - mse: 1.0854\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0852 - mse: 1.0852\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0850 - mse: 1.0850\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0848 - mse: 1.0848\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0846 - mse: 1.0846\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0844 - mse: 1.0844\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0842 - mse: 1.0842\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0840 - mse: 1.0840\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0838 - mse: 1.0838\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0836 - mse: 1.0836\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0834 - mse: 1.0834\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0832 - mse: 1.0832\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0830 - mse: 1.0830\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x1d17acf9390>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "X = [1, 2, 3, 4, 5, 6, 7, 8, 9] # 공부하는 시간\n",
    "y = [11, 22, 33, 44, 53, 66, 77, 87, 95] # 각 공부하는 시간에 맵핑되는 성적\n",
    "\n",
    "inputs = Input(shape=(1,))\n",
    "output = Dense(1, activation='linear')(inputs)\n",
    "linear_model = Model(inputs, output)\n",
    "\n",
    "sgd = optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "linear_model.compile(optimizer=sgd, loss='mse', metrics=['mse'])\n",
    "linear_model.fit(X, y, epochs=300)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T04:10:01.408780200Z",
     "start_time": "2024-02-08T04:09:53.656590Z"
    }
   },
   "id": "caf99d88a1785af8",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "그 외에 다양한 다른 예제들을 구현해봅시다.\n",
    "\n",
    "#### 3) 로지스틱 회귀(Logistic Regression)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b85b20f5e44ff049"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(3,))\n",
    "output = Dense(1, activation='sigmoid')(inputs)\n",
    "logistic_model = Model(inputs, output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T04:11:31.579932800Z",
     "start_time": "2024-02-08T04:11:31.518302300Z"
    }
   },
   "id": "220fa1ed5d653e48",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4) 다중 입력을 받는 모델(model that accepts multiple inputs)\n",
    "\n",
    "functional API를 사용하면 아래와 같이 다중 입력과 다중 출력을 가지는 모델도 만들 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fcea813729b390a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 최종 완성된 다중 입력, 다중 출력 모델의 예\n",
    "# model = Model(inputs=[a1, a2], outputs=[b1, b2, b3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T04:11:44.899984100Z",
     "start_time": "2024-02-08T04:11:44.864170800Z"
    }
   },
   "id": "48552e5f6bb3ee5a",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "이번에는 다중 입력을 받는 모델을 입력층부터 출력층까지 설계해보겠습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf0afdba9d361be4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 두 개의 입력층을 정의\n",
    "inputA = Input(shape=(64,))\n",
    "inputB = Input(shape=(128,))\n",
    "\n",
    "# 첫번째 입력층으로부터 분기되어 진행되는 인공 신경망을 정의\n",
    "x = Dense(16, activation=\"relu\")(inputA)\n",
    "x = Dense(8, activation=\"relu\")(x)\n",
    "x = Model(inputs=inputA, outputs=x)\n",
    "\n",
    "# 두번째 입력층으로부터 분기되어 진행되는 인공 신경망을 정의\n",
    "y = Dense(64, activation=\"relu\")(inputB)\n",
    "y = Dense(32, activation=\"relu\")(y)\n",
    "y = Dense(8, activation=\"relu\")(y)\n",
    "y = Model(inputs=inputB, outputs=y)\n",
    "\n",
    "# 두개의 인공 신경망의 출력을 연결(concatenate)\n",
    "result = concatenate([x.output, y.output])\n",
    "\n",
    "z = Dense(2, activation=\"relu\")(result)\n",
    "z = Dense(1, activation=\"linear\")(z)\n",
    "\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T04:11:55.997652Z",
     "start_time": "2024-02-08T04:11:55.912838Z"
    }
   },
   "id": "c4b7291111ea422a",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "위 모델은 두 개의 입력층으로부터 분기되어 진행된 후 마지막에는 하나의 출력을 예측하는 모델입니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a8bd6a84cced8d8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5) RNN(Recurrence Neural Network) 은닉층 사용하기\n",
    "\n",
    "이번에는 RNN 은닉층을 가지는 모델을 설계해봅시다. 여기서는 하나의 특성(feature)에 50개의 시점(time-step)을 입력으로 받는 모델을 설계해보겠습니다.\n",
    "RNN에 대한 구체적인 내용은 다음 챕터인 RNN 챕터에서 배웁니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62a1a1358777af64"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(50,1))\n",
    "lstm_layer = LSTM(10)(inputs)\n",
    "x = Dense(10, activation='relu')(lstm_layer)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T04:12:23.685458500Z",
     "start_time": "2024-02-08T04:12:23.433997400Z"
    }
   },
   "id": "f59fe704947c43eb",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "다수의 입력과 다수의 출력을 가지는 좀 더 다양한 예제는 앞서 소개한 케라스 공식 문서에서 확인할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62fecf600f8cacc3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 07-10 케라스 서브클래싱 API(Keras Subclassing API)\n",
    "***\n",
    "\n",
    "케라스의 구현 방식에는 Sequential API, Functional API 외에도 Subclassing API라는 구현 방식이 존재합니다.\n",
    "\n",
    "![그림](img_49.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a9ed6765545e0e9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. 서브클래싱 API로 구현한 선형 회귀\n",
    "***\n",
    "\n",
    "Sequential API로 구현했던 선형 회귀를 Subclassing API로 구현한다면 다음과 같습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6ec50daf499ef6e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class LinearRegression(tf.keras.Model): #클래스(class) 형태의 모델은 tf.keras.Model을 상속받는다.\n",
    "  def __init__(self): # 모델의 구조와 동적을 정의하는 생성자를 정의, 파이썬에서 객체가 갖는 속성값을 초기화하는 역할로, 객체가 생성될 때 자동으로 호출된다.\n",
    "    super(LinearRegression, self).__init__() #  tf.keras.Model 클래스의 속성들을 가지고 초기화\n",
    "    self.linear_layer = tf.keras.layers.Dense(1, input_dim=1, activation='linear') \n",
    "\n",
    "  def call(self, x): # 모델이 데이터를 입력받아 예측값을 리턴하는 포워드(forward) 연산을 진행시키는 함수입니다.\n",
    "    y_pred = self.linear_layer(x)\n",
    "\n",
    "    return y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T04:47:09.816907700Z",
     "start_time": "2024-02-08T04:47:09.737795600Z"
    }
   },
   "id": "658338c0d692e3ef",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T04:47:10.250883800Z",
     "start_time": "2024-02-08T04:47:10.173584700Z"
    }
   },
   "id": "e9bfd709dfa43a4a",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X = [[1, 2, 3, 4, 5, 6, 7, 8, 9]] # 공부하는 시간\n",
    "y = [[11, 22, 33, 44, 53, 66, 77, 87, 95]] # 각 공부하는 시간에 맵핑되는 성적"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T04:47:10.639648900Z",
     "start_time": "2024-02-08T04:47:10.565287500Z"
    }
   },
   "id": "6eb69453fb8c9d28",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 4940.3457 - mse: 4940.3457\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 93849.9062 - mse: 93849.9062\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2074612.5000 - mse: 2074612.5000\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 46202828.0000 - mse: 46202828.0000\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1029308672.0000 - mse: 1029308672.0000\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 22931331072.0000 - mse: 22931331072.0000\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 510873337856.0000 - mse: 510873337856.0000\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11381437890560.0000 - mse: 11381437890560.0000\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 253560256200704.0000 - mse: 253560256200704.0000\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5648916007616512.0000 - mse: 5648916007616512.0000\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 125848795245182976.0000 - mse: 125848795245182976.0000\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2803709021096247296.0000 - mse: 2803709021096247296.0000\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 62462134072094228480.0000 - mse: 62462134072094228480.0000\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1391556412074606198784.0000 - mse: 1391556412074606198784.0000\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 31001649431312024469504.0000 - mse: 31001649431312024469504.0000\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 690666994821956611604480.0000 - mse: 690666994821956611604480.0000\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 15386956117008742331973632.0000 - mse: 15386956117008742331973632.0000\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 342796841245924577995915264.0000 - mse: 342796841245924577995915264.0000\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7636965623319392619253989376.0000 - mse: 7636965623319392619253989376.0000\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 170139365259818520052867530752.0000 - mse: 170139365259818520052867530752.0000\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3790433071591123815728733487104.0000 - mse: 3790433071591123815728733487104.0000\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 84444783811373588569768473919488.0000 - mse: 84444783811373588569768473919488.0000\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1881294073366884368968443110621184.0000 - mse: 1881294073366884368968443110621184.0000\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 41912222856622491588221306956414976.0000 - mse: 41912222856622491588221306956414976.0000\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 933737171058861209561704743168901120.0000 - mse: 933737171058861209561704743168901120.0000\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20802169167456048586690126540877856768.0000 - mse: 20802169167456048586690126540877856768.0000\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: inf - mse: inf\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: inf - mse: inf\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: inf - mse: inf\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: inf - mse: inf\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: inf - mse: inf\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: inf - mse: inf\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: inf - mse: inf\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: inf - mse: inf\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: inf - mse: inf\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: inf - mse: inf\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: inf - mse: inf\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: inf - mse: inf\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: inf - mse: inf\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: inf - mse: inf\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: inf - mse: inf\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: inf - mse: inf\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: inf - mse: inf\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: inf - mse: inf\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: inf - mse: inf\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: inf - mse: inf\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: inf - mse: inf\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: inf - mse: inf\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: inf - mse: inf\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: inf - mse: inf\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: inf - mse: inf\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: inf - mse: inf\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: inf - mse: inf\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: inf - mse: inf\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: inf - mse: inf\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: nan - mse: nan\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: nan - mse: nan\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: nan - mse: nan\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: nan - mse: nan\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: nan - mse: nan\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan - mse: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x1d17de73b50>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "model.compile(optimizer=sgd, loss='mse', metrics=['mse'])\n",
    "model.fit(X, y, epochs=300)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T04:47:19.049368100Z",
     "start_time": "2024-02-08T04:47:11.031684600Z"
    }
   },
   "id": "c7c67c2811817bfe",
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": [
    "클래스(class) 형태의 모델은 tf.keras.Model을 상속받습니다. 그리고 init()에서 모델의 구조와 동적을 정의하는 생성자를 정의합니다.\n",
    "이는 파이썬에서 객체가 갖는 속성값을 초기화하는 역할로, 객체가 생성될 때 자동으호 호출됩니다.\n",
    "super() 함수를 부르면 여기서 만든 클래스는 tf.keras.Model 클래스의 속성들을 가지고 초기화 됩니다.\n",
    "call() 함수는 모델이 데이터를 입력받아 예측값을 리턴하는 포워드(forward) 연산을 진행시키는 함수입니다.\n",
    "\n",
    "- $H(x)$식에 입력 $x$로부터 예측된 $y$를 얻는 것을 forward 연산이라고 합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d0e64af6d890562"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. 언제 서브클래싱 API를 써야 할까?\n",
    "***\n",
    "\n",
    "Sequential API는 간단한 모델을 구현하기에 적합합니다.\n",
    "Functional API로는 Sequential API로 구현할 수 없는 복잡한 모델들을 구현가능합니다.\n",
    "그런데 Subclassing API로는 Functional API가 구현할 수 없는 모델들조차 구현할 수 있는 경우가 있습니다.\n",
    "Functional API는 기본적으로 딥 러닝 모델을 DAG(directed acyclic graph)로 취급합니다.\n",
    "실제로 대부분의 딥 러닝 모델이 이에 속하기는 하지만, 항상 그렇지는 않습니다.\n",
    "예를 들어서 재귀 네트워크나 트리 RNN은 이 가정을 따르지 않으며 Functional API에서 구현할 수 없습니다.\n",
    "\n",
    "이를 반대로 해석하면 대부분의 딥 러닝 모델은 Functional API 수준에서도 전부 구현이 가능하다는 의미이기도 합니다.\n",
    "그래서 Subclassing API는 밑바닥부터 새로운 수준의 아키텍처를 구현해야 하는 실험적 연구를 하는 연구자들에게 적합합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff8a8e6fdc25d56d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. 세 가지 구현 방식 비교.\n",
    "***\n",
    "\n",
    "#### 1) Sequential API\n",
    "\n",
    "- 장점 : 단순하게 층을 쌓는 방식으로 쉽고 사용하기가 간단합니다.\n",
    "- 단점 : 다수의 입력(multi-input), 다수의 출력(multi-output)을 가진 모델 또는 층 간의 연결(concatenate)이나 덧셈(Add)과 같은 연산을 하는 모델을 구현하기에는 적합하지 않습니다. \n",
    "이런 모델들의 구현은 Functional API를 사용해야 합니다.\n",
    "\n",
    "<br/>\n",
    "\n",
    "#### 2) Functional API\n",
    "- 장점 : Sequential API로는 구현하기 어려운 복잡한 모델들을 구현할 수 있습니다.\n",
    "- 단점 : 입력의 크기(shape)를 명시한 입력층(Input layer)을 모델의 앞단에 정의해주어야 합니다. 가령, 아래의 코드를 봅시다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7365a39ab5640325"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\ISY\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\ISY\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ISY\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\ISY\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\ISY\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\ISY\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_11' (type Functional).\n    \n    Input 0 of layer \"dense_31\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 9)\n    \n    Call arguments received by layer 'model_11' (type Functional):\n      • inputs=tf.Tensor(shape=(None, 9), dtype=int32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m sgd \u001B[38;5;241m=\u001B[39m optimizers\u001B[38;5;241m.\u001B[39mSGD(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m)\n\u001B[0;32m      9\u001B[0m linear_model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39msgd, loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmse\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmse\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m---> 10\u001B[0m linear_model\u001B[38;5;241m.\u001B[39mfit(X, y, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m300\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file0h77otxe.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\Users\\ISY\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\ISY\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ISY\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\ISY\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\ISY\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\ISY\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_11' (type Functional).\n    \n    Input 0 of layer \"dense_31\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 9)\n    \n    Call arguments received by layer 'model_11' (type Functional):\n      • inputs=tf.Tensor(shape=(None, 9), dtype=int32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "# 선형 회귀 구현 코드의 일부 발췌\n",
    "\n",
    "inputs = Input(shape=(1,)) # <-- 해당 부분\n",
    "output = Dense(1, activation='linear')(inputs)\n",
    "linear_model = Model(inputs, output)\n",
    "\n",
    "sgd = optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "linear_model.compile(optimizer=sgd, loss='mse', metrics=['mse'])\n",
    "linear_model.fit(X, y, epochs=300)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:08:24.762880500Z",
     "start_time": "2024-02-08T05:08:24.596408100Z"
    }
   },
   "id": "8184f770eab33124",
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3) Subclassing API\n",
    "\n",
    "- 장점 : Functional API로도 구현할 수 없는 모델들조차 구현이 가능합니다.\n",
    "- 단점 : 객체 지향 프로그래밍(Object-oriented programming)에 익숙해야 하므로 코드 사용이 가장 까다롭습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1cb8f42d96b18a0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 07-11 다층 퍼셉트론(MultiLayer Perceptron, MLP)으로 텍스트 분류하기\n",
    "***\n",
    "\n",
    "다층 퍼셉트론(Multilayer Perceptron, MLP)으로 텍스트 분류를 수행합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db04ad6c20e33a8e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. 다층 퍼셉트론(MultiLayer Perceptron, MLP)\n",
    "***\n",
    "\n",
    "앞서 단층 퍼셉트론의 형태에서 은닉층이 1개 이상 추가된 신경망을 다층 퍼셉트론(MLP)이라고 한다고 배웠습니다.\n",
    "다층 퍼셉트론은 피드 포워드 신경망(Feed Forward Neural Network, FFNN)의 가장 기본적인 형태입니다.\n",
    "피드 포워드 신경망은 입력층에서 출력층으로 오직 한 방향으로만 연산 방향이 정해져 있는 신경망을 말합니다.\n",
    "\n",
    "뒤에서는 순환 신경망(RNN)과 분산 표현(distributed representation)이라는 새로운 개념들을 사용하여 각종 자연어 처리 실습을 하게 될텐데,\n",
    "이번 실습의 목적은 위 두 가지 개념없이 지금까지 배운 개념만으로도 자연어 처리를 할 수 있다는 것을 보여주기 위함입니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87cc77d609ac3290"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. 케라스의 texts_to_matrix() 이해하기\n",
    "***\n",
    "\n",
    "MLP로 텍스트 분류를 수행하기 전에 이번에 사용할 도구인 케라스 Tokenizer의 texts_to_matrix()를 이해해봅시다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4837b1de6a0f402"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'바나나': 1, '먹고': 2, '싶은': 3, '사과': 4, '길고': 5, '노란': 6, '저는': 7, '과일이': 8, '좋아요': 9}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# 우선 케라스의 전처리 도구인 Tokenizer를 임포트합니다.\n",
    "\n",
    "texts = ['먹고 싶은 사과', '먹고 싶은 바나나', '길고 노란 바나나 바나나', '저는 과일이 좋아요']\n",
    "\n",
    "# 위 텍스트 데이터에 대해서 정수 인코딩을 수행합니다.\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "print(tokenizer.word_index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:14:36.679096400Z",
     "start_time": "2024-02-08T05:14:36.628686800Z"
    }
   },
   "id": "9933d046a2f0dde7",
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": [
    "각 단어에 숫자 1부터 시작하는 정수 인덱스가 부여되었습니다. 텍스트 데이터에 texts_to_matrix()를 사용해보겠습니다.\n",
    "texts_to_matrix()란 이름에서 알 수 있지만, 이 도구는 입력된 텍스트 데이터로부터 행렬(matrix)를 만드는 도구입니다.\n",
    "texts_to_matrx()는 총 4개의 모드를 지원하는데 각 모드는 'binary', 'count', 'freq', 'tfidf'로 총 4개입니다. 우선 'count' 모드를 사용해봅시다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16e9e9374b0c2c28"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.texts_to_matrix(texts, mode = 'count')) # texts_to_matrix의 입력으로 texts를 넣고, 모드는 'count'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:15:17.844355300Z",
     "start_time": "2024-02-08T05:15:17.810701100Z"
    }
   },
   "id": "e5d53b76ae86351",
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "source": [
    "위의 경우는 총 4개의 모드 중에서 'count' 모드를 사용했을 경우입니다. \n",
    "'count'를 사용하면 우리가 앞서 배운 문서 단어 행렬(Document-Term Matrix, DTM)을 생성합니다. \n",
    "DTM에서의 인덱스는 앞서 확인한 word_index의 결과입니다.\n",
    "\n",
    "다만 주의할 점은 각 단어에 부여되는 인덱스는 1부터 시작하는 반면에 완성되는 행렬의 인덱스는 0부터 시작합니다. \n",
    "실제로 단어의 개수는 9개였지만 완성된 행렬의 열의 개수는 10개인 것과 첫번째 열은 모든 행에서 값이 0인 것을 볼 수 있습니다. \n",
    "인덱스 0에는 그 어떤 단어도 할당되지 않았기 때문입니다.\n",
    "\n",
    "우선, 네번째 행을 보겠습니다. 네번째 행은 테스트 데이터에서 네번째 문장을 의미합니다. \n",
    "네번째 행은 8번째 열, 9번째 열, 10번째 열에서 1의 값을 가집니다. 이는 7번 단어, 8번 단어, 9번 단어가 네번째 문장에서 1개씩 존재함을 의미합니다. \n",
    "위에서 정수 인코딩 된 결과를 보면 7번 단어는 '저는', 8번 단어는 '과일이', 9번 단어는 '좋아요'입니다. \n",
    "세번째 행의 첫번째 열의 값은 2인데, 이는 세번째 문장에서 1번 인덱스를 가진 바나나가 두 번 등장했기 때문입니다.\n",
    "\n",
    "앞서 배웠듯이 DTM은 bag of words를 기반으로 하므로 단어 순서 정보는 보존되지 않습니다. \n",
    "사실 더 구체적으로는 4개의 모든 모드에서 단어 순서 정보는 보존되지 않습니다. 'binary' 모드를 보겠습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15ed7e4c1ec74328"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.texts_to_matrix(texts, mode = 'binary'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:20:51.895121Z",
     "start_time": "2024-02-08T05:20:51.859959100Z"
    }
   },
   "id": "3ef8c1d9a54ac4d4",
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "source": [
    "DTM과 결과가 매우 유사해보입니다. 다만 세번째 행, 두번째 열의 값이 DTM에서는 2였는데 여기서는 1로 바뀌었습니다.\n",
    "그 이유는 'binary' 모드는 해당 단어가 존재하는지만 관심을 가지고 해당 단어가 몇 개였는지는 무시하기 때문입니다.\n",
    "해당 단어가 존재하면 1, 단어가 존재하지 않으면 0의 값을 가집니다. 즉, 단어의 존재 유무로만 행렬을 표현합니다. 'tfidf' 모드를 보겠습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c036b5abdc333809"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.85 0.85 1.1  0.   0.   0.   0.   0.  ]\n",
      " [0.   0.85 0.85 0.85 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   1.43 0.   0.   0.   1.1  1.1  0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   1.1  1.1  1.1 ]]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.texts_to_matrix(texts, mode = 'tfidf').round(2)) # 둘째 자리까지 반올림하여 출력"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:21:12.339276Z",
     "start_time": "2024-02-08T05:21:12.296884600Z"
    }
   },
   "id": "3843448ca4e6c032",
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "source": [
    "'tfidf' 모드는 말 그대로 TF-IDF 행렬을 만듭니다. 다만, TF-IDF 실습에서 배운 기본식이나 사이킷런의 TfidfVectorizer에서 사용하는 식이랑 또 조금 다릅니다.\n",
    "앞서 배운 기본식에서 TF는 각 문서에서의 각 단어의 빈도였다면 'tfidf' 모드에서는 TF를 각 문서에서의 각 단어의 빈도에 자연 로그를 씌우고 1을 더한 값으로 정의했습니다.\n",
    "idf에서는 앞서 배운 기본식에서 로그는 자연 로그를 사용하고, 로그 안의 분수에 1을 추가로 더했습니다.\n",
    "물론, 이러한 식을 굳이 기억할 필요는 없고 여전히 TF-IDF의 기존 의도를 갖고 있다고 이해하면 됩니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b794f1d15cdba9b3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.33 0.33 0.33 0.   0.   0.   0.   0.  ]\n",
      " [0.   0.33 0.33 0.33 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.5  0.   0.   0.   0.25 0.25 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.33 0.33 0.33]]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.texts_to_matrix(texts, mode = 'freq').round(2)) # 둘째 자리까지 반올림하여 출력"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:23:40.883786900Z",
     "start_time": "2024-02-08T05:23:40.834062200Z"
    }
   },
   "id": "ffd7b869482d7d13",
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "source": [
    "마지막으로 'freq' 모드입니다. 'freq' 모드는 각 문서에서의 각 단어의 등장 횟수를 분자로, 각 문서의 크기(각 문서에서 등장한 모든 단어의 개수의 총 합)를 분모로 하는 표현 방법입니다.\n",
    "예를 들어 세번째 행을 보겠습니다. 세번째 문장은 '길고 노란 바나나 바나나' 였습니다. 문서의 크기는 4인데, 바나나는 총 2회 등장했습니다.\n",
    "이에 따라서 세번째 문장에서의 단어 '바나나'의 값은 위의 행렬에서 0.5가 됩니다. 반면에 '길고', '노란'이라는 두 단어는 각 1회 등장했으므로 각자 1/4의 값인 0.25의 값을 가집니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "904632c9596c70f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. 20개 뉴스 그룹(Twenty Newsgroups) 데이터에 대한 이해\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4b1db592c5a8a0a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 사이킷런에서는 20개의 다른 주제를 가진 18,846개의 뉴스 그룹 이메일 데이터를 제공합니다.\n",
    "\n",
    "newsdata = fetch_20newsgroups(subset = 'train') # 'train'을 기재하면 훈련 데이터만 리턴한다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:26:46.140083Z",
     "start_time": "2024-02-08T05:24:39.143162400Z"
    }
   },
   "id": "ffd71626caa89776",
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "source": [
    "위의 subset의 값으로 'all'을 넣으면 전체 데이터인 18,846개의 샘플을 다운로드할 수 있으며,\n",
    "'train'을 넣으면 훈련 데이터를, 'test'를 넣으면 테스트 데이터를 다운로드할 수 있습니다. newsdata.keys()를 출력하면 해당 데이터의 속성을 확인할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c054839c9280d4d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "print(newsdata.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:26:46.152344700Z",
     "start_time": "2024-02-08T05:26:46.142078600Z"
    }
   },
   "id": "95487c3e0a537d85",
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "source": [
    "해당 데이터는 data, filenames, target_names, target, DESCR, description이라는 6개 속성을 갖고 있습니다.\n",
    "이 중 실제로 훈련에 사용할 속성은 이메일 본문인 data와 메일이 어떤 주제인지 기재된 숫자 레이블인 target입니다. 우선 훈련용 샘플의 개수를 보겠습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5b46fb0d8cad2b5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 샘플의 개수 : 11314\n"
     ]
    }
   ],
   "source": [
    "print('훈련용 샘플의 개수 : {}'.format(len(newsdata.data)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:26:46.164847700Z",
     "start_time": "2024-02-08T05:26:46.145366800Z"
    }
   },
   "id": "ff5f13fabe5734cc",
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "source": [
    "훈련 샘플은 11,314개가 존재합니다. target_names에는 20개의 주제의 이름을 담고있습니다. 어떤 주제가 있는지 확인해보겠습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5acaca87a806afa4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 주제의 개수 : 20\n",
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print('총 주제의 개수 : {}'.format(len(newsdata.target_names)))\n",
    "print(newsdata.target_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:26:46.184765300Z",
     "start_time": "2024-02-08T05:26:46.151292800Z"
    }
   },
   "id": "c07f2df42fe19aae",
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "source": [
    "이번 실습의 목적은 테스트 데이터에서 이메일 본문을 보고 20개의 주제 중 어떤 주제인지를 맞추는 것입니다.\n",
    "레이블인 target에는 총 0부터 19까지의 숫자가 들어가있는데 첫번째 샘플의 경우에는 몇 번 주제인지 확인해보겠습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bb66dd2f207acfd"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 샘플의 레이블 : 7\n"
     ]
    }
   ],
   "source": [
    "print('첫번째 샘플의 레이블 : {}'.format(newsdata.target[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:30:54.093327500Z",
     "start_time": "2024-02-08T05:30:54.044796500Z"
    }
   },
   "id": "978d662f1ff7e349",
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "source": [
    "첫번째 샘플의 레이블의 값은 7입니다. 숫자만으로는 앞서 target_names를 통해 확인한 20개의 주제 중에서 어떤 주제를 의미하는지 알 수가 없습니다.\n",
    "7이 실제로 어떤 주제를 나타내는지는 target_names[] 안에 숫자를 입력하여 알 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9815011ff837158c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7번 레이블이 의미하는 주제 : rec.autos\n"
     ]
    }
   ],
   "source": [
    "print('7번 레이블이 의미하는 주제 : {}'.format(newsdata.target_names[7]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:33:50.344852100Z",
     "start_time": "2024-02-08T05:33:50.299438100Z"
    }
   },
   "id": "ef9540282ca96310",
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "source": [
    "7번 레이블은 rec.autos라는 주제입니다. 즉, 첫번째 샘플의 주제는 rec.autos입니다. 첫번째 샘플의 본문 내용을 확인해봅시다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbbd3c6f959fe46d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n"
     ]
    }
   ],
   "source": [
    "print(newsdata.data[0]) # 첫번째 샘플 출력"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:34:03.319990800Z",
     "start_time": "2024-02-08T05:34:03.269488900Z"
    }
   },
   "id": "645ff9ed77fad754",
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "source": [
    "이메일의 내용을 보니 스포츠 카에 대한 글로 보입니다. 이 글의 레이블은 7이고, 7번 레이블은 rec.autos란 주제를 의미합니다.\n",
    "훈련에 사용될 메일 본문인 data와 레이블인 target을 데이터프레임으로 만들어서 데이터에 대한 통계적인 정보들을 알아보겠습니다.\n",
    "\n",
    "data로부터 데이터프레임을 생성하고, target 열을 추가한 뒤에 상위 5개의 행을 출력합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3b8bff45441e732"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                               email  target\n0  From: lerxst@wam.umd.edu (where's my thing)\\nS...       7\n1  From: guykuo@carson.u.washington.edu (Guy Kuo)...       4\n2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4\n3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1\n4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>email</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n      <td>14</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(newsdata.data, columns = ['email'])\n",
    "data['target'] = pd.Series(newsdata.target)\n",
    "data[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:34:29.712700800Z",
     "start_time": "2024-02-08T05:34:29.620918900Z"
    }
   },
   "id": "c5fde1b7ba5bd07f",
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "source": [
    "메일 본문에 해당하는 email열과 레이블에 해당되는 target 열, 2개의 열로 구성된 데이터프레임이 생성된 것을 볼 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c5ce7c217e1b165"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11314 entries, 0 to 11313\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   email   11314 non-null  object\n",
      " 1   target  11314 non-null  int32 \n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 132.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:34:47.001139Z",
     "start_time": "2024-02-08T05:34:46.905955500Z"
    }
   },
   "id": "febdebc86cf29cd0",
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "source": [
    "news열은 문자열, target열은 정수형 데이터입니다. 혹시 Null 값을 가진 샘플이 있는지 isnull().values.any()로도 확인 가능합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5eb3b8986c89ee8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:35:00.800406300Z",
     "start_time": "2024-02-08T05:35:00.748159400Z"
    }
   },
   "id": "b84d9191f2ce5605",
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "source": [
    "False는 데이터에 별도의 Null 값은 없음을 의미합니다. nunique()를 통해 샘플 중 중복을 제거한 개수를 확인할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2869b8ada30048e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복을 제외한 샘플의 수 : 11314\n",
      "중복을 제외한 주제의 수 : 20\n"
     ]
    }
   ],
   "source": [
    "print('중복을 제외한 샘플의 수 : {}'.format(data['email'].nunique()))\n",
    "print('중복을 제외한 주제의 수 : {}'.format(data['target'].nunique()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:35:20.190571100Z",
     "start_time": "2024-02-08T05:35:20.101442300Z"
    }
   },
   "id": "d2b32e052fcafb22",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 레이블 값의 분포를 시각화해보겠습니다.\n",
    "\n",
    "data['target'].value_counts().plot(kind='bar');"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:35:33.512402600Z",
     "start_time": "2024-02-08T05:35:33.224498Z"
    }
   },
   "id": "b2570ae7f71aa5b6",
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "source": [
    "10번 레이블의 수가 가장 많고, 19번 레이블의 수가 가장 적으며 대체적으로 400 ~ 600개 사이의 분포를 보입니다.\n",
    "이번에는 각 레이블이 몇 개 있는지 구체적인 수치로 확인해보겠습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6333a8c652fdb7d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    target  count\n",
      "0        0    480\n",
      "1        1    584\n",
      "2        2    591\n",
      "3        3    590\n",
      "4        4    578\n",
      "5        5    593\n",
      "6        6    585\n",
      "7        7    594\n",
      "8        8    598\n",
      "9        9    597\n",
      "10      10    600\n",
      "11      11    595\n",
      "12      12    591\n",
      "13      13    594\n",
      "14      14    593\n",
      "15      15    599\n",
      "16      16    546\n",
      "17      17    564\n",
      "18      18    465\n",
      "19      19    377\n"
     ]
    }
   ],
   "source": [
    "print(data.groupby('target').size().reset_index(name='count'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:36:12.061170700Z",
     "start_time": "2024-02-08T05:36:11.998462800Z"
    }
   },
   "id": "c2d577a3dbcffcf4",
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "source": [
    "데이터프레임으로부터 다시 메일 본문과 레이블을 분리하고, 테스트 데이터 또한 불러오겠습니다.\n",
    "subset에 'test'를 기재하면 테스트 데이터를 불러옵니다. 훈련 데이터와 테스트 데이터의 본문과 레이블을 각각 저장합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a925a3545363defd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "newsdata_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "train_email = data['email']\n",
    "train_label = data['target']\n",
    "test_email = newsdata_test.data\n",
    "test_label = newsdata_test.target"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:36:28.591947800Z",
     "start_time": "2024-02-08T05:36:28.408014900Z"
    }
   },
   "id": "bf2a8488bb322e22",
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "source": [
    "훈련 데이터와 테스트 데이터가 모두 준비되었습니다. 케라스의 토크나이저 도구를 사용하여 전처리를 진행해봅시다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f046771e16b5d61e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "num_classes = 20"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:36:47.185716500Z",
     "start_time": "2024-02-08T05:36:47.133251700Z"
    }
   },
   "id": "7ba5aeede6859c6e",
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "source": [
    "우선 필요한 변수들을 정의합니다. vocab_size는 이번 실습에서 사용할 최대 단어 개수를 정의하는 변수입니다.\n",
    "뒤에서 케라스 토크나이저를 사용하면 빈도수 순으로 인덱스를 부여하므로, 빈도수가 가장 높은 상위 vocab_size 개수만큼의 단어를 사용합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a98fd31a44728449"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def prepare_data(train_data, test_data, mode): # 전처리 함수\n",
    "    tokenizer = Tokenizer(num_words = vocab_size) # vocab_size 개수만큼의 단어만 사용한다.\n",
    "    tokenizer.fit_on_texts(train_data)\n",
    "    X_train = tokenizer.texts_to_matrix(train_data, mode=mode) # 샘플 수 × vocab_size 크기의 행렬 생성\n",
    "    X_test = tokenizer.texts_to_matrix(test_data, mode=mode) # 샘플 수 × vocab_size 크기의 행렬 생성\n",
    "    return X_train, X_test, tokenizer.index_word"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:37:01.659094800Z",
     "start_time": "2024-02-08T05:37:01.602585100Z"
    }
   },
   "id": "a1870198e2b06f28",
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "source": [
    "케라스 토크나이저로 전처리를 수행하는 함수인 prepare_data를 만들었습니다.\n",
    "해당 함수는 케라스 토크나이저를 통해 단어 토큰화를 수행하고,\n",
    "앞서 배운 texts_to_matrix()를 사용하여 훈련 데이터와 테스트 데이터를 'binary', 'count', 'tfidf', 'freq' 4개의 모드 중 사용자가 정한 모드로 변환합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53d00c95c17d5bba"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train, X_test, index_to_word = prepare_data(train_email, test_email, 'binary') # binary 모드로 변환\n",
    "y_train = to_categorical(train_label, num_classes) # 원-핫 인코딩\n",
    "y_test = to_categorical(test_label, num_classes) # 원-핫 인코딩"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:37:30.357790Z",
     "start_time": "2024-02-08T05:37:23.810349500Z"
    }
   },
   "id": "637220d4280da868",
   "execution_count": 59
  },
  {
   "cell_type": "markdown",
   "source": [
    "메일 본문에 대해서는 'binary' 모드로 변환하고, 훈련 데이터와 테스트 데이터의 레이블은 원-핫 인코딩을 수행하였습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4767d28b17dc1e3b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 본문의 크기 : (11314, 10000)\n",
      "훈련 샘플 레이블의 크기 : (11314, 20)\n",
      "테스트 샘플 본문의 크기 : (7532, 10000)\n",
      "테스트 샘플 레이블의 크기 : (7532, 20)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플 본문의 크기 : {}'.format(X_train.shape))\n",
    "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
    "print('테스트 샘플 본문의 크기 : {}'.format(X_test.shape))\n",
    "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:37:43.049947800Z",
     "start_time": "2024-02-08T05:37:42.990873400Z"
    }
   },
   "id": "baec8ba098b86dfa",
   "execution_count": 60
  },
  {
   "cell_type": "markdown",
   "source": [
    "훈련 데이터와 테스트 데이터 모두 메일 본문의 크기가 샘플의 수 × 10,000의 행렬로 변환되었는데,\n",
    "열의 개수가 10,000인 것은 위의 prepard_data 함수 내부에서 Tokenizer의 num_words의 인자로 vocab_size를 지정해주었기 때문입니다.\n",
    "사실 단어의 정수 인덱스는 1부터 시작하지만, 행렬의 인덱스는 0부터 시작하여 0번 인덱스는 사용되지 않으므로 실제로 행렬에는 빈도수 기준 상위 9,999개의 단어가 표현된 셈입니다.\n",
    "빈도수 상위 1번 단어와 9,999번 단어를 확인해보겠습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d2f5c27f4695521"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빈도수 상위 1번 단어 : the\n",
      "빈도수 상위 9999번 단어 : mic\n"
     ]
    }
   ],
   "source": [
    "print('빈도수 상위 1번 단어 : {}'.format(index_to_word[1]))\n",
    "print('빈도수 상위 9999번 단어 : {}'.format(index_to_word[9999]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:38:26.864913100Z",
     "start_time": "2024-02-08T05:38:26.798010Z"
    }
   },
   "id": "dae4699d97c79962",
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "source": [
    "불용어에 해당되는 단어 'the'가 빈도수 상위 1번 단어가 된 것을 확인할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e8c7d9e3a5a96e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. 다층 퍼셉트론(Multilayer Perceptron, MLP)을 사용하여 텍스트 분류하기\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a34e876479fb2cfb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 모델을 설계해보겠습니다. 우선 모델 설계에 필요한 도구들을 임포트합니다.\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# 다층 퍼셉트론을 설계합니다.\n",
    "\n",
    "def fit_and_evaluate(X_train, y_train, X_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape=(vocab_size,), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=128, epochs=5, verbose=1, validation_split=0.1)\n",
    "    score = model.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
    "    return score[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:40:22.680150800Z",
     "start_time": "2024-02-08T05:40:22.623199Z"
    }
   },
   "id": "ce4befeafe8d4fe7",
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "source": [
    "모델 설계를 fit_and_evaluate라는 함수 내에 정의하였는데, 모델을 함수 내에 정의한 이유는 이번 실습에서는 입력값을 바꿔가면서 모델을 여러번 호출하기 위함입니다.\n",
    "우선은 모델의 아키텍처에 집중해보겠습니다.\n",
    "\n",
    "![그림](img_50.png)\n",
    "\n",
    "위의 그림은 현재 설계한 신경망의 구조를 보여줍니다. 현재 설계한 다층 퍼셉트론은 총 4개의 층을 가지고 있습니다.\n",
    "vocab_size의 크기를 가진 입력층, 256개의 뉴런을 가진 첫번째 은닉층, 128개의 뉴런을 가진 두번째 은닉층, num_classes의 크기를 가진 출력층입니다.\n",
    "또한 이번에 설계한 다층 퍼셉트론은 은닉층이 2개이므로 깊은 신경망(Deep Neural Network, DNN)입니다.\n",
    "\n",
    "코드로 돌아가보겠습니다. 위 모델에서는 과적합을 막기 위해서 두 번의 드롭아웃(Dropout)을 적용하였습니다.\n",
    "이 문제는 다중 클래스 분류 문제입니다. 여러 개의 선택지 중에서 하나의 선택지를 고르는 문제인데,\n",
    "이 경우 20개의 주제 중에서 모델은 자신이 정답이라고 생각하는 1개의 주제를 예측해야 합니다.\n",
    "다중 클래스 분류 문제이므로 출력층의 활성화 함수로는 소프트맥스 함수를 사용하고,\n",
    "손실 함수로는 크로스 엔트로피(categorical_crossentropy) 함수를 사용하였습니다.\n",
    "\n",
    "모델을 훈련시켜보겠습니다. 이번에는 앞서 배운 texts_to_matrix()의 4개의 모드에 대해서 전부 모델의 결과를 확인해보겠습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc26273307c3919c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "80/80 [==============================] - 3s 24ms/step - loss: 2.3033 - accuracy: 0.3312 - val_loss: 1.0197 - val_accuracy: 0.8092\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.9127 - accuracy: 0.7494 - val_loss: 0.4813 - val_accuracy: 0.8790\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.4524 - accuracy: 0.8787 - val_loss: 0.3448 - val_accuracy: 0.9028\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.2717 - accuracy: 0.9265 - val_loss: 0.3146 - val_accuracy: 0.9125\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.1828 - accuracy: 0.9539 - val_loss: 0.2991 - val_accuracy: 0.9099\n",
      "binary 모드의 테스트 정확도: 0.8293945789337158\n",
      "Epoch 1/5\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 2.7404 - accuracy: 0.2431 - val_loss: 1.6136 - val_accuracy: 0.7297\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 1.4639 - accuracy: 0.6309 - val_loss: 0.7469 - val_accuracy: 0.8313\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.7817 - accuracy: 0.8055 - val_loss: 0.4819 - val_accuracy: 0.8852\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.5071 - accuracy: 0.8733 - val_loss: 0.4122 - val_accuracy: 0.8949\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.3678 - accuracy: 0.9149 - val_loss: 0.3923 - val_accuracy: 0.9011\n",
      "count 모드의 테스트 정확도: 0.8223579525947571\n",
      "Epoch 1/5\n",
      "80/80 [==============================] - 3s 24ms/step - loss: 2.2541 - accuracy: 0.3486 - val_loss: 0.7870 - val_accuracy: 0.8542\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.8805 - accuracy: 0.7574 - val_loss: 0.4268 - val_accuracy: 0.8966\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.4866 - accuracy: 0.8731 - val_loss: 0.3560 - val_accuracy: 0.9108\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.2892 - accuracy: 0.9267 - val_loss: 0.3137 - val_accuracy: 0.9170\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.2443 - accuracy: 0.9433 - val_loss: 0.3155 - val_accuracy: 0.9196\n",
      "tfidf 모드의 테스트 정확도: 0.8301911950111389\n",
      "Epoch 1/5\n",
      "80/80 [==============================] - 3s 24ms/step - loss: 2.9781 - accuracy: 0.0911 - val_loss: 2.9285 - val_accuracy: 0.1802\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 2.7219 - accuracy: 0.1985 - val_loss: 2.3961 - val_accuracy: 0.3887\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 2.1723 - accuracy: 0.3342 - val_loss: 1.8521 - val_accuracy: 0.5733\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 1.7145 - accuracy: 0.4659 - val_loss: 1.4412 - val_accuracy: 0.6864\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 1.3464 - accuracy: 0.5894 - val_loss: 1.1384 - val_accuracy: 0.7032\n",
      "freq 모드의 테스트 정확도: 0.6670207381248474\n"
     ]
    }
   ],
   "source": [
    "modes = ['binary', 'count', 'tfidf', 'freq'] # 4개의 모드를 리스트에 저장.\n",
    "\n",
    "for mode in modes: # 4개의 모드에 대해서 각각 아래의 작업을 반복한다.\n",
    "    X_train, X_test, _ = prepare_data(train_email, test_email, mode) # 모드에 따라서 데이터를 전처리\n",
    "    score = fit_and_evaluate(X_train, y_train, X_test, y_test) # 모델을 훈련하고 평가.\n",
    "    print(mode+' 모드의 테스트 정확도:', score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T05:43:07.599316700Z",
     "start_time": "2024-02-08T05:41:49.741097600Z"
    }
   },
   "id": "b7d7a910607217b8",
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "source": [
    "각 모드에 대해서 총 5회의 에포크를 수행하는데, 각 모드에 대한 정확도는 다음과 같이 나왔습니다.\n",
    "- binary 모드의 테스트 정확도: 0.8312533\n",
    "- count 모드의 테스트 정확도: 0.8239511\n",
    "- tfidf 모드의 테스트 정확도: 0.8381572\n",
    "- freq 모드의 테스트 정확도: 0.6902549"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf70c598d6bbea67"
  },
  {
   "cell_type": "markdown",
   "source": [
    "대체적으로 82% ~ 83%의 비슷한 정확도를 보이는데, 'freq' 모드에서만 정확도가 69%가 나왔습니다.\n",
    "아무래도 'freq' 모드는 이번 문제를 풀기위한 적절한 전처리 방법이 아니었던 것 같습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acdcb6c8c0ae31cb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 07-12 피드 포워드 신경망 언어 모델(Neural Network Language Model, NNLM)\n",
    "***\n",
    "\n",
    "신경망 언어 모델의 시초인 피드 포워드 신경망 언어 모델(Feed Forward Neural Network Language Model)에 대해서 학습합니다.\n",
    "간단히 줄여 NNLM이라고 합시다. 뒤에서 RNNLM, BiLM 등 보다 발전된 신경망 언어 모델들을 배웁니다.\n",
    "\n",
    "```\n",
    "이 모델은 제안 되었을 당시 NPLM(Neural Probabilistic Language Model)이라는 이름을 갖고 있었습니다.\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e077d786249a0143"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. 기존 N-gram 언어 모델의 한계\n",
    "***\n",
    "\n",
    "언어 모델은 문장에 확률을 할당하는 모델이며, 주어진 문맥으로부터 아직 모르는 단어를 예측하는 것을 언어 모델링이라고 한다고 언급한 바 있습니다.\n",
    "다음은 이전 단어들로부터 다음 단어를 예측하는 언어 모델링(Language Modeling) 의 예를 보여줍니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "794966aed12bb2ef"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 다음 단어 예측하기\n",
    "# An adorable little boy is spreading ____"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T07:40:13.476669500Z",
     "start_time": "2024-02-13T07:40:13.447295300Z"
    }
   },
   "id": "9d72fa342beb32bb",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "위 문장을 가지고 앞서 배운 n-gram 언어 모델이 언어 모델링을 하는 방법을 복습해봅시다.\n",
    "\n",
    "![그림](img_51.png)\n",
    "\n",
    "n-gram 언어 모델은 언어 모델링에 바로 앞 n-1개의 단어를 참고합니다. 4-gram 언어 모델이라고 가정해봅시다.\n",
    "모델은 바로 앞 3개의 단어만 참고하며 더 앞의 단어들은 무시합니다. 위 예제에서 다음 단어 예측에 사용되는 단어는 boy, is, spreading입니다.\n",
    "\n",
    "![그림](img_52.png)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cdba3afbb7bad80"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. 단어의 의미적 유사성\n",
    "***\n",
    "\n",
    "희소 문제는 기계가 단어의 의미적 유사성을 알수 있다면 해결할 수 있는 문제입니다.\n",
    "실제 사람의 사례를 들어 이야기해보겠습니다. 저자는 최근 '톺아보다'라는 생소한 단어를 배웠고, '톺아보다'가 '샅샅이 살펴보다'와 유사한 의미임을 학습했습니다.\n",
    "그리고 '발표 자료를 살펴보다'라는 표현 대신 '발표 자료를 톺아보다'라는 표현을 써봤습니다.\n",
    "저는 '발표 자료를 톺아보다'라는 예문을 어디서 읽은 적은 없지만 두 단어가 유사함을 학습하였으므로 단어를 대신 선택하여 자연어 생성을 할 수 있었습니다.\n",
    "\n",
    "기계도 마찬가지입니다. '발표 자료를 살펴보다'라는 단어 시퀀스는 존재하지만, '발표 자료를 톺아보다'라는 단어 시퀀스는 존재하지 않는 코퍼스를 학습한 언어 모델이 있다고 가정해봅시다.\n",
    "언어 모델은 아래 선택지에서 다음 단어를 예측해야 합니다.\n",
    "\n",
    "- $P(톺아보다|발표자료를)$\n",
    "- $P(냠냠하다|발표자료를)$\n",
    "\n",
    "저자의 경우에는 '살펴보다'와 '톺아보다'의 유사성을 학습하였고 이를 근거로 두 선택지 중에서 '톺아보다'가 더 맞는 선택이라고 판단할 수 있습니다.\n",
    "하지만 n-gram 언어 모델은 '발표 자료를' 다음에 '톺아보다'가 나올 확률  $P(톺아보다|발표자료를)$를 0으로 연산합니다.\n",
    "n-gram 언어 모델은 '살펴보다'와 '톺아보다'의 단어의 유사도를 알 수 없으므로 예측에 고려할 수 없습니다.\n",
    "\n",
    "만약 언어 모델 또한 단어의 의미적 유사성을 학습할 수 있도록 설계한다면,\n",
    "훈련 코퍼스에 없는 단어 시퀀스에 대한 예측이라도 유사한 단어가 사용된 단어 시퀀스를 참고하여 보다 정확한 예측을 할 수 있습니다.\n",
    "그리고 이러한 아이디어를 반영한 언어 모델이 신경망 언어 모델 NNLM입니다.\n",
    "그리고 이 아이디어는 단어 벡터 간 유사도를 구할 수 있는 벡터를 얻어내는 워드 임베딩(word embedding) 의 아이디어이기도 합니다.\n",
    "NNLM이 어떻게 훈련 과정에서 단어의 유사도를 학습할 수 있는지 알아봅시다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "424c311296e9a404"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "###3. 피드 포워드 신경망 언어 모델(NNLM)\n",
    "***\n",
    "\n",
    "NNLM이 언어 모델링을 학습하는 과정을 보겠습니다. 이해를 위해 간소화 된 형태로 설명합니다.\n",
    "\n",
    "- 예문 : \"what will the fat cat sit on\"\n",
    "\n",
    "예를 들어 훈련 코퍼스에 위와 같은 문장이 있다고 해봅시다. 언어 모델은 주어진 단어 시퀀스로부터 다음 단어를 예측합니다.\n",
    "훈련 과정에서는 'what will the fat cat'이라는 단어 시퀀스가 입력으로 주어지면, 다음 단어 'sit'을 예측하는 방식으로 훈련됩니다.\n",
    "\n",
    "훈련 코퍼스가 준비된 상태에서 가장 먼저 해야 할 일은 기계가 단어를 인식할 수 있도록 모든 단어를 수치화하는 것입니다.\n",
    "훈련 코퍼스에 7개의 단어만 존재한다고 가정했을 때 위 단어들을 다음과 같이 원-핫 인코딩 할 수 있습니다.\n",
    "\n",
    "```\n",
    "what = [1, 0, 0, 0, 0, 0, 0]\n",
    "will = [0, 1, 0, 0, 0, 0, 0]\n",
    "the = [0, 0, 1, 0, 0, 0, 0]\n",
    "fat = [0, 0, 0, 1, 0, 0, 0]\n",
    "cat = [0, 0, 0, 0, 1, 0, 0]\n",
    "sit = [0, 0, 0, 0, 0, 1, 0]\n",
    "on = [0, 0, 0, 0, 0, 0, 1]\n",
    "```\n",
    "\n",
    "모든 단어가 단어 집합(vocabulary)의 크기인 7의 차원을 가지는 원-핫 벡터가 되었습니다.\n",
    "이 원-핫 벡터들이 훈련을 위한 NNLM의 입력이면서 예측을 위한 레이블이 됩니다.\n",
    "'what will the fat cat'를 입력을 받아서 'sit'을 예측하는 일은 기계에게 what, will, the, fat, cat의 원-핫 벡터를 입력받아 sit의 원-핫 벡터를 예측하는 문제입니다.\n",
    "\n",
    "NNLM은 n-gram 언어 모델처럼 다음 단어를 예측할 때, 앞의 모든 단어를 참고하는 것이 아니라 정해진 개수의 단어만을 참고합니다.\n",
    "이 개수를 n이라고 하고 n을 4라고 해봅시다. 이때, 언어 모델은 'what will the fat cat'라는 단어 시퀀스가 주어졌을 때,\n",
    "다음 단어를 예측하기 위해 앞의 4개 단어 'will the fat cat'까지만 참고하고 그 앞 단어인 what은 무시합니다.\n",
    "이 범위를 윈도우(window)라고 하기도 하는데, 여기서 윈도우의 크기인 n은 4입니다.\n",
    "\n",
    "![그림](img_53.png)\n",
    "\n",
    "NNLM의 구조를 보겠습니다. NNLM은 위의 그림과 같이 총 4개의 층(layer)으로 이루어진 인공 신경망입니다.\n",
    "입력층(input layer)을 보면 앞에서 윈도우의 크기는 4로 정하였으므로 입력은 4개의 단어 'will, the, fat, cat'의 원-핫 벡터입니다.\n",
    "출력층(output layer)을 보면 모델이 예측해야하는 정답에 해당되는 단어 sit의 원-핫 벡터는 모델이 예측한 값의 오차를 구하기 위해 레이블로서 사용됩니다.\n",
    "그리고 오차로부터 손실 함수를 사용하여 인공 신경망이 학습을 하게 됩니다.\n",
    "\n",
    "내부 메커니즘을 따라가봅시다. 4개의 원-핫 벡터를 입력 받은 NNLM은 다음층인 투사층(projection layer)을 지나게 됩니다.\n",
    "인공 신경망에서 입력층과 출력층 사이의 층은 보통 은닉층이라고 부르는데, 여기서 투사층이라고 명명한 이 층은 일반 은닉층과 다르게 가중치 행렬과의 곱셈은 이루어지지만 활성화 함수가 존재하지 않습니다.\n",
    "\n",
    "투사층의 크기를 M으로 설정하면, 각 입력 단어들은 투사층에서 V × M 크기의 가중치 행렬과 곱해집니다.\n",
    "여기서 V는 단어 집합의 크기를 의미합니다. 만약 원-핫 벡터의 차원이 7이고, M이 5라면 가중치 행렬 W는 7 × 5 행렬이 됩니다.\n",
    "\n",
    "![그림](img_54.png)\n",
    "\n",
    "각 단어의 원-핫 벡터와 가중치 W 행렬의 곱이 어떻게 이루어지는지 보겠습니다.\n",
    "위 그림에서는 각 원-핫 벡터를 $x$로 표기하였습니다.\n",
    "원-핫 벡터의 특성으로 인해 i번째 인덱스에 1이라는 값을 가지고 그 외의 0의 값을 가지는 원-핫 벡터와 가중치 W 행렬의 곱은 사실 W행렬의 i번째 행을 그대로 읽어오는 것과(lookup) 동일합니다.\n",
    "그래서 이 작업을 룩업 테이블(lookup table)이라고 합니다.\n",
    "\n",
    "룩업 테이블 후에는 V차원을 가지는 원-핫 벡터는 이보다 더 차원이 작은 M차원의 벡터로 맵핑됩니다.\n",
    "위 그림에서 단어 fat을 의미하는 원-핫 벡터를 $xfat$으로 표현했고,\n",
    "테이블 룩업 과정을 거친 후의 단어 벡터는 $efat$으로 표현했습니다.\n",
    "이 벡터들은 초기에는 랜덤한 값을 가지지만 학습 과정에서 값이 계속 변경되는데 이 단어 벡터를 임베딩 벡터(embedding vector) 라고 합니다.\n",
    "\n",
    "![그림](img_55.png)\n",
    "\n",
    "각 단어가 테이블 룩업을 통해 임베딩 벡터로 변경되고, 투사층에서 모든 임베딩 벡터들의 값은 연결됩니다(concatenate).\n",
    "여기서 벡터의 연결 연산은 벡터들을 이어붙이는 것을 의미합니다. 가령, 5차원 벡터 4개를 연결한다는 의미는 20차원 벡터를 얻는다는 의미입니다. \n",
    "$x$를 각 단어의 원-핫 벡터, NNLM이 예측하고자 하는 단어가 문장에서 $t$번째 단어라고 하고, 윈도우의 크기를 $n$,\n",
    "룩업 테이블을 의미하는 함수를 $lookup$, 세미콜론(;)을 연결 기호로 하였을 때 투사층을 식으로 표현하면 아래와 같습니다.\n",
    "\n",
    "![그림](img_56.png)\n",
    "\n",
    "일반적인 은닉층이 활성화 함수를 사용하는 비선형층(nonlinear layer)인 것과는 달리 투사층은 활성화 함수가 존재하지 않는 선형층(linear layer)이라는 점이 다소 생소하지만,\n",
    "이 다음은 다시 은닉층을 사용하는 일반적인 피드 포워드 신경망과 동일합니다.\n",
    "\n",
    "![그림](img_57.png)\n",
    "\n",
    "투사층의 결과는 h의 크기를 가지는 은닉층을 지납니다.\n",
    "일반적인 피드 포워드 신경망에서 은닉층을 지난다는 것은 은닉층의 입력은 가중치 곱해진 후 편향이 더해져 활성화 함수의 입력이 된다는 의미입니다.\n",
    "이때의 가중치와 편향을 $Wh$와 $bh$이라고 하고, 은닉층의 활성화 함수를 하이퍼볼릭탄젠트 함수라고 하였을 때, 은닉층을 식으로 표현하면 아래와 같습니다.\n",
    "\n",
    "![그림](img_58.png)\n",
    "\n",
    "은닉층의 출력은 V의 크기를 가지는 출력층으로 향합니다.\n",
    "이 과정에서 다시 또 다른 가중치와 곱해지고 편향이 더해지면, 입력이었던 원-핫 벡터들과 동일하게 V차원의 벡터를 얻습니다.\n",
    "만약 입력 벡터의 차원이 7이었다면 해당 벡터도 동일한 차원 수를 가집니다.\n",
    "출력층에서는 활성화 함수로 소프트맥스(softmax) 함수를 사용하는데,\n",
    "V차원의 벡터는 소프트맥스 함수를 지나면서 벡터의 각 원소는 0과 1사이의 실수값을 가지며 총 합은 1이 되는 상태로 바뀝니다.\n",
    "이 벡터를 NNLM의 예측값이라는 의미에서 $\\hat{y}$라고 합시다. 이를 식으로 표현하면 아래와 같습니다.\n",
    "\n",
    "![그림](img_59.png)\n",
    "\n",
    "벡터 $\\hat{y}$의 각 차원 안에서의 값이 의미하는 것은 이와 같습니다. \n",
    "$\\hat{y}$의 j번째 인덱스가 가진 0과 1사이의 값은 j번째 단어가 다음 단어일 확률을 나타냅니다.\n",
    "그리고 $\\hat{y}$는 실제값. 즉, 실제 정답에 해당되는 단어인 원-핫 벡터의 값에 가까워져야 합니다.\n",
    "실제값에 해당되는 다음 단어를 $y$라고 했을 때, 이 두 벡터가 가까워지게 하기위해서 NNLM는 손실 함수로 크로스 엔트로피(cross-entropy) 함수를 사용합니다.\n",
    "해당 문제는 단어 집합의 모든 단어라는 V개의 선택지 중 정답인 'sit'을 예측해야하는 다중 클래스 분류 문제입니다.\n",
    "그리고 역전파가 이루어지면 모든 가중치 행렬들이 학습되는데, 여기에는 투사층에서의 가중치 행렬도 포함되므로 임베딩 벡터값 또한 학습됩니다.\n",
    "\n",
    "이번 예제에서는 7개의 단어만 사용했지만, 만약 충분한 훈련 데이터가 있다는 가정 하에 NNLM이 얻을 수 있는 이점은 무엇일까요?\n",
    "NNLM의 핵심은 충분한 양의 훈련 코퍼스를 위와 같은 과정으로 학습한다면 결과적으로 수많은 문장에서 유사한 목적으로 사용되는 단어들은 결국 유사한 임베딩 벡터값을 얻게되는 것에 있습니다.\n",
    "이렇게 되면 훈련이 끝난 후 다음 단어를 예측 과정에서 (마치 앞서 언급한 저자의 '톺아보기'와 같은 예시처럼) 훈련 코퍼스에서 없던 단어 시퀀스라 하더라도 다음 단어를 선택할 수 있습니다.\n",
    "\n",
    "단어 간 유사도를 구할 수 있는 임베딩 벡터의 아이디어는 Word2Vec, FastText, GloVe 등으로 발전되어서 딥 러닝 자연어 처리 모델에서는 필수적으로 사용되는 방법이 되었습니다.\n",
    "임베딩 벡터에 대해서는 워드 임베딩 챕터에서 좀 더 자세히 다룹니다.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "178e3a7e51756d1a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. NNLM의 이점과 한계\n",
    "***\n",
    "\n",
    "NNLM은 기존 n-gram 언어 모델의 한계를 개선하였지만 여전히 가지는 문제점이 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "244e91ddb0278897"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) 기존 모델에서의 개선점\n",
    "NNLM은 단어를 표현하기 위해 임베딩 벡터를 사용하므로서 단어의 유사도를 계산할 수 있었습니다. 그리고 이를 통해 희소 문제(sparsity problem)를 해결하였습니다.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4209a804e2784b87"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) 고정된 길이의 입력(Fixed-length input)\n",
    "NNLM이 극복하지 못한 한계 또한 존재합니다. NNLM은 n-gram 언어 모델과 마찬가지로 다음 단어를 예측하기 위해 모든 이전 단어를 참고하는 것이 아니라 정해진 n개의 단어만을 참고할 수 있습니다.\n",
    "이 한계를 극복할 수 있는 언어 모델이 있는데, 다음 챕터에서 배우게 될 RNN(Recurrent Neural Network)을 사용한 RNN 언어 모델(Recurrent Neural Network Language Model, RNNLM)입니다.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4767549ecc135381"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
