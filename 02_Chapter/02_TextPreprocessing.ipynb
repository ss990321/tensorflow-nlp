{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "# 02.텍스트 전처리(Text preprocessing)\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "103572498d70b072"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-28T16:50:46.483997900Z",
     "start_time": "2023-12-28T16:50:46.438036300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 토큰화 : ['I', 'am', 'actively', 'looking', 'for', 'Ph.D.', 'students', '.', 'and', 'you', 'are', 'a', 'Ph.D.', 'student', '.']\n",
      "품사 태깅 : [('I', 'PRP'), ('am', 'VBP'), ('actively', 'RB'), ('looking', 'VBG'), ('for', 'IN'), ('Ph.D.', 'NNP'), ('students', 'NNS'), ('.', '.'), ('and', 'CC'), ('you', 'PRP'), ('are', 'VBP'), ('a', 'DT'), ('Ph.D.', 'NNP'), ('student', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "text = \"I am actively looking for Ph.D. students. and you are a Ph.D. student.\"\n",
    "tokenized_sentence = word_tokenize(text)\n",
    "\n",
    "print('단어 토큰화 :',tokenized_sentence)\n",
    "print('품사 태깅 :',pos_tag(tokenized_sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKT 형태소 분석 : ['열심히', '코딩', '한', '당신', ',', '연휴', '에는', '여행', '을', '가봐요']\n",
      "OKT 품사 태깅 : [('열심히', 'Adverb'), ('코딩', 'Noun'), ('한', 'Josa'), ('당신', 'Noun'), (',', 'Punctuation'), ('연휴', 'Noun'), ('에는', 'Josa'), ('여행', 'Noun'), ('을', 'Josa'), ('가봐요', 'Verb')]\n",
      "OKT 명사 추출 : ['코딩', '당신', '연휴', '여행']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Kkma\n",
    "\n",
    "okt = Okt()\n",
    "kkma = Kkma()\n",
    "\n",
    "print('OKT 형태소 분석 :', okt.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print('OKT 품사 태깅 :', okt.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print('OKT 명사 추출 :', okt.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T16:50:46.760993300Z",
     "start_time": "2023-12-28T16:50:46.473009800Z"
    }
   },
   "id": "99f850e36a348fb7"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "꼬꼬마 형태소 분석 : ['열심히', '코딩', '하', 'ㄴ', '당신', ',', '연휴', '에', '는', '여행', '을', '가보', '아요']\n",
      "꼬꼬마 품사 태깅 : [('열심히', 'MAG'), ('코딩', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD'), ('당신', 'NP'), (',', 'SP'), ('연휴', 'NNG'), ('에', 'JKM'), ('는', 'JX'), ('여행', 'NNG'), ('을', 'JKO'), ('가보', 'VV'), ('아요', 'EFN')]\n",
      "꼬꼬마 명사 추출 : ['코딩', '당신', '연휴', '여행']\n"
     ]
    }
   ],
   "source": [
    "print('꼬꼬마 형태소 분석 :', kkma.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print('꼬꼬마 품사 태깅 :', kkma.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print('꼬꼬마 명사 추출 :', kkma.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T16:50:47.019990900Z",
     "start_time": "2023-12-28T16:50:46.766025100Z"
    }
   },
   "id": "8c8ffc0748b8267e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## 02-03 표제어 추출(Lemmatization)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db1a4955507dffe3"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "표제어 추출 전 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
      "표제어 추출 후 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
    "\n",
    "print('표제어 추출 전 :',words)\n",
    "print('표제어 추출 후 :',[lemmatizer.lemmatize(word) for word in words])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T16:50:47.062992Z",
     "start_time": "2023-12-28T16:50:47.026991900Z"
    }
   },
   "id": "1cc2ab6417a1194a"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "표제어 추출 전 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
      "\n",
      "re1 :  die\n",
      "표제어 수정 추출1 ['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'die', 'watched', 'ha', 'starting']\n",
      "\n",
      "re2 :  watch\n",
      "표제어 수정 추출2 ['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'die', 'watch', 'ha', 'starting']\n",
      "\n",
      "re3 :  have\n",
      "표제어 수정 추출3 ['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'die', 'watch', 'have', 'starting']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
    "\n",
    "print('표제어 추출 전 :',words)\n",
    "\n",
    "result = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "dies = 'dies'\n",
    "watched = 'watched'\n",
    "has = 'has'\n",
    "\n",
    "num=0\n",
    "while num<len(result):\n",
    "    if words[num] == dies :\n",
    "        re1 = lemmatizer.lemmatize('dies', 'v')\n",
    "        print('\\nre1 : ', re1)\n",
    "        result[num] = re1\n",
    "        print('표제어 수정 추출1', result)\n",
    "        \n",
    "    elif words[num] == watched : \n",
    "        re2 = lemmatizer.lemmatize('watched', 'v')\n",
    "        print('\\nre2 : ', re2)\n",
    "        result[num] = re2\n",
    "        print('표제어 수정 추출2', result)\n",
    "         \n",
    "    elif words[num] == has :\n",
    "        re3 = lemmatizer.lemmatize('has', 'v')\n",
    "        print('\\nre3 : ', re3)\n",
    "        result[num] = re3\n",
    "        print('표제어 수정 추출3', result)\n",
    "        \n",
    "    num = num + 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T17:14:56.004532600Z",
     "start_time": "2023-12-28T17:14:55.978539500Z"
    }
   },
   "id": "d8518274d84c4654"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "944831f0e16e48e9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## 02-04 불용어(Stopword)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30cc206f2d4965bd"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from konlpy.tag import Okt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T09:46:56.949192400Z",
     "start_time": "2023-12-29T09:46:51.226608600Z"
    }
   },
   "id": "3ae529cbe79a53bb"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "불용어 10개 출력 : ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
     ]
    }
   ],
   "source": [
    "#불용어 확인하기\n",
    "stop_words_list = stopwords.words('english')\n",
    "print('불용어 개수 :', len(stop_words_list))\n",
    "print('불용어 10개 출력 :',stop_words_list[:10])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T09:52:10.092241200Z",
     "start_time": "2023-12-29T09:52:10.042205900Z"
    }
   },
   "id": "9bf8d1545771f1d6"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'set'>\n",
      "불용어 제거 전 : ['Family', 'is', 'not', 'an', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n",
      "불용어 제거 후 : ['Family', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n"
     ]
    }
   ],
   "source": [
    "#불용어 제거하기\n",
    "example = \"Family is not an important thing. It's everything.\"\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "word_tokens = word_tokenize(example)\n",
    "\n",
    "result = []\n",
    "for word in word_tokens: \n",
    "    if word not in stop_words: \n",
    "        result.append(word) \n",
    "\n",
    "print('불용어 제거 전 :',word_tokens) \n",
    "print('불용어 제거 후 :',result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T09:53:45.956294200Z",
     "start_time": "2023-12-29T09:53:45.911301500Z"
    }
   },
   "id": "41948bb650b62414"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 제거 전 : ['고기', '를', '아무렇게나', '구', '우려', '고', '하면', '안', '돼', '.', '고기', '라고', '다', '같은', '게', '아니거든', '.', '예컨대', '삼겹살', '을', '구울', '때', '는', '중요한', '게', '있지', '.']\n",
      "불용어 제거 후 : ['고기', '하면', '.', '고기', '라고', '다', '아니거든', '.', '예컨대', '삼겹살', '을', '중요한', '있지', '.']\n"
     ]
    }
   ],
   "source": [
    "#한국어에서 불용어 제거하기\n",
    "okt = Okt()\n",
    "\n",
    "example = \"고기를 아무렇게나 구우려고 하면 안 돼. 고기라고 다 같은 게 아니거든. 예컨대 삼겹살을 구울 때는 중요한 게 있지.\"\n",
    "stop_words = \"를 아무렇게나 구 우려 고 안 돼 같은 게 구울 때 는\"\n",
    "\n",
    "stop_words = set(stop_words.split(' '))\n",
    "word_tokens = okt.morphs(example)\n",
    "\n",
    "result = [word for word in word_tokens if not word in stop_words]\n",
    "\n",
    "print('불용어 제거 전 :',word_tokens) \n",
    "print('불용어 제거 후 :',result)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T10:00:59.537108Z",
     "start_time": "2023-12-29T10:00:54.075948400Z"
    }
   },
   "id": "2b35016e2f27208e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## 02-05 정규 표현식(Regular Expression)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ec97a97c14cdcb6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. 정규 표현식 문법과 모듈 함수\n",
    "***\n",
    "\n",
    "파이썬에서는 정규 표현식 모듈 re을 지원하므로, 이를 이용하면 특정 규칙이 있는 텍스트 데이터를 빠르게 정제할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d018ffc50893b954"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) 정규 표현식 문법\n",
    "\n",
    "\n",
    "| 특수문자       | 설명                                                                                                                                                                    |\n",
    "|------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| .          | 한 개의 임의의 문자를 나타냅니다. (줄바꿈 문자인 \\n는 제외)                                                                                                                                  |\n",
    "| ?          | 앞의 문자가 존재할 수도 있고, 존재하지 않을 수도 있습니다. (문자가 0개 또는 1개)                                                                                                                     |\n",
    "| *          | 앞의 문자가 무한개로 존재할 수도 있고, 존재하지 않을 수도 있습니다. (문자가 0개 또는 1개)                                                                                                                |\n",
    "| +          | 앞의 문자가 최소 한 개 이상 존재합니다. (문자가 1개 이상)                                                                                                                                   |\n",
    "| ^          | 뒤의 문자열로 문자열이 시작됩니다.                                                                                                                                                   |\n",
    "| $          | 앞의 문자열로 문자열이 끝납니다.                                                                                                                                                    |\n",
    "| {숫자}       | 숫자만큼 반복합니다.                                                                                                                                                           |\n",
    "| {숫자1, 숫자2} | 숫자1 이상 숫자2 이하만큼 반복합니다. ?, *, + 를 이것으로 대체할 수 있습니다.                                                                                                                     |\n",
    "| {숫자,}      | 숫자 이상만큼 반복합니다.                                                                                                                                                        |\n",
    "| [ ]        | 대괄호 안의 문자들 중 한 개의 문자와 매치합니다. [amk]라고 한다면 a 또는 m 또는 k 중 하나라도 존재하면 매치를 의미합니다.<br/>[a-z]와 같이 범위를 지정할 수도 있습니다.<br/>[a-zA-Z]는 알파벳 전체를 의미하는 범위이며, 문자열에 알파벳이 존재하면 매치를 의미합니다. |\n",
    "| [^문자]      | 해당 문자를 제외한 문자를 매치합니다.                                                                                                                                                 |\n",
    "| 1          | A1B 와 같이 쓰이며 A 또는 B의 의미를 가집니다.                                                                                                                                        |\n",
    "***\n",
    "정규 표현식 문법에는 역 슬래쉬(\\)를 이용하여 자주 쓰이는 문자 규칙들이 있습니다.\n",
    "\n",
    "![표](img.png)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cab2305ff74d76b9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) 정규표현식 모듈 함수\n",
    "\n",
    "| 모듈함수          | 설명                                                                                            |\n",
    "|---------------|-----------------------------------------------------------------------------------------------|\n",
    "| re.compile()  | 정규표현식을 컴파일하는 함수입니다. 다시말해, 파이썬에게 전해주는 역할을 합니다.<br/>찾고자 하는 패턴이 빈번한 경우에는 미리 컴파일 해놓고 사용하면 속도와 편의성 면에서 유리합니다. |\n",
    "| re.search()   | 문자열 전체에 대해서 정규표현식과 매치되는지를 검색합니다.<br/>(매치된다면 Match Object를 리턴하고 매치되지 않으면 아무런 값도 출력되지 않습니다.)         |\n",
    "| re.match()    | 문자열의 처음이 정규표현식과 매치되는지를 검색합니다.                                                                 |\n",
    "| re.split()    | 정규 표현식을 기준으로 문자열을 분리하여 리스트로 리턴합니다.                                                            |\n",
    "| re.findall()  | 문자열에서 정규 표현식과 매치되는 모든 경우의 문자열을 찾아서 리스트로 리턴합니다.<br/>만약, 매치되는 문자열이 없다면 빈 리스트가 리턴됩니다.                 |\n",
    "| re.finditer() | 문자열에서 정규 표현식과 매치되는 모든 경우의 문자열에 대한 이터레이터 객체를 리턴합니다.                                            |\n",
    "| re.sub()      | 문자열에서 정규 표현식과 일치하는 부분에 대해서 다른 문자열로 대체합니다.                                                     |"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa6d062551d29b2d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. 정규 표현식 실습\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b689b2386350f6d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:22:01.839131400Z",
     "start_time": "2024-01-04T06:22:01.824723700Z"
    }
   },
   "id": "4b6856aa3cc1dd69",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 1) . 기호\n",
    "# .은 한 개의 임의의 문자를 나타냅니다. 예를 들어서 정규 표현식이 a.c라고 합시다. a와 c 사이에는 어떤 1개의 문자라도 올 수 있습니다.\n",
    "\n",
    "r = re.compile(\"a.c\")\n",
    "r.search(\"kkk\") # 아무런 결과도 출력되지 않는다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:23:32.379850600Z",
     "start_time": "2024-01-04T06:23:32.339447900Z"
    }
   },
   "id": "c864292669e6c234",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(0, 3), match='abc'>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abc\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:24:11.676994600Z",
     "start_time": "2024-01-04T06:24:11.641223700Z"
    }
   },
   "id": "da4add65d2f7d911",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(0, 2), match='ac'>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) ?기호\n",
    "# ?는 ?앞의 문자가 존재할 수도 있고 존재하지 않을 수도 있는 경우를 나타냅니다.\n",
    "# 예를 들어서 정규 표현식이 ab?c라고 합시다. 이 경우 이 정규 표현식에서의 b는 있다고 취급할 수도 있고, 없다고 취급할 수도 있습니다. 즉, abc와 ac 모두 매치할 수 있습니다.\n",
    "\n",
    "r = re.compile(\"ab?c\")\n",
    "r.search(\"ac\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:28:06.391246600Z",
     "start_time": "2024-01-04T06:28:06.365008800Z"
    }
   },
   "id": "1d0f0c574855fa05",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(0, 3), match='abc'>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abc\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:28:15.569379800Z",
     "start_time": "2024-01-04T06:28:15.533856400Z"
    }
   },
   "id": "b51b4fb95609107a",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 3) *기호\n",
    "# *은 바로 앞의 문자가 0개 이상일 경우를 나타냅니다. 앞의 문자는 존재하지 않을 수도 있으며, 또는 여러 개일 수도 있습니다.\n",
    "# 정규 표현식이 ab*c라면 ac, abc, abbc, abbbc 등과 매치할 수 있으며 b의 개수는 무수히 많을 수 있습니다.\n",
    "\n",
    "r = re.compile(\"ab*c\")\n",
    "r.search(\"a\") # 아무런 결과도 출력되지 않는다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:33:45.584277600Z",
     "start_time": "2024-01-04T06:33:45.556354100Z"
    }
   },
   "id": "35b70af4158086c3",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(0, 2), match='ac'>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"ac\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:33:50.805960200Z",
     "start_time": "2024-01-04T06:33:50.776304500Z"
    }
   },
   "id": "15cc0d5fc92cfe6a",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(0, 3), match='abc'>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abc\") "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:34:09.083245900Z",
     "start_time": "2024-01-04T06:34:09.045952300Z"
    }
   },
   "id": "cc2e99d6fabf17a1",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(0, 6), match='abbbbc'>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abbbbc\") "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:34:19.019295900Z",
     "start_time": "2024-01-04T06:34:18.976435500Z"
    }
   },
   "id": "a3e1baaee2828c6b",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 4) +기호\n",
    "# +는 *와 유사합니다. 다른 점은 앞의 문자가 최소 1개 이상이어야 합니다. 정규 표현식이 ab+c라고 한다면 ac는 매치되지 않습니다.\n",
    "# 하지만 abc, abbc, abbbc 등과 매치할 수 있으며 b의 개수는 무수히 많을 수 있습니다.\n",
    "\n",
    "r = re.compile(\"ab+c\")\n",
    "r.search(\"ac\") # 아무런 결과도 출력되지 않는다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:34:51.303364900Z",
     "start_time": "2024-01-04T06:34:51.261968800Z"
    }
   },
   "id": "24ae05bc3c9d0f2a",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(0, 3), match='abc'>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abc\") "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:34:55.675628400Z",
     "start_time": "2024-01-04T06:34:55.645101200Z"
    }
   },
   "id": "feb55ce6a663c496",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(0, 6), match='abbbbc'>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abbbbc\") "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:35:00.415243600Z",
     "start_time": "2024-01-04T06:35:00.371823800Z"
    }
   },
   "id": "64e576b3c8fc7e94",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 5) ^기호\n",
    "# ^는 시작되는 문자열을 지정합니다. 정규표현식이 ^ab라면 문자열 ab로 시작되는 경우 매치합니다.\n",
    "\n",
    "r = re.compile(\"^ab\")\n",
    "\n",
    "# 아무런 결과도 출력되지 않는다.\n",
    "r.search(\"bbc\")\n",
    "r.search(\"zab\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:35:23.914167100Z",
     "start_time": "2024-01-04T06:35:23.874375700Z"
    }
   },
   "id": "8f3881da9e524d0d",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(0, 2), match='ab'>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abz\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:35:33.087925900Z",
     "start_time": "2024-01-04T06:35:33.047810800Z"
    }
   },
   "id": "9c7aa8295e8defd7",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 6) {숫자} 기호\n",
    "# 문자에 해당 기호를 붙이면, 해당 문자를 숫자만큼 반복한 것을 나타냅니다. \n",
    "# 예를 들어서 정규 표현식이 ab{2}c라면 a와 c 사이에 b가 존재하면서 b가 2개인 문자열에 대해서 매치합니다.\n",
    "\n",
    "r = re.compile(\"ab{2}c\")\n",
    "\n",
    "# 아무런 결과도 출력되지 않는다.\n",
    "r.search(\"ac\")\n",
    "r.search(\"abc\")\n",
    "r.search(\"abbbbbc\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:36:20.569515100Z",
     "start_time": "2024-01-04T06:36:20.531813200Z"
    }
   },
   "id": "2f4c2b20fda87c26",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(0, 4), match='abbc'>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abbc\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:36:26.203917400Z",
     "start_time": "2024-01-04T06:36:26.172288Z"
    }
   },
   "id": "773ca91736e673ef",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 7) {숫자1, 숫자2} 기호\n",
    "# 문자에 해당 기호를 붙이면, 해당 문자를 숫자1 이상 숫자2 이하만큼 반복합니다.\n",
    "# 예를 들어서 정규 표현식이 ab{2,8}c라면 a와 c 사이에 b가 존재하면서 b는 2개 이상 8개 이하인 문자열에 대해서 매치합니다.\n",
    "\n",
    "r = re.compile(\"ab{2,8}c\")\n",
    "\n",
    "# 아무런 결과도 출력되지 않는다.\n",
    "r.search(\"ac\") # b 0개\n",
    "r.search(\"abc\") # b 1개\n",
    "r.search(\"abbbbbbbbbc\") # b 9개"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:37:50.744485200Z",
     "start_time": "2024-01-04T06:37:50.702453500Z"
    }
   },
   "id": "5b05020617f217ed",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(0, 4), match='abbc'>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abbc\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:37:58.763182600Z",
     "start_time": "2024-01-04T06:37:58.718695100Z"
    }
   },
   "id": "e2e7823d1436c398",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(0, 10), match='abbbbbbbbc'>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abbbbbbbbc\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:38:04.672358300Z",
     "start_time": "2024-01-04T06:38:04.626982200Z"
    }
   },
   "id": "a5f41cbffc37d4fa",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 8) {숫자,} 기호\n",
    "# 문자에 해당 기호를 붙이면 해당 문자를 숫자 이상 만큼 반복합니다.\n",
    "# 예를 들어서 정규 표현식이 a{2,}bc라면 뒤에 bc가 붙으면서 a의 개수가 2개 이상인 경우인 문자열과 매치합니다. \n",
    "# 또한 만약 {0,}을 쓴다면 *와 동일한 의미가 되며, {1,}을 쓴다면 +와 동일한 의미가 됩니다.\n",
    "\n",
    "r = re.compile(\"a{2,}bc\")\n",
    "\n",
    "# 아무런 결과도 출력되지 않는다.\n",
    "r.search(\"bc\")\n",
    "r.search(\"aa\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:44:16.265753100Z",
     "start_time": "2024-01-04T06:44:16.176171Z"
    }
   },
   "id": "69b9cfc4a3080948",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(0, 4), match='aabc'>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"aabc\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:44:20.778527800Z",
     "start_time": "2024-01-04T06:44:20.736856100Z"
    }
   },
   "id": "8fb1c1a105e52218",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(0, 10), match='aaaaaaaabc'>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"aaaaaaaabc\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:44:27.456240800Z",
     "start_time": "2024-01-04T06:44:27.414493700Z"
    }
   },
   "id": "28cf2d356877cad9",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 9) [ ] 기호\n",
    "# [ ]안에 문자들을 넣으면 그 문자들 중 한 개의 문자와 매치라는 의미를 가집니다.\n",
    "# 예를 들어서 정규 표현식이 [abc]라면, a 또는 b또는 c가 들어가있는 문자열과 매치됩니다. 범위를 지정하는 것도 가능합니다.\n",
    "# [a-zA-Z]는 알파벳 전부를 의미하며, [0-9]는 숫자 전부를 의미합니다.\n",
    "\n",
    "r = re.compile(\"[abc]\") # [abc]는 [a-c]와 같다.\n",
    "r.search(\"zzz\") # 아무런 결과도 출력되지 않는다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:44:59.141372900Z",
     "start_time": "2024-01-04T06:44:59.095497700Z"
    }
   },
   "id": "6e58e6cd7e54d4d9",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(0, 1), match='a'>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"a\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:47:40.536599600Z",
     "start_time": "2024-01-04T06:47:40.442434500Z"
    }
   },
   "id": "4d4423de9414e1bd",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(0, 1), match='a'>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"aaaaaaa\")     "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:47:41.274952200Z",
     "start_time": "2024-01-04T06:47:41.185162100Z"
    }
   },
   "id": "ca12ab7166e610a4",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(0, 1), match='b'>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"baac\")      "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:47:41.785970600Z",
     "start_time": "2024-01-04T06:47:41.705542600Z"
    }
   },
   "id": "c0f70b759b951129",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 이번에는 알파벳 소문자에 대해서 범위 지정하여 정규 표현식을 만들어보고 문자열과 매치해보겠습니다.\n",
    "\n",
    "r = re.compile(\"[a-z]\")\n",
    "\n",
    "# 아무런 결과도 출력되지 않는다.\n",
    "r.search(\"AAA\")\n",
    "r.search(\"111\") "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:48:07.965654200Z",
     "start_time": "2024-01-04T06:48:07.923790900Z"
    }
   },
   "id": "4b27333091e6d70a",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(0, 1), match='a'>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"aBC\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:48:13.773067500Z",
     "start_time": "2024-01-04T06:48:13.729451700Z"
    }
   },
   "id": "c3067873bb7cc651",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 10) [^문자] 기호\n",
    "# [^문자]는 ^기호 뒤에 붙은 문자들을 제외한 모든 문자를 매치하는 역할을 합니다. \n",
    "# 예를 들어서 [^abc]라는 정규 표현식이 있다면, a 또는 b 또는 c가 들어간 문자열을 제외한 모든 문자열을 매치합니다.\n",
    "\n",
    "r = re.compile(\"[^abc]\")\n",
    "\n",
    "# 아무런 결과도 출력되지 않는다.\n",
    "r.search(\"a\")\n",
    "r.search(\"ab\") \n",
    "r.search(\"b\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:51:02.401363800Z",
     "start_time": "2024-01-04T06:51:02.359173700Z"
    }
   },
   "id": "8135961858936735",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(0, 1), match='d'>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"d\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:51:25.652731600Z",
     "start_time": "2024-01-04T06:51:25.558882500Z"
    }
   },
   "id": "bfd2578bb5cc92e6",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(0, 1), match='1'>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"1\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:51:26.106328500Z",
     "start_time": "2024-01-04T06:51:26.034910800Z"
    }
   },
   "id": "a485871649dde4df",
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. 정규 표현식 모듈 함수 예제\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e056ca294f361672"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# (1) re.match() 와 re.search()의 차이\n",
    "# search()가 정규 표현식 전체에 대해서 문자열이 매치하는지를 본다면, match()는 문자열의 첫 부분부터 정규 표현식과 매치하는지를 확인합니다. \n",
    "# 문자열 중간에 찾을 패턴이 있더라도 match 함수는 문자열의 시작에서 패턴이 일치하지 않으면 찾지 않습니다.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "311425fd1daa7e17"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "r = re.compile(\"ab.\")\n",
    "r.match(\"kkkabc\") # 아무런 결과도 출력되지 않는다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:54:46.355364100Z",
     "start_time": "2024-01-04T06:54:46.289050800Z"
    }
   },
   "id": "882d470476135621",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(3, 6), match='abc'>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"kkkabc\")  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:54:51.274907500Z",
     "start_time": "2024-01-04T06:54:51.231397800Z"
    }
   },
   "id": "780f6c42f1b5418",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(0, 3), match='abc'>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.match(\"abckkk\")  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:55:10.482752300Z",
     "start_time": "2024-01-04T06:55:10.369266200Z"
    }
   },
   "id": "91ac9320853f3984",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['사과', '딸기', '수박', '메론', '바나나']"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (2) re.split()\n",
    "# split() 함수는 입력된 정규 표현식을 기준으로 문자열들을 분리하여 리스트로 리턴합니다. \n",
    "# 토큰화에 유용하게 쓰일 수 있습니다. 공백을 기준으로 문자열 분리를 수행하고 결과로서 리스트를 리턴해봅시다.\n",
    "\n",
    "# 공백 기준 분리\n",
    "text = \"사과 딸기 수박 메론 바나나\"\n",
    "re.split(\" \", text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:58:17.567314800Z",
     "start_time": "2024-01-04T06:58:17.517624700Z"
    }
   },
   "id": "4b0b624c723b05c8",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['사과', '딸기', '수박', '메론', '바나나']"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이와 유사하게 줄바꿈이나 다른 정규 표현식을 기준으로 텍스트를 분리할 수도 있습니다.\n",
    "\n",
    "# 줄바꿈 기준 분리\n",
    "text = \"\"\"사과\n",
    "딸기\n",
    "수박\n",
    "메론\n",
    "바나나\"\"\"\n",
    "\n",
    "re.split(\"\\n\", text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:58:45.241159100Z",
     "start_time": "2024-01-04T06:58:45.192046200Z"
    }
   },
   "id": "caf95d54780a1bcb",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['사과', '딸기', '수박', '메론', '바나나']"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# '+'를 기준으로 분리\n",
    "text = \"사과+딸기+수박+메론+바나나\"\n",
    "\n",
    "re.split(\"\\+\", text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T06:58:51.088009900Z",
     "start_time": "2024-01-04T06:58:50.963782800Z"
    }
   },
   "id": "ff36a6fe3763fedd",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['010', '1234', '1234', '30']"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3) re.findall()\n",
    "# findall() 함수는 정규 표현식과 매치되는 모든 문자열들을 리스트로 리턴합니다. 단, 매치되는 문자열이 없다면 빈 리스트를 리턴합니다. \n",
    "# 임의의 텍스트에 정규 표현식으로 숫자를 의미하는 규칙으로 findall()을 수행하면 전체 텍스트로부터 숫자만 찾아내서 리스트로 리턴합니다.\n",
    "\n",
    "text = \"\"\"이름 : 김철수\n",
    "전화번호 : 010 - 1234 - 1234\n",
    "나이 : 30\n",
    "성별 : 남\"\"\"\n",
    "\n",
    "re.findall(\"\\d+\", text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T07:00:50.338247800Z",
     "start_time": "2024-01-04T07:00:50.291666600Z"
    }
   },
   "id": "83af63c555de2552",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하지만 만약 입력 텍스트에 숫자가 없다면 빈 리스트를 리턴하게 됩니다.\n",
    "\n",
    "re.findall(\"\\d+\", \"문자열입니다.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T07:03:37.948327600Z",
     "start_time": "2024-01-04T07:03:37.864775500Z"
    }
   },
   "id": "70eb490327e078d2",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular expression   A regular expression  regex or regexp     sometimes called a rational expression        is  in theoretical computer science and formal language theory  a sequence of characters that define a search pattern \n"
     ]
    }
   ],
   "source": [
    "# (4) re.sub()\n",
    "# sub() 함수는 정규 표현식 패턴과 일치하는 문자열을 찾아 다른 문자열로 대체할 수 있습니다.\n",
    "# 아래와 같은 정제 작업에 많이 사용되는데, 영어 문장에 각주 등과 같은 이유로 특수 문자가 섞여있는 경우에 특수 문자를 제거하고 싶다면 알파벳 외의 문자는 공백으로 처리하는 등의 용도로 쓸 수 있습니다.\n",
    "\n",
    "text = \"Regular expression : A regular expression, regex or regexp[1] (sometimes called a rational expression)[2][3] is, in theoretical computer science and formal language theory, a sequence of characters that define a search pattern.\"\n",
    "\n",
    "preprocessed_text = re.sub('[^a-zA-Z]', ' ', text) # 알파벳을 제외한 모든 문자 공백으로 대체\n",
    "print(preprocessed_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T07:05:55.638854900Z",
     "start_time": "2024-01-04T07:05:55.571484800Z"
    }
   },
   "id": "bb10f3d05f4185a4",
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. 정규 표현식 텍스트 전처리 예제\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8afb29bc182f039f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "text = \"\"\"100 John    PROF\n",
    "101 James   STUD\n",
    "102 Mac   STUD\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T07:06:42.583389800Z",
     "start_time": "2024-01-04T07:06:42.539136700Z"
    }
   },
   "id": "d67cefa769747292",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['100', 'John', 'PROF', '101', 'James', 'STUD', '102', 'Mac', 'STUD']"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \\s+는 공백을 찾아내는 정규표현식입니다. 뒤에 붙는 +는 최소 1개 이상의 패턴을 찾아낸다는 의미입니다.\n",
    "# s는 공백을 의미하기 때문에 최소 1개 이상의 공백인 패턴을 찾아냅니다. split은 주어진 정규표현식을 기준으로 분리하므로 결과는 아래와 같습니다.\n",
    "\n",
    "re.split('\\s+', text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T07:07:05.775971400Z",
     "start_time": "2024-01-04T07:07:05.730876Z"
    }
   },
   "id": "6983abba5c0a7e9e",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['100', '101', '102']"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 해당 입력으로부터 숫자만을 뽑아온다고 해봅시다. 여기서 \\d는 숫자에 해당되는 정규표현식입니다.\n",
    "# +를 붙이면 최소 1개 이상의 숫자에 해당하는 값을 의미합니다. findall()은 해당 표현식에 일치하는 값을 찾아냅니다.\n",
    "\n",
    "re.findall('\\d+',text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T07:08:44.805873100Z",
     "start_time": "2024-01-04T07:08:44.667264200Z"
    }
   },
   "id": "f7c4dc4d540bdcf9",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['J', 'P', 'R', 'O', 'F', 'J', 'S', 'T', 'U', 'D', 'M', 'S', 'T', 'U', 'D']"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텍스트로부터 대문자인 행의 값만 가져와봅시다. 이 경우 정규 표현식에 대문자를 기준으로 매치시키면 됩니다. \n",
    "# 하지만 정규 표현식에 대문자라는 기준만을 넣을 경우에는 문자열을 가져오는 것이 아니라 모든 대문자 각각을 갖고오게 됩니다.\n",
    "\n",
    "re.findall('[A-Z]',text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T07:08:51.197802300Z",
     "start_time": "2024-01-04T07:08:51.147188800Z"
    }
   },
   "id": "fc9ae04507fb7778",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['PROF', 'STUD', 'STUD']"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 대문자가 연속적으로 네 번 등장하는 경우라는 조건을 추가해봅시다.\n",
    "\n",
    "re.findall('[A-Z]{4}',text) # 대문자로 구성된 문자열들을 가져옴"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T07:11:18.691344900Z",
     "start_time": "2024-01-04T07:11:18.632155600Z"
    }
   },
   "id": "686e67acdaf61623",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['John', 'James', 'Mac']"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이름의 경우에는 대문자와 소문자가 섞여있다.\n",
    "# 이름에 대한 행의 값을 갖고오고 싶다면 처음에 대문자가 등장한 후에 소문자가 여러번 등장하는 경우에 매치하게 합니다.\n",
    "\n",
    "re.findall('[A-Z][a-z]+',text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T07:12:14.804800100Z",
     "start_time": "2024-01-04T07:12:14.753992600Z"
    }
   },
   "id": "43e5e1c0606f6da8",
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. 정규 표현식을 이용한 토큰화\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67df9496614fb33f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "NLTK에서는 정규 표현식을 사용해서 단어 토큰화를 수행하는 RegexpTokenizer를 지원합니다.\n",
    "RegexpTokenizer()에서 괄호 안에 하나의 토큰으로 규정하기를 원하는 정규 표현식을 넣어서 토큰화를 수행합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8608ac579885e240"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer1 :  ['Don', 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'Mr', 'Jone', 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n",
      "tokenizer2 :  [\"Don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name,', 'Mr.', \"Jone's\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "text = \"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop\"\n",
    "\n",
    "tokenizer1 = RegexpTokenizer(\"[\\w]+\") # tokenizer1에 사용한 \\w+는 문자 또는 숫자가 1개 이상인 경우를 의미합니다.\n",
    "tokenizer2 = RegexpTokenizer(\"\\s+\", gaps=True) # tokenizer2에서는 공백을 기준으로 토큰화하도록 했습니다.\n",
    "#  gaps=true는 해당 정규 표현식을 토큰으로 나누기 위한 기준으로 사용한다는 의미입니다. \n",
    "#  만약 gaps=True라는 부분을 기재하지 않는다면, 토큰화의 결과는 공백들만 나오게 됩니다.\n",
    "\n",
    "print(\"tokenizer1 : \", tokenizer1.tokenize(text))\n",
    "print(\"tokenizer2 : \", tokenizer2.tokenize(text))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T07:18:08.495926900Z",
     "start_time": "2024-01-04T07:18:08.393187900Z"
    }
   },
   "id": "c46b968f6d1320e9",
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "source": [
    "tokenizer2의 결과는 위의 tokenizer1의 결과와는 달리 아포스트로피나 온점을 제외하지 않고 토큰화가 수행된 것을 확인할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a56b38070eb2ef5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## 02-06 정수 인코딩(Integer Encoding)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10e7c88da89fb1fc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. 정수 인코딩(Integer Encoding)\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc2c41e196dfda7f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) dictionary 사용하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6097247a66c0563f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "raw_text = \"A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T11:01:25.313583500Z",
     "start_time": "2023-12-29T11:01:25.288589700Z"
    }
   },
   "id": "42b229f3911f612"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A barber is a person.', 'a barber is good person.', 'a barber is huge person.', 'he Knew A Secret!', 'The Secret He Kept is huge secret.', 'Huge secret.', 'His barber kept his word.', 'a barber kept his word.', 'His barber kept his secret.', 'But keeping and keeping such a huge secret to himself was driving the barber crazy.', 'the barber went up a huge mountain.']\n"
     ]
    }
   ],
   "source": [
    "# 문장 토큰화\n",
    "sentences = sent_tokenize(raw_text)\n",
    "print(sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T11:02:00.879825100Z",
     "start_time": "2023-12-29T11:02:00.835820900Z"
    }
   },
   "id": "ef5a2cde3ca0d626"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n",
      "단어 집합 :  {'barber': 8, 'person': 3, 'good': 1, 'huge': 5, 'knew': 1, 'secret': 6, 'kept': 4, 'word': 2, 'keeping': 2, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1}\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "vocab = {} # 딕셔너리\n",
    "preprocessed_sentences = []\n",
    "stop_words = set(stopwords.words('english')) # 불용어 set\n",
    "\n",
    "for sentence in sentences:\n",
    "    # 단어 토큰화\n",
    "    tokenized_sentence = word_tokenize(sentence)\n",
    "    result = []\n",
    "\n",
    "    for word in tokenized_sentence: \n",
    "        word = word.lower() # 모든 단어를 소문자화하여 단어의 개수를 줄인다.\n",
    "        if word not in stop_words: # 단어 토큰화 된 결과에 대해서 불용어를 제거한다.\n",
    "            if len(word) > 2: # 단어 길이가 2이하인 경우에 대하여 추가로 단어를 제거한다.\n",
    "                result.append(word) \n",
    "                if word not in vocab: # vocab에는 각 단어에 대한 빈도수가 기록된다.\n",
    "                    vocab[word] = 0 # 없으면 0 \n",
    "                vocab[word] += 1 # 있으면 빈도 +1\n",
    "    preprocessed_sentences.append(result) \n",
    "print(preprocessed_sentences)\n",
    "print('단어 집합 : ', vocab)\n",
    "print(vocab[\"barber\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T11:46:45.515929500Z",
     "start_time": "2023-12-29T11:46:45.442934500Z"
    }
   },
   "id": "7cd460665e165c1b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3), ('word', 2), ('keeping', 2), ('good', 1), ('knew', 1), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)]\n"
     ]
    }
   ],
   "source": [
    "# 빈도 높은 순서로 정렬\n",
    "vocab_sorted = sorted(vocab.items(), key = lambda x:x[1], reverse = True)\n",
    "print(vocab_sorted)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T11:09:20.989385200Z",
     "start_time": "2023-12-29T11:09:20.977391600Z"
    }
   },
   "id": "1bf6550408ba23a3"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7}\n"
     ]
    }
   ],
   "source": [
    "# 높은 빈도수를 가진 단어일수록 낮은 정수를 부여합니다. 정수는 1부터 부여\n",
    "\n",
    "word_to_index = {}\n",
    "i = 0\n",
    "for (word, frequency) in vocab_sorted :\n",
    "    if frequency > 1 : # 빈도수가 작은 단어는 제외.\n",
    "        i = i + 1\n",
    "        word_to_index[word] = i\n",
    "\n",
    "print(word_to_index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T11:49:02.211862200Z",
     "start_time": "2023-12-29T11:49:02.161830500Z"
    }
   },
   "id": "171888cf41252ef9"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
     ]
    }
   ],
   "source": [
    "# 빈도수 상위 5개만 사용\n",
    "\n",
    "vocab_size = 5\n",
    "\n",
    "# 인덱스가 5 초과인 단어 제거\n",
    "words_frequency = []\n",
    "\n",
    "for word, index in word_to_index.items():\n",
    "    if index >= vocab_size + 1:\n",
    "        words_frequency.append(word)\n",
    "\n",
    "#컴프리헨션           |word|ㅡ> == words_frequency.append(word) : 맨 앞의 word는 리스트에 추가하는 표현식이다.\n",
    "# words_frequency = [word for word, index in word_to_index.items() if index >= vocab_size + 1]\n",
    "\n",
    "# 해당 단어에 대한 인덱스 정보를 삭제\n",
    "for w in words_frequency:\n",
    "    del word_to_index[w]\n",
    "print(word_to_index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T12:26:10.055285800Z",
     "start_time": "2023-12-29T12:25:44.909367700Z"
    }
   },
   "id": "5cbbae98af8bf1cd"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'OOV': 6}\n"
     ]
    }
   ],
   "source": [
    "#Out-Of-Vocabulary(단어 집합에 없는 단어) 문제\n",
    "\n",
    "word_to_index['OOV'] = len(word_to_index) + 1\n",
    "print(word_to_index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T12:36:40.123455700Z",
     "start_time": "2023-12-29T12:36:40.081462700Z"
    }
   },
   "id": "37f2f468b9f2ca82"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5], [1, 6, 5], [1, 3, 5], [6, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [6, 6, 3, 2, 6, 1, 6], [1, 6, 3, 6]]\n"
     ]
    }
   ],
   "source": [
    "# word_to_index를 사용하여 sentences의 모든 단어들을 맵핑되는 정수로 인코딩\n",
    "\n",
    "encoded_sentences = []\n",
    "for sentence in preprocessed_sentences:\n",
    "    encoded_sentence = []\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            # 단어 집합에 있는 단어라면 해당 단어의 정수를 리턴.\n",
    "            encoded_sentence.append(word_to_index[word])\n",
    "        except KeyError:\n",
    "            # 만약 단어 집합에 없는 단어라면 'OOV'의 정수를 리턴.\n",
    "            encoded_sentence.append(word_to_index['OOV'])\n",
    "    encoded_sentences.append(encoded_sentence)\n",
    "print(encoded_sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T12:37:44.119738900Z",
     "start_time": "2023-12-29T12:37:44.080736900Z"
    }
   },
   "id": "4f50ed555e42cc03"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) Counter 사용하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86397f29dfca111d"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(preprocessed_sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T12:59:02.915325100Z",
     "start_time": "2023-12-29T12:59:02.903288600Z"
    }
   },
   "id": "fcc87479aaf4b84f"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['barber', 'person', 'barber', 'good', 'person', 'barber', 'huge', 'person', 'knew', 'secret', 'secret', 'kept', 'huge', 'secret', 'huge', 'secret', 'barber', 'kept', 'word', 'barber', 'kept', 'word', 'barber', 'kept', 'secret', 'keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy', 'barber', 'went', 'huge', 'mountain']\n"
     ]
    }
   ],
   "source": [
    "# 하나의 리스트로 만들기\n",
    "\n",
    "# words = np.hstack(preprocessed_sentences)으로도 수행 가능.\n",
    "all_words_list = sum(preprocessed_sentences, [])\n",
    "print(all_words_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T12:59:07.653899900Z",
     "start_time": "2023-12-29T12:59:07.619910400Z"
    }
   },
   "id": "148ccde2e399f54"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'barber': 8, 'secret': 6, 'huge': 5, 'kept': 4, 'person': 3, 'word': 2, 'keeping': 2, 'good': 1, 'knew': 1, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1})\n"
     ]
    }
   ],
   "source": [
    "# 파이썬의 Counter()의 입력으로 사용하면 중복을 제거하고 단어의 빈도수를 기록\n",
    "\n",
    "# 파이썬의 Counter 모듈을 이용하여 단어의 빈도수 카운트\n",
    "vocab = Counter(all_words_list)\n",
    "print(vocab)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T12:59:08.379914300Z",
     "start_time": "2023-12-29T12:59:08.338911900Z"
    }
   },
   "id": "329223a1f5b67fc"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# vocab에 단어를 입력하면 빈도수를 리턴합니다.\n",
    "\n",
    "print(vocab[\"barber\"]) # 'barber'라는 단어의 빈도수 출력"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T12:59:11.167897400Z",
     "start_time": "2023-12-29T12:59:11.138900400Z"
    }
   },
   "id": "7965ed173dc92aaa"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]\n"
     ]
    }
   ],
   "source": [
    "# 등장 빈도수 상위 5개의 단어만 단어 집합으로 저장\n",
    "\n",
    "vocab_size = 5\n",
    "vocab = vocab.most_common(vocab_size) # 등장 빈도수가 높은 상위 5개의 단어만 저장\n",
    "print(vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T12:59:20.458328600Z",
     "start_time": "2023-12-29T12:59:20.401331300Z"
    }
   },
   "id": "defe0346679e4bd9"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
     ]
    }
   ],
   "source": [
    "# 높은 빈도수를 가진 단어일수록 낮은 정수 인덱스를 부여\n",
    "\n",
    "word_to_index = {}\n",
    "i = 0\n",
    "for (word, frequency) in vocab :\n",
    "    i = i + 1\n",
    "    word_to_index[word] = i\n",
    "\n",
    "print(word_to_index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T13:00:23.536304500Z",
     "start_time": "2023-12-29T13:00:23.526293800Z"
    }
   },
   "id": "66c46b6cf2d35a28"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3) NLTK의 FreqDist 사용하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5bcb1063a1c7eae"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T13:01:23.775715800Z",
     "start_time": "2023-12-29T13:01:23.743686800Z"
    }
   },
   "id": "d89ac6ad7d6032e"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "FreqDist({'barber': 8, 'secret': 6, 'huge': 5, 'kept': 4, 'person': 3, 'word': 2, 'keeping': 2, 'good': 1, 'knew': 1, 'driving': 1, ...})"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.hstack으로 문장 구분을 제거\n",
    "vocab = FreqDist(np.hstack(preprocessed_sentences))\n",
    "vocab"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T13:02:26.377987600Z",
     "start_time": "2023-12-29T13:02:26.297985600Z"
    }
   },
   "id": "67307d7c6f2b22f0"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(vocab[\"barber\"]) # 'barber'라는 단어의 빈도수 출력"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T13:01:42.525522Z",
     "start_time": "2023-12-29T13:01:42.486480400Z"
    }
   },
   "id": "b9819f705de54ee"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 5\n",
    "vocab = vocab.most_common(vocab_size) # 등장 빈도수가 높은 상위 5개의 단어만 저장\n",
    "print(vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T13:03:01.726195100Z",
     "start_time": "2023-12-29T13:03:01.668157400Z"
    }
   },
   "id": "8e70140722df26"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
     ]
    }
   ],
   "source": [
    "# enumerate()를 사용하여 높은 빈도수의 단어에 낮은 정수 인덱스를 부여\n",
    "\n",
    "word_to_index = {word[0] : index + 1 for index, word in enumerate(vocab)}\n",
    "print(word_to_index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T13:03:17.162521100Z",
     "start_time": "2023-12-29T13:03:17.091516Z"
    }
   },
   "id": "41e3ae5eb95a875d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4) enumerate 이해하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6007d8478d230fa"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value : a, index: 0\n",
      "value : b, index: 1\n",
      "value : c, index: 2\n",
      "value : d, index: 3\n",
      "value : e, index: 4\n"
     ]
    }
   ],
   "source": [
    "# enumerate()는 순서가 있는 자료형(list, set, tuple, dictionary, string)을 입력으로 받아 인덱스를 순차적으로 함께 리턴한다는 특징이 있습니다.\n",
    "\n",
    "test_input = ['a', 'b', 'c', 'd', 'e']\n",
    "for index, value in enumerate(test_input): # 입력의 순서대로 0부터 인덱스를 부여함.\n",
    "  print(\"value : {}, index: {}\".format(value, index))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T13:10:55.915245700Z",
     "start_time": "2023-12-29T13:10:55.860248500Z"
    }
   },
   "id": "3af7ed022b5bd4e9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. 케라스(Keras)의 텍스트 전처리\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a612c6566518a319"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T13:16:49.027850500Z",
     "start_time": "2023-12-29T13:16:48.980829700Z"
    }
   },
   "id": "b2823d46ecb04e4b"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "preprocessed_sentences = [['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T13:16:59.593118400Z",
     "start_time": "2023-12-29T13:16:59.569118Z"
    }
   },
   "id": "c5838bbe1b6b303c"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "# fit_on_texts()안에 코퍼스를 입력으로 하면 빈도수를 기준으로 단어 집합을 생성.\n",
    "tokenizer.fit_on_texts(preprocessed_sentences)\n",
    "\n",
    "print(preprocessed_sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T15:12:12.751852500Z",
     "start_time": "2023-12-29T15:12:12.700824900Z"
    }
   },
   "id": "f1754e69e5330f90"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7, 'good': 8, 'knew': 9, 'driving': 10, 'crazy': 11, 'went': 12, 'mountain': 13}\n"
     ]
    }
   ],
   "source": [
    "# 각 단어에 인덱스가 어떻게 부여되었는지를 보려면, word_index를 사용합니다.\n",
    "print(tokenizer.word_index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T13:17:26.574183700Z",
     "start_time": "2023-12-29T13:17:26.508171800Z"
    }
   },
   "id": "ab374cafd612ae45"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('barber', 8), ('person', 3), ('good', 1), ('huge', 5), ('knew', 1), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)])\n"
     ]
    }
   ],
   "source": [
    "# 각 단어가 카운트를 수행하였을 때 몇 개였는지를 보고자 한다면 word_counts를 사용합니다.\n",
    "print(tokenizer.word_counts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T15:13:24.639821300Z",
     "start_time": "2023-12-29T15:13:24.577787400Z"
    }
   },
   "id": "6cb34751123888f0"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"
     ]
    }
   ],
   "source": [
    "# texts_to_sequences()는 입력으로 들어온 코퍼스에 대해서 각 단어를 이미 정해진 인덱스로 변환합니다.\n",
    "print(tokenizer.texts_to_sequences(preprocessed_sentences))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T15:13:58.791325100Z",
     "start_time": "2023-12-29T15:13:58.710328900Z"
    }
   },
   "id": "ce301e011ba3f5ad"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "# 상위 단어 5개만 사용 \n",
    "vocab_size = 5\n",
    "tokenizer = Tokenizer(num_words = vocab_size + 1) # 상위 5개 단어만 사용\n",
    "tokenizer.fit_on_texts(preprocessed_sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T15:15:11.754009500Z",
     "start_time": "2023-12-29T15:15:11.708025300Z"
    }
   },
   "id": "79bf46f59945ff4e"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7, 'good': 8, 'knew': 9, 'driving': 10, 'crazy': 11, 'went': 12, 'mountain': 13}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index) # 안바뀜"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T15:15:35.679546400Z",
     "start_time": "2023-12-29T15:15:35.617513600Z"
    }
   },
   "id": "1071905b23208239"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('barber', 8), ('person', 3), ('good', 1), ('huge', 5), ('knew', 1), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)])\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_counts) #안바뀜"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T15:17:07.225647100Z",
     "start_time": "2023-12-29T15:17:07.175651300Z"
    }
   },
   "id": "66795031c86c58de"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5], [1, 5], [1, 3, 5], [2], [2, 4, 3, 2], [3, 2], [1, 4], [1, 4], [1, 4, 2], [3, 2, 1], [1, 3]]\n"
     ]
    }
   ],
   "source": [
    "# 사실 실제 적용은 texts_to_sequences를 사용할 때 적용이 됩니다.\n",
    "print(tokenizer.texts_to_sequences(preprocessed_sentences))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T15:17:48.696078Z",
     "start_time": "2023-12-29T15:17:48.626083Z"
    }
   },
   "id": "79c3c8b76b957ba0"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 OOV의 인덱스 : 1\n"
     ]
    }
   ],
   "source": [
    "# 단어 집합에 없는 단어들은 OOV로 간주하여 보존하고 싶다면 Tokenizer의 인자 oov_token을 사용합니다.\n",
    "\n",
    "# 숫자 0과 OOV를 고려해서 단어 집합의 크기는 +2\n",
    "vocab_size = 5\n",
    "tokenizer = Tokenizer(num_words = vocab_size + 2, oov_token = 'OOV')\n",
    "tokenizer.fit_on_texts(preprocessed_sentences)\n",
    "\n",
    "# 케라스 토크나이저는 기본적으로 'OOV'의 인덱스를 1로 합니다.\n",
    "print('단어 OOV의 인덱스 : {}'.format(tokenizer.word_index['OOV']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T15:19:28.257267800Z",
     "start_time": "2023-12-29T15:19:28.186271800Z"
    }
   },
   "id": "7cbfd3af9a15db87"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 6], [2, 1, 6], [2, 4, 6], [1, 3], [3, 5, 4, 3], [4, 3], [2, 5, 1], [2, 5, 1], [2, 5, 3], [1, 1, 4, 3, 1, 2, 1], [2, 1, 4, 1]]\n"
     ]
    }
   ],
   "source": [
    "# 빈도수 상위 5개의 단어는 2 ~ 6까지의 인덱스를 가졌으며, 그 외 단어 집합에 없는 'good'과 같은 단어들은 전부 'OOV'의 인덱스인 1로 인코딩되었습니다.\n",
    "print(tokenizer.texts_to_sequences(preprocessed_sentences)) # 원래 단어들은 인코딩에서 +1 됨, oov는 1로 표현됨."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T15:23:30.621718900Z",
     "start_time": "2023-12-29T15:23:30.588723400Z"
    }
   },
   "id": "71ce43ec2da09191"
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## 02-07 패딩(Padding)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9666e0e219c64468"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Numpy로 패딩하기\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5469b9460bcf5aa"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T09:28:56.874650400Z",
     "start_time": "2023-12-30T09:28:56.748653800Z"
    }
   },
   "id": "c1f94d503ebffe10"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "preprocessed_sentences = [['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T09:29:07.143609500Z",
     "start_time": "2023-12-30T09:29:07.035582300Z"
    }
   },
   "id": "d71cd5181cecc387"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(preprocessed_sentences)\n",
    "encoded = tokenizer.texts_to_sequences(preprocessed_sentences)\n",
    "print(encoded)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T09:29:24.585017600Z",
     "start_time": "2023-12-30T09:29:24.504011100Z"
    }
   },
   "id": "b31b2fefe298cba4"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 길이 : 7\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(item) for item in encoded)\n",
    "print('최대 길이 :', max_len)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T09:59:23.203487800Z",
     "start_time": "2023-12-30T09:59:23.144489900Z"
    }
   },
   "id": "6b82e22c0ce279e6"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  5  0  0  0  0  0]\n",
      " [ 1  8  5  0  0  0  0]\n",
      " [ 1  3  5  0  0  0  0]\n",
      " [ 9  2  0  0  0  0  0]\n",
      " [ 2  4  3  2  0  0  0]\n",
      " [ 3  2  0  0  0  0  0]\n",
      " [ 1  4  6  0  0  0  0]\n",
      " [ 1  4  6  0  0  0  0]\n",
      " [ 1  4  2  0  0  0  0]\n",
      " [ 7  7  3  2 10  1 11]\n",
      " [ 1 12  3 13  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# 제로 패딩(zero padding)\n",
    "\n",
    "for sentence in encoded:\n",
    "    while len(sentence) < max_len:\n",
    "        sentence.append(0)\n",
    "\n",
    "padded_np = np.array(encoded)\n",
    "print(padded_np)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T09:59:48.298529600Z",
     "start_time": "2023-12-30T09:59:48.125532400Z"
    }
   },
   "id": "4a22a73e6fa87bc3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. 케라스 전처리 도구로 패딩하기\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1473e699083cb021"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# 케라스에서는 위와 같은 패딩을 위해 pad_sequences()를 제공하고 있습니다.\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T10:06:26.544877Z",
     "start_time": "2023-12-30T10:06:26.462871400Z"
    }
   },
   "id": "669e6fb2dcd80f4a"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizer.texts_to_sequences(preprocessed_sentences)\n",
    "print(encoded)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T10:06:40.997814200Z",
     "start_time": "2023-12-30T10:06:40.911819600Z"
    }
   },
   "id": "2384f0998b29529c"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  1  5]\n",
      " [ 0  0  0  0  1  8  5]\n",
      " [ 0  0  0  0  1  3  5]\n",
      " [ 0  0  0  0  0  9  2]\n",
      " [ 0  0  0  2  4  3  2]\n",
      " [ 0  0  0  0  0  3  2]\n",
      " [ 0  0  0  0  1  4  6]\n",
      " [ 0  0  0  0  1  4  6]\n",
      " [ 0  0  0  0  1  4  2]\n",
      " [ 7  7  3  2 10  1 11]\n",
      " [ 0  0  0  1 12  3 13]]\n"
     ]
    }
   ],
   "source": [
    "# pad_sequences는 기본적으로 문서의 앞에 0으로 채웁니다.\n",
    "\n",
    "padded = pad_sequences(encoded)\n",
    "print(padded)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T10:07:16.112229400Z",
     "start_time": "2023-12-30T10:07:16.024911300Z"
    }
   },
   "id": "50a990d648370d09"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  5  0  0  0  0  0]\n",
      " [ 1  8  5  0  0  0  0]\n",
      " [ 1  3  5  0  0  0  0]\n",
      " [ 9  2  0  0  0  0  0]\n",
      " [ 2  4  3  2  0  0  0]\n",
      " [ 3  2  0  0  0  0  0]\n",
      " [ 1  4  6  0  0  0  0]\n",
      " [ 1  4  6  0  0  0  0]\n",
      " [ 1  4  2  0  0  0  0]\n",
      " [ 7  7  3  2 10  1 11]\n",
      " [ 1 12  3 13  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# 뒤에 0을 채우고 싶다면 인자로 padding='post'를 주면됩니다.\n",
    "\n",
    "padded = pad_sequences(encoded, padding='post')\n",
    "print(padded)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T10:08:40.765909400Z",
     "start_time": "2023-12-30T10:08:40.677913500Z"
    }
   },
   "id": "e6566435b3307a91"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy를 이용하여 패딩을 했을 때와 결과가 동일합니다. 실제로 결과가 동일한지 두 결과를 비교합니다.\n",
    "(padded == padded_np).all()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T10:08:57.285726200Z",
     "start_time": "2023-12-30T10:08:57.214722900Z"
    }
   },
   "id": "9966a02b66e772ec"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  5  0  0  0]\n",
      " [ 1  8  5  0  0]\n",
      " [ 1  3  5  0  0]\n",
      " [ 9  2  0  0  0]\n",
      " [ 2  4  3  2  0]\n",
      " [ 3  2  0  0  0]\n",
      " [ 1  4  6  0  0]\n",
      " [ 1  4  6  0  0]\n",
      " [ 1  4  2  0  0]\n",
      " [ 3  2 10  1 11]\n",
      " [ 1 12  3 13  0]]\n"
     ]
    }
   ],
   "source": [
    "# maxlen의 인자로 정수를 주면, 해당 정수로 모든 문서의 길이를 동일하게 합니다.\n",
    "\n",
    "padded = pad_sequences(encoded, padding='post', maxlen=5)\n",
    "print(padded)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T10:21:23.659593700Z",
     "start_time": "2023-12-30T10:21:23.555591800Z"
    }
   },
   "id": "3b9b6d08cb5dae0d"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  5  0  0  0]\n",
      " [ 1  8  5  0  0]\n",
      " [ 1  3  5  0  0]\n",
      " [ 9  2  0  0  0]\n",
      " [ 2  4  3  2  0]\n",
      " [ 3  2  0  0  0]\n",
      " [ 1  4  6  0  0]\n",
      " [ 1  4  6  0  0]\n",
      " [ 1  4  2  0  0]\n",
      " [ 7  7  3  2 10]\n",
      " [ 1 12  3 13  0]]\n"
     ]
    }
   ],
   "source": [
    "# truncating='post'를 사용할 경우 뒤의 단어가 삭제됩니다.\n",
    "\n",
    "padded = pad_sequences(encoded, padding='post', truncating='post', maxlen=5)\n",
    "print(padded)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T10:23:04.000347300Z",
     "start_time": "2023-12-30T10:23:03.907344Z"
    }
   },
   "id": "b74020b44cf46cc9"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "# 숫자 0이 아니라 다른 숫자를 패딩을 위한 숫자로 사용하고 싶다면 이 또한 가능합니다.\n",
    "\n",
    "last_value = len(tokenizer.word_index) + 1 # 단어 집합의 크기보다 1 큰 숫자를 사용\n",
    "print(last_value)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T10:23:36.279145300Z",
     "start_time": "2023-12-30T10:23:36.178149700Z"
    }
   },
   "id": "7193803ae3bfb7bc"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  5 14 14 14 14 14]\n",
      " [ 1  8  5 14 14 14 14]\n",
      " [ 1  3  5 14 14 14 14]\n",
      " [ 9  2 14 14 14 14 14]\n",
      " [ 2  4  3  2 14 14 14]\n",
      " [ 3  2 14 14 14 14 14]\n",
      " [ 1  4  6 14 14 14 14]\n",
      " [ 1  4  6 14 14 14 14]\n",
      " [ 1  4  2 14 14 14 14]\n",
      " [ 7  7  3  2 10  1 11]\n",
      " [ 1 12  3 13 14 14 14]]\n"
     ]
    }
   ],
   "source": [
    "# pad_sequences의 인자로 value를 사용하면 0이 아닌 다른 숫자로 패딩이 가능합니다.\n",
    "\n",
    "padded = pad_sequences(encoded, padding='post', value=last_value)\n",
    "print(padded)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T10:26:01.290356400Z",
     "start_time": "2023-12-30T10:26:01.133351400Z"
    }
   },
   "id": "41b231abe17320da"
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## 02-08 원-핫 인코딩(One-Hot Encoding)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "631b3a4bcfdf6380"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. 원-핫 인코딩(One-Hot Encoding)이란?\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0130dd86f83d52a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**원-핫 인코딩의 두 가지 과정**\n",
    "- 첫째, 정수 인코딩을 수행합니다. 다시 말해 각 단어에 고유한 정수를 부여합니다.\n",
    "- 둘째, 표현하고 싶은 단어의 고유한 정수를 인덱스로 간주하고 해당 위치에 1을 부여하고, 다른 단어의 인덱스의 위치에는 0을 부여합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5fa3657ad486fa4"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '는', '자연어', '처리', '를', '배운다']\n"
     ]
    }
   ],
   "source": [
    "# 문장 : 나는 자연어 처리를 배운다\n",
    "# Okt 형태소 분석기를 통해서 문장에 대해서 토큰화를 수행합니다.\n",
    "\n",
    "from konlpy.tag import Okt  \n",
    "\n",
    "okt = Okt()  \n",
    "tokens = okt.morphs(\"나는 자연어 처리를 배운다\")  \n",
    "print(tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T11:34:19.185840800Z",
     "start_time": "2023-12-30T11:34:12.864763200Z"
    }
   },
   "id": "d43dcd8e21d40577"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합 : {'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '배운다': 5}\n"
     ]
    }
   ],
   "source": [
    "# 각 토큰에 대해서 고유한 정수를 부여합니다.\n",
    "# 지금은 문장이 짧기 때문에 각 단어의 빈도수를 고려하지 않지만, 빈도수 순으로 단어를 정렬하여 정수를 부여하는 경우가 많습니다.\n",
    "\n",
    "word_to_index = {word : index for index, word in enumerate(tokens)}\n",
    "print('단어 집합 :',word_to_index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T11:37:50.485733900Z",
     "start_time": "2023-12-30T11:37:50.203656500Z"
    }
   },
   "id": "b2d2420f2392336"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "[0, 0, 1, 0, 0, 0]"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰을 입력하면 해당 토큰에 대한 원-핫 벡터를 만들어내는 함수를 만들었습니다.\n",
    "\n",
    "def one_hot_encoding(word, word_to_index):\n",
    "  one_hot_vector = [0]*(len(word_to_index)) # one_hot_vector를 word_to_index의 길이와 같도록 0으로 초기화 된 리스트를 생성\n",
    "  index = word_to_index[word]\n",
    "  one_hot_vector[index] = 1\n",
    "  return one_hot_vector\n",
    "\n",
    "# 함수 실행\n",
    "one_hot_encoding(\"자연어\", word_to_index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T11:49:29.672260400Z",
     "start_time": "2023-12-30T11:49:29.576227500Z"
    }
   },
   "id": "84fe9198838b00c6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. 케라스(Keras)를 이용한 원-핫 인코딩(One-Hot Encoding)\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "609524ed81c2ed91"
  },
  {
   "cell_type": "markdown",
   "source": [
    "케라스는 원-핫 인코딩을 수행하는 유용한 도구 to_categorical()를 지원합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38ca9bc010759cc3"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "text = \"나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T11:51:56.000296Z",
     "start_time": "2023-12-30T11:51:55.930268Z"
    }
   },
   "id": "264ac17f0fc64ebe"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야']\n",
      "단어 집합 : {'갈래': 1, '점심': 2, '햄버거': 3, '나랑': 4, '먹으러': 5, '메뉴는': 6, '최고야': 7}\n"
     ]
    }
   ],
   "source": [
    "# 케라스 토크나이저를 이용한 정수 인코딩은 다음과 같습니다.\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "text = \"나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야\"\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "print([text])\n",
    "print('단어 집합 :',tokenizer.word_index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T12:05:29.832058200Z",
     "start_time": "2023-12-30T12:05:29.712060600Z"
    }
   },
   "id": "a3993c3972d84be9"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 5, 1, 6, 3, 7]]\n",
      "[2, 5, 1, 6, 3, 7]\n"
     ]
    }
   ],
   "source": [
    "sub_text = \"점심 먹으러 갈래 메뉴는 햄버거 최고야\"\n",
    "encoded = tokenizer.texts_to_sequences([sub_text])[0]\n",
    "print(encoded)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T12:21:27.947373200Z",
     "start_time": "2023-12-30T12:21:27.836382Z"
    }
   },
   "id": "5844e4be7350eff2"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# 이제 해당 결과를 가지고, 원-핫 인코딩을 진행해보겠습니다.\n",
    "# 케라스는 정수 인코딩 된 결과로부터 원-핫 인코딩을 수행하는 to_categorical()를 지원합니다.\n",
    "\n",
    "one_hot = to_categorical(encoded)\n",
    "print(one_hot)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T12:23:33.973526500Z",
     "start_time": "2023-12-30T12:23:33.857534400Z"
    }
   },
   "id": "adda9d9ecffa4098"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. 원-핫 인코딩(One-Hot Encoding)의 한계\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8c3f98c8afeb07f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 원 핫 벡터는 단어 집합의 크기가 곧 벡터의 차원 수가 됩니다. 이는 저장 공간 측면에서는 매우 비효율적인 표현 방법입니다.\n",
    "- 원-핫 벡터는 단어의 유사도를 표현하지 못한다는 단점이 있습니다. 단어 간 유사성을 알 수 없다는 단점은 검색 시스템 등에서는 문제가 될 소지가 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74cfe17f2ae53749"
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## 02-09 데이터의 분리(Splitting Data)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3038a13fc1da77fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. 지도 학습(Supervised Learning)\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8c378821c34e21e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "머신 러닝 모델을 학습시키고 평가하기 위해서는 데이터를 적절하게 분리하는 작업이 필요합니다.\n",
    "1.  <훈련 데이터> ex)18,000개\n",
    "    X_train : 문제지 데이터\n",
    "    y_train : 문제지에 대한 정답 데이터.\n",
    "    \n",
    "    <테스트 데이터> ex)2,000개\n",
    "    X_test : 시험지 데이터.\n",
    "    y_test : 시험지에 대한 정답 데이터.\n",
    "2. 기계는 X_train과 y_train에 대해서 학습을 합니다.\n",
    "3. X_train과 y_train을 함께 보면서 어떤 메일 내용일 때 정상 메일인지 스팸 메일인지를 열심히 규칙을 도출\n",
    "4. 그리고 학습을 다 한 기계에게 y_test는 보여주지 않고, X_test에 대해서 정답을 예측하게 합니다.\n",
    "5. 예측한 답과 실제 정답인 y_test를 비교하면서 기계가 정답을 얼마나 맞췄는지를 평가합니다. 이 수치가 기계의 정확도(Accuracy)가 됩니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d3d04255f142a6a"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T12:28:35.749263100Z",
     "start_time": "2023-12-30T12:28:32.201239500Z"
    }
   },
   "id": "8bda01f2e5f630a9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. X와 y분리하기\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6ff480aba02568f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) zip 함수를 이용하여 분리하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57ee637fe64cd086"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X 데이터 : ('a', 'b', 'c')\n",
      "y 데이터 : (1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "# zip()함수는 동일한 개수를 가지는 시퀀스 자료형에서 각 순서에 등장하는 원소들끼리 묶어주는 역할을 합니다.\n",
    "# 리스트의 리스트 구성에서 zip 함수는 X와 y를 분리하는데 유용합니다. \n",
    "\n",
    "X, y = zip(['a', 1], ['b', 2], ['c', 3])\n",
    "print('X 데이터 :',X)\n",
    "print('y 데이터 :',y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T12:52:59.063037900Z",
     "start_time": "2023-12-30T12:52:58.935035100Z"
    }
   },
   "id": "9dd549de0013fd58"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 1] ['b', 2] ['c', 3]\n",
      "X 데이터 : ('a', 'b', 'c')\n",
      "y 데이터 : (1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "# 리스트의 리스트 또는 행렬 또는 뒤에서 배울 개념인 2D 텐서.\n",
    "\n",
    "sequences = [['a', 1], ['b', 2], ['c', 3]]\n",
    "X, y = zip(*sequences)\n",
    "print(*sequences) # *sequences는 시퀀스들을 unpack하여 각 시퀀스의 요소들을 개별적으로 전달하는 역할을 합니다.\n",
    "print('X 데이터 :',X)\n",
    "print('y 데이터 :',y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T12:55:35.937980700Z",
     "start_time": "2023-12-30T12:55:35.852526700Z"
    }
   },
   "id": "1f27b44e63197656"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) 데이터프레임을 이용하여 분리하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30f89692e6bc0b8a"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "                    메일 본문  스팸 메일 유무\n0        당신에게 드리는 마지막 혜택!         1\n1    내일 뵐 수 있을지 확인 부탁드...         0\n2    도연씨. 잘 지내시죠? 오랜만입...         0\n3  (광고) AI로 주가를 예측할 수 있다!         1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>메일 본문</th>\n      <th>스팸 메일 유무</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>당신에게 드리는 마지막 혜택!</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>내일 뵐 수 있을지 확인 부탁드...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>도연씨. 잘 지내시죠? 오랜만입...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(광고) AI로 주가를 예측할 수 있다!</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = [['당신에게 드리는 마지막 혜택!', 1],\n",
    "['내일 뵐 수 있을지 확인 부탁드...', 0],\n",
    "['도연씨. 잘 지내시죠? 오랜만입...', 0],\n",
    "['(광고) AI로 주가를 예측할 수 있다!', 1]]\n",
    "columns = ['메일 본문', '스팸 메일 유무']\n",
    "\n",
    "df = pd.DataFrame(values, columns=columns)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T13:40:10.619955800Z",
     "start_time": "2023-12-30T13:40:10.421958800Z"
    }
   },
   "id": "53bfa31cbeb746b0"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X 데이터 : ['당신에게 드리는 마지막 혜택!', '내일 뵐 수 있을지 확인 부탁드...', '도연씨. 잘 지내시죠? 오랜만입...', '(광고) AI로 주가를 예측할 수 있다!']\n",
      "y 데이터 : [1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임은 열의 이름으로 각 열에 접근이 가능하므로, 이를 이용하면 손쉽게 X 데이터와 y 데이터를 분리할 수 있습니다.\n",
    "\n",
    "X = df['메일 본문']\n",
    "y = df['스팸 메일 유무']\n",
    "\n",
    "print('X 데이터 :',X.to_list())\n",
    "print('y 데이터 :',y.to_list())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T13:41:30.517731100Z",
     "start_time": "2023-12-30T13:41:30.459462600Z"
    }
   },
   "id": "fa09165e3eedeb7a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3) Numpy를 이용하여 분리하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "990192be5ccebc1d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 임의의 데이터를 만들어서 Numpy의 슬라이싱(slicing)을 사용하여 데이터를 분리해봅시다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9ede196476f6e2f"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 :\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]]\n"
     ]
    }
   ],
   "source": [
    "np_array = np.arange(0,16).reshape((4,4))\n",
    "print('전체 데이터 :')\n",
    "print(np_array)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T13:42:13.124251600Z",
     "start_time": "2023-12-30T13:42:13.028247200Z"
    }
   },
   "id": "87daf9d4bafd0770"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X 데이터 :\n",
      "[[ 0  1  2]\n",
      " [ 4  5  6]\n",
      " [ 8  9 10]\n",
      " [12 13 14]]\n",
      "y 데이터 : [ 3  7 11 15]\n"
     ]
    }
   ],
   "source": [
    "# 마지막 열을 제외하고 X데이터에 저장합니다. 마지막 열만을 y데이터에 저장합니다.\n",
    "\n",
    "X = np_array[:, :3]\n",
    "y = np_array[:,3]\n",
    "\n",
    "print('X 데이터 :')\n",
    "print(X)\n",
    "print('y 데이터 :',y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T13:55:24.768647100Z",
     "start_time": "2023-12-30T13:55:24.665374500Z"
    }
   },
   "id": "2371493e2b0e261f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. 테스트 데이터 분리하기\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e5a73ea355f9791"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) 사이킷 런을 이용하여 분리하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c13fffd4ce1b9e51"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# 이번에는 이미 X와 y가 분리된 데이터에 대해서 테스트 데이터를 분리하는 과정에 대해서 알아보겠습니다.\n",
    "# 사이킷런은 학습용 테스트와 테스트용 데이터를 쉽게 분리할 수 있게 해주는 train_test_split()를 지원합니다.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state=1234)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T14:31:38.633261100Z",
     "start_time": "2023-12-30T14:31:38.552258600Z"
    }
   },
   "id": "c35a9896163df22"
  },
  {
   "cell_type": "markdown",
   "source": [
    "각 인자는 다음을 의미합니다. train_size와 test_size는 둘 중 하나만 기재해도 됩니다.\n",
    "\n",
    "X : 독립 변수 데이터. (배열이나 데이터프레임)\n",
    "y : 종속 변수 데이터. 레이블 데이터.\n",
    "test_size : 테스트용 데이터 개수를 지정한다. 1보다 작은 실수를 기재할 경우, 비율을 나타낸다.\n",
    "train_size : 학습용 데이터의 개수를 지정한다. 1보다 작은 실수를 기재할 경우, 비율을 나타낸다.\n",
    "random_state : 난수 시드"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ac740361705d9e"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X 전체 데이터 :\n",
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]\n",
      " [8 9]]\n",
      "y 전체 데이터 :\n",
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# 임의로 X와 y 데이터를 생성\n",
    "X, y = np.arange(10).reshape((5, 2)), range(5)\n",
    "\n",
    "print('X 전체 데이터 :')\n",
    "print(X)\n",
    "print('y 전체 데이터 :')\n",
    "print(list(y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T13:59:29.385235100Z",
     "start_time": "2023-12-30T13:59:29.230237600Z"
    }
   },
   "id": "1c8137da38c17aaf"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X 훈련 데이터 :\n",
      "[[2 3]\n",
      " [4 5]\n",
      " [6 7]]\n",
      "X 테스트 데이터 :\n",
      "[[8 9]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "#  random_state 값을 임의로 1234로 지정했습니다.\n",
    "\n",
    "# 7:3의 비율로 훈련 데이터와 테스트 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)\n",
    "\n",
    "# 70%의 비율로 분리된 X의 훈련 데이터와 30%의 비율로 분리된 X의 테스트 데이터입니다.\n",
    "print('X 훈련 데이터 :')\n",
    "print(X_train)\n",
    "print('X 테스트 데이터 :')\n",
    "print(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T14:33:33.829666300Z",
     "start_time": "2023-12-30T14:33:33.743587800Z"
    }
   },
   "id": "e16f6d6bd09c2a6d"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y 훈련 데이터 :\n",
      "[1, 2, 3]\n",
      "y 테스트 데이터 :\n",
      "[4, 0]\n"
     ]
    }
   ],
   "source": [
    "# 70%의 비율로 분리된 y의 훈련 데이터와 30%의 비율로 분리된 y의 테스트 데이터입니다.\n",
    "print('y 훈련 데이터 :')\n",
    "print(y_train)\n",
    "print('y 테스트 데이터 :')\n",
    "print(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T14:33:36.014680300Z",
     "start_time": "2023-12-30T14:33:35.925630Z"
    }
   },
   "id": "704a20e6c07549da"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y 훈련 데이터 :\n",
      "[4, 0, 3]\n",
      "y 테스트 데이터 :\n",
      "[2, 1]\n"
     ]
    }
   ],
   "source": [
    "# random_state의 의미를 이해하기 위해서 이번에는 random_state의 값을 임의로 다른 값인 1을 주고 다시 분리해보겠습니다. 그리고 y데이터를 출력해봅시다.\n",
    "\n",
    "# random_state의 값을 변경\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "print('y 훈련 데이터 :')\n",
    "print(y_train)\n",
    "print('y 테스트 데이터 :')\n",
    "print(y_test)\n",
    "# 데이터가 다른 순서로 섞였다는 의미입니다. "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T14:34:22.794318800Z",
     "start_time": "2023-12-30T14:34:22.697314500Z"
    }
   },
   "id": "6306b3b72487e3d8"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y 훈련 데이터 :\n",
      "[1, 2, 3]\n",
      "y 테스트 데이터 :\n",
      "[4, 0]\n"
     ]
    }
   ],
   "source": [
    " # random_state의 값을 고정해두면 실행할 때마다 항상 동일한 순서로 데이터를 섞으므로, 동일한 코드를 다음에 재현하고자 할 때 사용할 수 있습니다.\n",
    "\n",
    "# random_state을 이전의 값이었던 1234로 변경\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)\n",
    "\n",
    "print('y 훈련 데이터 :')\n",
    "print(y_train)\n",
    "print('y 테스트 데이터 :')\n",
    "print(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T14:35:44.031069300Z",
     "start_time": "2023-12-30T14:35:43.907034300Z"
    }
   },
   "id": "b17541c007f83d18"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) 수동으로 분리하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9c38a340a075110"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X 전체 데이터 :\n",
      "[[ 0  1]\n",
      " [ 2  3]\n",
      " [ 4  5]\n",
      " [ 6  7]\n",
      " [ 8  9]\n",
      " [10 11]\n",
      " [12 13]\n",
      " [14 15]\n",
      " [16 17]\n",
      " [18 19]\n",
      " [20 21]\n",
      " [22 23]]\n",
      "y 전체 데이터 :\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "# 실습을 위해 임의로 X와 y가 이미 분리 된 데이터를 생성\n",
    "X, y = np.arange(0,24).reshape((12,2)), range(12)\n",
    "\n",
    "print('X 전체 데이터 :')\n",
    "print(X)\n",
    "print('y 전체 데이터 :')\n",
    "print(list(y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T14:36:11.835106Z",
     "start_time": "2023-12-30T14:36:11.749108300Z"
    }
   },
   "id": "2dd86a95822a3fea"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 크기 : 9\n",
      "테스트 데이터의 크기 : 3\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터의 개수와 테스트 데이터의 개수를 정해보겠습니다. \n",
    "# num_of_train은 훈련 데이터의 개수를 의미하며, num_of_test는 테스트 데이터의 개수를 의미합니다.\n",
    "\n",
    "num_of_train = int(len(X) * 0.8) # 데이터의 전체 길이의 80%에 해당하는 길이값을 구한다.\n",
    "num_of_test = int(len(X) - num_of_train) # 전체 길이에서 80%에 해당하는 길이를 뺀다.\n",
    "print('훈련 데이터의 크기 :',num_of_train)\n",
    "print('테스트 데이터의 크기 :',num_of_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T15:09:28.949454100Z",
     "start_time": "2023-12-30T15:09:28.867366500Z"
    }
   },
   "id": "cd44623bbe77a2fc"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X 테스트 데이터 :\n",
      "[[18 19]\n",
      " [20 21]\n",
      " [22 23]]\n",
      "y 테스트 데이터 :\n",
      "[9, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "X_test = X[num_of_train:] # 전체 데이터 중에서 20%만큼 뒤의 데이터 저장\n",
    "y_test = y[num_of_train:] # 전체 데이터 중에서 20%만큼 뒤의 데이터 저장\n",
    "X_train = X[:num_of_train] # 전체 데이터 중에서 80%만큼 앞의 데이터 저장\n",
    "y_train = y[:num_of_train] # 전체 데이터 중에서 80%만큼 앞의 데이터 저장\n",
    "\n",
    "print('X 테스트 데이터 :')\n",
    "print(X_test)\n",
    "print('y 테스트 데이터 :')\n",
    "print(list(y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T15:13:42.199654700Z",
     "start_time": "2023-12-30T15:13:42.080653900Z"
    }
   },
   "id": "4c0ddb9ffb31d74c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## 02-10 한국어 전처리 패키지(Text Preprocessing Tools for Korean Text)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b51d927d6b2b8a09"
  },
  {
   "cell_type": "markdown",
   "source": [
    "유용한 한국어 전처리 패키지를 정리해봅시다. 앞서 소개한 형태소와 문장 토크나이징 도구들인 KoNLPy와 KSS(Korean Sentence Splitter)와 함께 유용하게 사용할 수 있는 패키지들입니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d12bb2bacfa891a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. PyKoSpacing\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "307a9f92119a69d9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "전희원님이 개발한 PyKoSpacing은 띄어쓰기가 되어있지 않은 문장을 띄어쓰기를 한 문장으로 변환해주는 패키지입니다. PyKoSpacing은 대용량 코퍼스를 학습하여 만들어진 띄어쓰기 딥 러닝 모델로 준수한 성능을 가지고 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed284e1a29cc979"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "sent = '김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T17:32:56.683808100Z",
     "start_time": "2023-12-30T17:32:56.513810Z"
    }
   },
   "id": "91622e6b147f52db"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "김철수는극중두인격의사나이이광수역을맡았다.철수는한국유일의태권도전승자를가리는결전의날을앞두고10년간함께훈련한사형인유연재(김광수분)를찾으러속세로내려온인물이다.\n"
     ]
    }
   ],
   "source": [
    "new_sent = sent.replace(\" \", '') # 띄어쓰기가 없는 문장 임의로 만들기\n",
    "print(new_sent)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T17:32:57.952815300Z",
     "start_time": "2023-12-30T17:32:57.813820400Z"
    }
   },
   "id": "f746d652b392c433"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.\n",
      "김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.\n"
     ]
    }
   ],
   "source": [
    "from pykospacing import Spacing\n",
    "spacing = Spacing()\n",
    "kospacing_sent = spacing(new_sent) \n",
    "\n",
    "print(sent)\n",
    "print(kospacing_sent)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T17:33:02.378813900Z",
     "start_time": "2023-12-30T17:33:00.794826700Z"
    }
   },
   "id": "975c437c177f3ce7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Py-Hanspell\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba752c9f7779aec9"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "맞춤법 틀리면 왜 안돼? 쓰고 싶은 대로 쓰면 되지 \n"
     ]
    }
   ],
   "source": [
    "# Py-Hanspell은 네이버 한글 맞춤법 검사기를 바탕으로 만들어진 패키지입니다.\n",
    "\n",
    "from hanspell import spell_checker\n",
    "\n",
    "sent = \"맞춤법 틀리면 외 않되? 쓰고싶은대로쓰면돼지 \"\n",
    "spelled_sent = spell_checker.check(sent)\n",
    "\n",
    "hanspell_sent = spelled_sent.checked\n",
    "print(hanspell_sent)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T17:33:05.106817100Z",
     "start_time": "2023-12-30T17:33:04.960812Z"
    }
   },
   "id": "8f7e7f44d16beb28"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "김철수는 극 중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연제(김광수 분)를 찾으러 속세로 내려온 인물이다.\n",
      "김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.\n"
     ]
    }
   ],
   "source": [
    "# 이 패키지는 띄어쓰기 또한 보정합니다. PyKoSpacing에 사용한 예제를 그대로 사용해봅시다.\n",
    "\n",
    "spelled_sent = spell_checker.check(new_sent)\n",
    "\n",
    "hanspell_sent = spelled_sent.checked\n",
    "print(hanspell_sent)\n",
    "print(kospacing_sent) # 앞서 사용한 kospacing 패키지에서 얻은 결과"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T17:39:09.427837900Z",
     "start_time": "2023-12-30T17:39:09.120816Z"
    }
   },
   "id": "7bd075a4aa902680"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. SOYNLP를 이용한 단어 토큰화\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0f0e4d97b0e9aa1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "soynlp는 품사 태깅, 단어 토큰화 등을 지원하는 단어 토크나이저입니다. 비지도 학습으로 단어 토큰화를 한다는 특징을 갖고 있으며, 데이터에 자주 등장하는 단어들을 단어로 분석합니다. soynlp 단어 토크나이저는 내부적으로 단어 점수 표로 동작합니다. 이 점수는 응집 확률(cohesion probability)과 브랜칭 엔트로피(branching entropy)를 활용합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f4024e528b85ef0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. 신조어 문제"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4868676e48aa6423"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['에이', '비식스', '이대', '휘', '1월', '최애', '돌', '기부', '요정']\n"
     ]
    }
   ],
   "source": [
    "# 기존의 형태소 분석기는 신조어나 형태소 분석기에 등록되지 않은 단어 같은 경우에는 제대로 구분하지 못하는 단점이 있었습니다.\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "tokenizer = Okt()\n",
    "print(tokenizer.morphs('에이비식스 이대휘 1월 최애돌 기부 요정'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T17:40:53.128082900Z",
     "start_time": "2023-12-30T17:40:47.666080300Z"
    }
   },
   "id": "80cce8efd57913b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. 학습하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf672d335ce2cfc8"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "30091"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텍스트 데이터에서 특정 문자 시퀀스가 함께 자주 등장하는 빈도가 높고, 앞 뒤로 조사 또는 완전히 다른 단어가 등장하는 것을 고려해서 해당 문자 시퀀스를 형태소라고 판단하는 단어 토크나이저 : soynlp\n",
    "\n",
    "import urllib.request\n",
    "from soynlp import DoublespaceLineCorpus\n",
    "from soynlp.word import WordExtractor\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/lovit/soynlp/master/tutorials/2016-10-20.txt\", filename=\"2016-10-20.txt\")\n",
    "\n",
    "# 훈련 데이터를 다수의 문서로 분리\n",
    "corpus = DoublespaceLineCorpus(\"2016-10-20.txt\")\n",
    "len(corpus) # 총 3만 91개의 문서가 존재합니다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T17:43:19.161156200Z",
     "start_time": "2023-12-30T17:43:00.602803800Z"
    }
   },
   "id": "4709b00e34adea97"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "515540cd3071f653"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19  1990  52 1 22\n",
      "오패산터널 총격전 용의자 검거 서울 연합뉴스 경찰 관계자들이 19일 오후 서울 강북구 오패산 터널 인근에서 사제 총기를 발사해 경찰을 살해한 용의자 성모씨를 검거하고 있다 성씨는 검거 당시 서바이벌 게임에서 쓰는 방탄조끼에 헬멧까지 착용한 상태였다 독자제공 영상 캡처 연합뉴스  서울 연합뉴스 김은경 기자 사제 총기로 경찰을 살해한 범인 성모 46 씨는 주도면밀했다  경찰에 따르면 성씨는 19일 오후 강북경찰서 인근 부동산 업소 밖에서 부동산업자 이모 67 씨가 나오기를 기다렸다 이씨와는 평소에도 말다툼을 자주 한 것으로 알려졌다  이씨가 나와 걷기 시작하자 성씨는 따라가면서 미리 준비해온 사제 총기를 이씨에게 발사했다 총알이 빗나가면서 이씨는 도망갔다 그 빗나간 총알은 지나가던 행인 71 씨의 배를 스쳤다  성씨는 강북서 인근 치킨집까지 이씨 뒤를 쫓으며 실랑이하다 쓰러뜨린 후 총기와 함께 가져온 망치로 이씨 머리를 때렸다  이 과정에서 오후 6시 20분께 강북구 번동 길 위에서 사람들이 싸우고 있다 총소리가 났다 는 등의 신고가 여러건 들어왔다  5분 후에 성씨의 전자발찌가 훼손됐다는 신고가 보호관찰소 시스템을 통해 들어왔다 성범죄자로 전자발찌를 차고 있던 성씨는 부엌칼로 직접 자신의 발찌를 끊었다  용의자 소지 사제총기 2정 서울 연합뉴스 임헌정 기자 서울 시내에서 폭행 용의자가 현장 조사를 벌이던 경찰관에게 사제총기를 발사해 경찰관이 숨졌다 19일 오후 6시28분 강북구 번동에서 둔기로 맞았다 는 폭행 피해 신고가 접수돼 현장에서 조사하던 강북경찰서 번동파출소 소속 김모 54 경위가 폭행 용의자 성모 45 씨가 쏜 사제총기에 맞고 쓰러진 뒤 병원에 옮겨졌으나 숨졌다 사진은 용의자가 소지한 사제총기  신고를 받고 번동파출소에서 김창호 54 경위 등 경찰들이 오후 6시 29분께 현장으로 출동했다 성씨는 그사이 부동산 앞에 놓아뒀던 가방을 챙겨 오패산 쪽으로 도망간 후였다  김 경위는 오패산 터널 입구 오른쪽의 급경사에서 성씨에게 접근하다가 오후 6시 33분께 풀숲에 숨은 성씨가 허공에 난사한 10여발의 총알 중 일부를 왼쪽 어깨 뒷부분에 맞고 쓰러졌다  김 경위는 구급차가 도착했을 때 이미 의식이 없었고 심폐소생술을 하며 병원으로 옮겨졌으나 총알이 폐를 훼손해 오후 7시 40분께 사망했다  김 경위는 외근용 조끼를 입고 있었으나 총알을 막기에는 역부족이었다  머리에 부상을 입은 이씨도 함께 병원으로 이송됐으나 생명에는 지장이 없는 것으로 알려졌다  성씨는 오패산 터널 밑쪽 숲에서 오후 6시 45분께 잡혔다  총격현장 수색하는 경찰들 서울 연합뉴스 이효석 기자 19일 오후 서울 강북구 오패산 터널 인근에서 경찰들이 폭행 용의자가 사제총기를 발사해 경찰관이 사망한 사건을 조사 하고 있다  총 때문에 쫓던 경관들과 민간인들이 몸을 숨겼는데 인근 신발가게 직원 이모씨가 다가가 성씨를 덮쳤고 이어 현장에 있던 다른 상인들과 경찰이 가세해 체포했다  성씨는 경찰에 붙잡힌 직후 나 자살하려고 한 거다 맞아 죽어도 괜찮다 고 말한 것으로 전해졌다  성씨 자신도 경찰이 발사한 공포탄 1발 실탄 3발 중 실탄 1발을 배에 맞았으나 방탄조끼를 입은 상태여서 부상하지는 않았다  경찰은 인근을 수색해 성씨가 만든 사제총 16정과 칼 7개를 압수했다 실제 폭발할지는 알 수 없는 요구르트병에 무언가를 채워두고 심지를 꽂은 사제 폭탄도 발견됐다  일부는 숲에서 발견됐고 일부는 성씨가 소지한 가방 안에 있었다\n",
      "테헤란 연합뉴스 강훈상 특파원 이용 승객수 기준 세계 최대 공항인 아랍에미리트 두바이국제공항은 19일 현지시간 이 공항을 이륙하는 모든 항공기의 탑승객은 삼성전자의 갤럭시노트7을 휴대하면 안 된다고 밝혔다  두바이국제공항은 여러 항공 관련 기구의 권고에 따라 안전성에 우려가 있는 스마트폰 갤럭시노트7을 휴대하고 비행기를 타면 안 된다 며 탑승 전 검색 중 발견되면 압수할 계획 이라고 발표했다  공항 측은 갤럭시노트7의 배터리가 폭발 우려가 제기된 만큼 이 제품을 갖고 공항 안으로 들어오지 말라고 이용객에 당부했다  이런 조치는 두바이국제공항 뿐 아니라 신공항인 두바이월드센터에도 적용된다  배터리 폭발문제로 회수된 갤럭시노트7 연합뉴스자료사진\n"
     ]
    }
   ],
   "source": [
    "# 상위 3개의 문서만 출력해봅시다.\n",
    "\n",
    "i = 0\n",
    "for document in corpus:\n",
    "  if len(document) > 0:\n",
    "    print(document)\n",
    "    i = i+1\n",
    "  if i == 3:\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T17:43:36.648158600Z",
     "start_time": "2023-12-30T17:43:36.485160100Z"
    }
   },
   "id": "c9cd49a7900bb8db"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.202 Gb\n",
      "all cohesion probabilities was computed. # words = 223348\n",
      "all branching entropies was computed # words = 361598\n",
      "all accessor variety was computed # words = 361598\n"
     ]
    }
   ],
   "source": [
    "# soynlp는 학습 기반의 단어 토크나이저이므로 기존의 KoNLPy에서 제공하는 형태소 분석기들과는 달리 학습 과정을 거쳐야 합니다. 이는 전체 코퍼스로부터 응집 확률과 브랜칭 엔트로피 단어 점수표를 만드는 과정입니다. WordExtractor.extract()를 통해서 전체 코퍼스에 대해 단어 점수표를 계산합니다.\n",
    "\n",
    "word_extractor = WordExtractor()\n",
    "word_extractor.train(corpus)\n",
    "word_score_table = word_extractor.extract()\n",
    "\n",
    "# 학습이 완료되었습니다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T17:47:04.340042800Z",
     "start_time": "2023-12-30T17:45:41.444246800Z"
    }
   },
   "id": "822f1684720788a2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. SOYNLP의 응집 확률(cohesion probability)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1da800de4c8ae128"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "0.08838002913645132"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"반포한\"].cohesion_forward"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T18:06:31.716495500Z",
     "start_time": "2023-12-30T18:06:31.589500800Z"
    }
   },
   "id": "9bd9bcf45a0e63bf"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "0.19841268168224552"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"반포한강\"].cohesion_forward"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T18:06:42.662187400Z",
     "start_time": "2023-12-30T18:06:42.435185Z"
    }
   },
   "id": "100385e148cb4263"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "0.2972877884078849"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"반포한강공\"].cohesion_forward"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T18:06:57.299517Z",
     "start_time": "2023-12-30T18:06:57.150475800Z"
    }
   },
   "id": "a5dc8ac35ad0c2e6"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "0.37891487632839754"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"반포한강공원\"].cohesion_forward # 응집 확률 가장 높음"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T18:07:04.970332600Z",
     "start_time": "2023-12-30T18:07:04.821340900Z"
    }
   },
   "id": "81c19dc44e44e9ac"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "0.33492963377557666"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"반포한강공원에\"].cohesion_forward"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T18:07:12.396119100Z",
     "start_time": "2023-12-30T18:07:12.219123800Z"
    }
   },
   "id": "dfaa56ce9148187a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4. SOYNLP의 브랜칭 엔트로피(branching entropy)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aad5da523dc859c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Branching Entropy는 확률 분포의 엔트로피값을 사용합니다. 이는 주어진 문자열에서 얼마나 다음 문자가 등장할 수 있는지를 판단하는 척도입니다.\n",
    "- 브랜칭 엔트로피의 값은 하나의 완성된 단어에 가까워질수록 문맥으로 인해 점점 정확히 예측할 수 있게 되면서 점점 줄어드는 양상을 보입니다.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1d0937652b7a37e"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "1.6371694761537934"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"디스\"].right_branching_entropy # 헷갈릴수록 높은 값"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T18:15:50.629517200Z",
     "start_time": "2023-12-30T18:15:50.463516600Z"
    }
   },
   "id": "f77ff85dbe7215a2"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "-0.0"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"디스플\"].right_branching_entropy # 명백할수록 낮은 값"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T18:15:58.747761600Z",
     "start_time": "2023-12-30T18:15:58.582763400Z"
    }
   },
   "id": "7bfd0ff0b0e287c7"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "-0.0"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"디스플레\"].right_branching_entropy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T18:17:21.986122200Z",
     "start_time": "2023-12-30T18:17:21.836106500Z"
    }
   },
   "id": "3107b782e1de1727"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "3.1400392861792916"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"디스플레이\"].right_branching_entropy # 하나의 단어가 끝나면 그 경계 부분부터 다시 브랜칭 엔트로피 값이 증가하게 됨을 의미"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T18:17:28.510165700Z",
     "start_time": "2023-12-30T18:17:28.325169100Z"
    }
   },
   "id": "236fb4921a73670f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5. SOYNLP의 L tokenizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "824f3a5aad1e60e3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "한국어는 띄어쓰기 단위로 나눈 어절 토큰은 주로 L 토큰 + R 토큰의 형식을 가질 때가 많습니다. 예를 들어서 '공원에'는 '공원 + 에'로 나눌 수 있겠지요. 또는 '공부하는'은 '공부 + 하는'으로 나눌 수도 있을 것입니다. L 토크나이저는 L 토큰 + R 토큰으로 나누되, 분리 기준을 점수가 가장 높은 L 토큰을 찾아내는 원리를 가지고 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af9fcbd4699f081e"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "[('국제사회', '와'), ('우리', '의'), ('노력', '들로'), ('범죄', '를'), ('척결', '하자')]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.tokenizer import LTokenizer\n",
    "\n",
    "scores = {word:score.cohesion_forward for word, score in word_score_table.items()}\n",
    "l_tokenizer = LTokenizer(scores=scores)\n",
    "l_tokenizer.tokenize(\"국제사회와 우리의 노력들로 범죄를 척결하자\", flatten=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T18:21:35.406525700Z",
     "start_time": "2023-12-30T18:21:35.150523300Z"
    }
   },
   "id": "ff86b1e768ee9084"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6. 최대 점수 토크나이저"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fb73b2075cad949"
  },
  {
   "cell_type": "markdown",
   "source": [
    "최대 점수 토크나이저는 띄어쓰기가 되지 않는 문장에서 점수가 높은 글자 시퀀스를 순차적으로 찾아내는 토크나이저입니다. 띄어쓰기가 되어 있지 않은 문장을 넣어서 점수를 통해 토큰화 된 결과를 보겠습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3542a7fee476274a"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "['국제사회', '와', '우리', '의', '노력', '들로', '범죄', '를', '척결', '하자']"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.tokenizer import MaxScoreTokenizer\n",
    "\n",
    "maxscore_tokenizer = MaxScoreTokenizer(scores=scores)\n",
    "maxscore_tokenizer.tokenize(\"국제사회와우리의노력들로범죄를척결하자\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T19:08:26.133976100Z",
     "start_time": "2023-12-30T19:08:25.909976800Z"
    }
   },
   "id": "f7faf6949fdc2f51"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. SOYNLP를 이용한 반복되는 문자 정제\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32ea362d3f930a50"
  },
  {
   "cell_type": "markdown",
   "source": [
    "반복되는 것은 하나로 정규화시켜줍니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "833f91199bb3b403"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아ㅋㅋ영화존잼쓰ㅠㅠ\n",
      "아ㅋㅋ영화존잼쓰ㅠㅠ\n",
      "아ㅋㅋ영화존잼쓰ㅠㅠ\n",
      "아ㅋㅋ영화존잼쓰ㅠㅠ\n"
     ]
    }
   ],
   "source": [
    "from soynlp.normalizer import *\n",
    "print(emoticon_normalize('앜ㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠ', num_repeats=2))\n",
    "print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠ', num_repeats=2))\n",
    "print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠㅠ', num_repeats=2))\n",
    "print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠㅠㅠㅠ', num_repeats=2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T19:09:59.588079200Z",
     "start_time": "2023-12-30T19:09:59.467974800Z"
    }
   },
   "id": "179695c36697f511"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "와하하핫\n",
      "와하하핫\n",
      "와하하핫\n"
     ]
    }
   ],
   "source": [
    "print(repeat_normalize('와하하하하하하하하하핫', num_repeats=2))\n",
    "print(repeat_normalize('와하하하하하하핫', num_repeats=2))\n",
    "print(repeat_normalize('와하하하하핫', num_repeats=2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T19:10:26.977872300Z",
     "start_time": "2023-12-30T19:10:26.799305200Z"
    }
   },
   "id": "fea8081fec31b7b9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Customized KoNLPy\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c35810d470eac8f6"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "['은', '경이', '는', '사무실', '로', '갔습니다', '.']"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Customized Konlpy라는 사용자 사전 추가가 매우 쉬운 패키지를 사용하여 토큰화\n",
    "from ckonlpy.tag import Twitter\n",
    "twitter = Twitter()\n",
    "twitter.morphs('은경이는 사무실로 갔습니다.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T19:14:13.102942100Z",
     "start_time": "2023-12-30T19:14:12.540945400Z"
    }
   },
   "id": "117f08b36045ca47"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# add_dictionary('단어', '품사')와 같은 형식으로 사전 추가\n",
    "twitter.add_dictionary('은경이', 'Noun')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T19:14:15.548201100Z",
     "start_time": "2023-12-30T19:14:15.402162Z"
    }
   },
   "id": "41f0bb02d2fa5189"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "['은경이', '는', '사무실', '로', '갔습니다', '.']"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.morphs('은경이는 사무실로 갔습니다.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T19:14:21.856968100Z",
     "start_time": "2023-12-30T19:14:21.701965600Z"
    }
   },
   "id": "2052eb04482d4f59"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
